{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import re\n",
    "#from bs4 import BeautifulSoup"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 8] nodename\n",
      "[nltk_data]     nor servname provided, or not known>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model_file = '/Users/shubh1/Desktop/CSCI 544/GoogleNews-vectors-negative300.bin'\n",
    "#wordmodel = Word2Vec(model_file)\n",
    "wordmodel= gensim.models.KeyedVectors.load_word2vec_format(model_file, binary=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "happy = wordmodel['happy']\n",
    "print(happy.shape)\n",
    "print(happy[:10])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(300,)\n",
      "[-0.0005188   0.16015625  0.0016098   0.02539062  0.09912109 -0.0859375\n",
      "  0.32421875 -0.02172852  0.13476562  0.11035156]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "print(wordmodel.most_similar(positive=['woman', 'king'], negative=['man']))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('queen', 0.7118192911148071), ('monarch', 0.6189674139022827), ('princess', 0.5902430415153503), ('crown_prince', 0.5499460697174072), ('prince', 0.5377321839332581), ('kings', 0.5236844420433044), ('Queen_Consort', 0.5235946178436279), ('queens', 0.5181134939193726), ('sultan', 0.5098593235015869), ('monarchy', 0.5087411403656006)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(wordmodel.similarity('car', 'minivan'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.69070363\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "cleaned_data_multi = pd.read_csv('/Users/shubh1/Desktop/CSCI 544/cleaned_data.csv')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "cleaned_data_multi=cleaned_data_multi.dropna() # Dropping reviews that have type NaN as this will cause when randomly selecting classes with a particular class\n",
    "cleaned_data_multi = cleaned_data_multi.reset_index(drop=True) # reseting the index tso that it covers up for the dropped values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "cleaned_data_multi.head()\n",
    "(cleaned_data_multi['bin_class'].value_counts())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    99972\n",
       "1    99917\n",
       "3    49968\n",
       "Name: bin_class, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "#cleaned_data_multi = cleaned_data_multi.sample(n=60000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "cleaned_data_multi['bin_class'].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    99972\n",
       "1    99917\n",
       "3    49968\n",
       "Name: bin_class, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "cleaned_data_multi['bin_class']=cleaned_data_multi['bin_class'].astype(int)\n",
    "s1 = cleaned_data_multi.bin_class[cleaned_data_multi.bin_class.eq(0)].sample(20000).index\n",
    "s2 = cleaned_data_multi.bin_class[cleaned_data_multi.bin_class.eq(1)].sample(20000).index \n",
    "s3 = cleaned_data_multi.bin_class[cleaned_data_multi.bin_class.eq(3)].sample(20000).index \n",
    "\n",
    "\n",
    "\n",
    "cleaned_data_multi = cleaned_data_multi.loc[s1.union(s2).union(s3)]\n",
    "display(cleaned_data_multi['bin_class'].value_counts())\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "3    20000\n",
       "1    20000\n",
       "0    20000\n",
       "Name: bin_class, dtype: int64"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "cleaned_data_multi['tokens'] = cleaned_data_multi['review_body'].apply(word_tokenize)\n",
    "#print(tokens)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "cleaned_data_multi.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>bin_class</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>245</td>\n",
       "      <td>3</td>\n",
       "      <td>looking coffee equipment travel want drink hot...</td>\n",
       "      <td>3</td>\n",
       "      <td>[looking, coffee, equipment, travel, want, dri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>280</td>\n",
       "      <td>5</td>\n",
       "      <td>cool prop</td>\n",
       "      <td>1</td>\n",
       "      <td>[cool, prop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>311</td>\n",
       "      <td>3</td>\n",
       "      <td>bought husband swearing owned one similar turn...</td>\n",
       "      <td>3</td>\n",
       "      <td>[bought, husband, swearing, owned, one, simila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>350</td>\n",
       "      <td>1</td>\n",
       "      <td>happy bought blender saw well blended fresh fr...</td>\n",
       "      <td>0</td>\n",
       "      <td>[happy, bought, blender, saw, well, blended, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>370</td>\n",
       "      <td>3</td>\n",
       "      <td>finish unit good w high polish unfortunately p...</td>\n",
       "      <td>3</td>\n",
       "      <td>[finish, unit, good, w, high, polish, unfortun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  star_rating  \\\n",
       "8          245            3   \n",
       "11         280            5   \n",
       "13         311            3   \n",
       "15         350            1   \n",
       "16         370            3   \n",
       "\n",
       "                                          review_body  bin_class  \\\n",
       "8   looking coffee equipment travel want drink hot...          3   \n",
       "11                                          cool prop          1   \n",
       "13  bought husband swearing owned one similar turn...          3   \n",
       "15  happy bought blender saw well blended fresh fr...          0   \n",
       "16  finish unit good w high polish unfortunately p...          3   \n",
       "\n",
       "                                               tokens  \n",
       "8   [looking, coffee, equipment, travel, want, dri...  \n",
       "11                                       [cool, prop]  \n",
       "13  [bought, husband, swearing, owned, one, simila...  \n",
       "15  [happy, bought, blender, saw, well, blended, f...  \n",
       "16  [finish, unit, good, w, high, polish, unfortun...  "
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "from gensim.models import Word2Vec"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "pip install gensim"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.1.2-cp37-cp37m-win_amd64.whl (24.0 MB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from gensim) (1.20.1)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from gensim) (1.4.1)\n",
      "Collecting Cython==0.29.23\n",
      "  Downloading Cython-0.29.23-cp37-cp37m-win_amd64.whl (1.6 MB)\n",
      "Installing collected packages: smart-open, Cython, gensim\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 0.29.6\n",
      "    Uninstalling Cython-0.29.6:\n",
      "      Successfully uninstalled Cython-0.29.6\n",
      "Successfully installed Cython-0.29.23 gensim-4.1.2 smart-open-5.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING: You are using pip version 20.0.2; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\shubh\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "My_model_multi = Word2Vec(sentences=cleaned_data_multi['tokens'], vector_size=300, window=11, min_count=10, workers=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "print(My_model_multi.wv.most_similar(positive=['woman', 'king'], negative=['man']))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('queen', 0.6290410757064819), ('henry', 0.6241995096206665), ('bbb', 0.6143993735313416), ('tramontina', 0.6095842123031616), ('rsvp', 0.6068211793899536), ('tovolo', 0.6010700464248657), ('vollrath', 0.5951377153396606), ('thisi', 0.5926298499107361), ('stanley', 0.5890523791313171), ('amco', 0.5888289213180542)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "My_model_multi.wv.most_similar(\"car\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('desk', 0.8362933993339539),\n",
       " ('shirt', 0.8031399250030518),\n",
       " ('backpack', 0.7890848517417908),\n",
       " ('cupholder', 0.6997740864753723),\n",
       " ('seat', 0.6996307373046875),\n",
       " ('sip', 0.6810407042503357),\n",
       " ('purse', 0.6785313487052917),\n",
       " ('spill', 0.6735360026359558),\n",
       " ('sippy', 0.6578125953674316),\n",
       " ('chin', 0.6452553868293762)]"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "source": [
    "#rev_rat = rev_rat.loc[rev_rat[\"class\"] != 3]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "(cleaned_data_multi.head(10))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>bin_class</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>245</td>\n",
       "      <td>3</td>\n",
       "      <td>looking coffee equipment travel want drink hot...</td>\n",
       "      <td>3</td>\n",
       "      <td>[looking, coffee, equipment, travel, want, dri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>280</td>\n",
       "      <td>5</td>\n",
       "      <td>cool prop</td>\n",
       "      <td>1</td>\n",
       "      <td>[cool, prop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>311</td>\n",
       "      <td>3</td>\n",
       "      <td>bought husband swearing owned one similar turn...</td>\n",
       "      <td>3</td>\n",
       "      <td>[bought, husband, swearing, owned, one, simila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>350</td>\n",
       "      <td>1</td>\n",
       "      <td>happy bought blender saw well blended fresh fr...</td>\n",
       "      <td>0</td>\n",
       "      <td>[happy, bought, blender, saw, well, blended, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>370</td>\n",
       "      <td>3</td>\n",
       "      <td>finish unit good w high polish unfortunately p...</td>\n",
       "      <td>3</td>\n",
       "      <td>[finish, unit, good, w, high, polish, unfortun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>465</td>\n",
       "      <td>4</td>\n",
       "      <td>work designed</td>\n",
       "      <td>1</td>\n",
       "      <td>[work, designed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>597</td>\n",
       "      <td>1</td>\n",
       "      <td>worst quality product ever seen thin paper arr...</td>\n",
       "      <td>0</td>\n",
       "      <td>[worst, quality, product, ever, seen, thin, pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>764</td>\n",
       "      <td>5</td>\n",
       "      <td>great product</td>\n",
       "      <td>1</td>\n",
       "      <td>[great, product]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>781</td>\n",
       "      <td>3</td>\n",
       "      <td>cute see picture sleeping pour somthing hot so...</td>\n",
       "      <td>3</td>\n",
       "      <td>[cute, see, picture, sleeping, pour, somthing,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>864</td>\n",
       "      <td>5</td>\n",
       "      <td>pan bombay going buy similar one macy 's well ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[pan, bombay, going, buy, similar, one, macy, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  star_rating  \\\n",
       "8          245            3   \n",
       "11         280            5   \n",
       "13         311            3   \n",
       "15         350            1   \n",
       "16         370            3   \n",
       "21         465            4   \n",
       "27         597            1   \n",
       "34         764            5   \n",
       "35         781            3   \n",
       "37         864            5   \n",
       "\n",
       "                                          review_body  bin_class  \\\n",
       "8   looking coffee equipment travel want drink hot...          3   \n",
       "11                                          cool prop          1   \n",
       "13  bought husband swearing owned one similar turn...          3   \n",
       "15  happy bought blender saw well blended fresh fr...          0   \n",
       "16  finish unit good w high polish unfortunately p...          3   \n",
       "21                                      work designed          1   \n",
       "27  worst quality product ever seen thin paper arr...          0   \n",
       "34                                      great product          1   \n",
       "35  cute see picture sleeping pour somthing hot so...          3   \n",
       "37  pan bombay going buy similar one macy 's well ...          1   \n",
       "\n",
       "                                               tokens  \n",
       "8   [looking, coffee, equipment, travel, want, dri...  \n",
       "11                                       [cool, prop]  \n",
       "13  [bought, husband, swearing, owned, one, simila...  \n",
       "15  [happy, bought, blender, saw, well, blended, f...  \n",
       "16  [finish, unit, good, w, high, polish, unfortun...  \n",
       "21                                   [work, designed]  \n",
       "27  [worst, quality, product, ever, seen, thin, pa...  \n",
       "34                                   [great, product]  \n",
       "35  [cute, see, picture, sleeping, pour, somthing,...  \n",
       "37  [pan, bombay, going, buy, similar, one, macy, ...  "
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "print(\"The vocabulary is built\")\n",
    "print(\"Word2Vec vocabulary length: \", len(My_model_multi.wv.index_to_key))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The vocabulary is built\n",
      "Word2Vec vocabulary length:  7628\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "def avg_of_my_w2v(tokens, my_model):\n",
    "    all_avg = []\n",
    "    x = my_model.wv.index_to_key\n",
    "    for i in tokens:\n",
    "        count = 0\n",
    "        flag = True\n",
    "        vec_avg = [0]*300\n",
    "        for word in i:\n",
    "            if word in x:\n",
    "                count += 1\n",
    "                vec_avg = np.add(vec_avg, my_model.wv[word])\n",
    "                flag = False\n",
    "        if not flag:\n",
    "            vec_avg = np.divide(vec_avg, count)\n",
    "        all_avg.append(vec_avg)\n",
    "    return all_avg"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "all_avg_vec = avg_of_my_w2v(cleaned_data_multi['tokens'], My_model_multi)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "len(all_avg_vec)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "avg_df = pd.DataFrame(all_avg_vec)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "avg_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038945</td>\n",
       "      <td>0.206727</td>\n",
       "      <td>-0.067343</td>\n",
       "      <td>-0.112090</td>\n",
       "      <td>0.054422</td>\n",
       "      <td>-0.227041</td>\n",
       "      <td>0.085277</td>\n",
       "      <td>0.186996</td>\n",
       "      <td>-0.074366</td>\n",
       "      <td>-0.122684</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119227</td>\n",
       "      <td>0.036371</td>\n",
       "      <td>0.137847</td>\n",
       "      <td>-0.013985</td>\n",
       "      <td>0.068264</td>\n",
       "      <td>0.207776</td>\n",
       "      <td>0.063666</td>\n",
       "      <td>-0.071212</td>\n",
       "      <td>0.028563</td>\n",
       "      <td>-0.037898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.472058</td>\n",
       "      <td>0.115312</td>\n",
       "      <td>-0.502373</td>\n",
       "      <td>-0.254824</td>\n",
       "      <td>0.550768</td>\n",
       "      <td>-0.803153</td>\n",
       "      <td>-0.388678</td>\n",
       "      <td>-0.719717</td>\n",
       "      <td>0.151161</td>\n",
       "      <td>-0.172232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117870</td>\n",
       "      <td>-0.482158</td>\n",
       "      <td>-0.257723</td>\n",
       "      <td>0.337146</td>\n",
       "      <td>0.025211</td>\n",
       "      <td>0.088929</td>\n",
       "      <td>-0.035327</td>\n",
       "      <td>-0.222433</td>\n",
       "      <td>-0.289926</td>\n",
       "      <td>0.179659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.077275</td>\n",
       "      <td>0.270581</td>\n",
       "      <td>0.095362</td>\n",
       "      <td>-0.042503</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>-0.138072</td>\n",
       "      <td>0.141207</td>\n",
       "      <td>0.129736</td>\n",
       "      <td>-0.081879</td>\n",
       "      <td>0.033735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072841</td>\n",
       "      <td>-0.147933</td>\n",
       "      <td>-0.086988</td>\n",
       "      <td>0.124434</td>\n",
       "      <td>-0.057612</td>\n",
       "      <td>-0.119156</td>\n",
       "      <td>0.057782</td>\n",
       "      <td>-0.109142</td>\n",
       "      <td>-0.032817</td>\n",
       "      <td>-0.156690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.135579</td>\n",
       "      <td>0.187834</td>\n",
       "      <td>0.065052</td>\n",
       "      <td>-0.085146</td>\n",
       "      <td>-0.072632</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>0.087453</td>\n",
       "      <td>0.163439</td>\n",
       "      <td>-0.021071</td>\n",
       "      <td>-0.064506</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005571</td>\n",
       "      <td>-0.011158</td>\n",
       "      <td>0.032949</td>\n",
       "      <td>0.152239</td>\n",
       "      <td>-0.073318</td>\n",
       "      <td>0.094006</td>\n",
       "      <td>-0.030412</td>\n",
       "      <td>-0.052817</td>\n",
       "      <td>-0.041079</td>\n",
       "      <td>-0.104955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016743</td>\n",
       "      <td>-0.012309</td>\n",
       "      <td>-0.125040</td>\n",
       "      <td>-0.259933</td>\n",
       "      <td>0.085846</td>\n",
       "      <td>-0.268520</td>\n",
       "      <td>-0.156323</td>\n",
       "      <td>-0.222903</td>\n",
       "      <td>-0.272131</td>\n",
       "      <td>0.045757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156090</td>\n",
       "      <td>-0.046029</td>\n",
       "      <td>-0.003645</td>\n",
       "      <td>0.113972</td>\n",
       "      <td>0.056319</td>\n",
       "      <td>0.396197</td>\n",
       "      <td>0.043700</td>\n",
       "      <td>-0.218440</td>\n",
       "      <td>-0.007843</td>\n",
       "      <td>0.140811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.038945  0.206727 -0.067343 -0.112090  0.054422 -0.227041  0.085277   \n",
       "1 -0.472058  0.115312 -0.502373 -0.254824  0.550768 -0.803153 -0.388678   \n",
       "2 -0.077275  0.270581  0.095362 -0.042503  0.000374 -0.138072  0.141207   \n",
       "3  0.135579  0.187834  0.065052 -0.085146 -0.072632  0.002635  0.087453   \n",
       "4  0.016743 -0.012309 -0.125040 -0.259933  0.085846 -0.268520 -0.156323   \n",
       "\n",
       "        7         8         9    ...       290       291       292       293  \\\n",
       "0  0.186996 -0.074366 -0.122684  ... -0.119227  0.036371  0.137847 -0.013985   \n",
       "1 -0.719717  0.151161 -0.172232  ...  0.117870 -0.482158 -0.257723  0.337146   \n",
       "2  0.129736 -0.081879  0.033735  ... -0.072841 -0.147933 -0.086988  0.124434   \n",
       "3  0.163439 -0.021071 -0.064506  ... -0.005571 -0.011158  0.032949  0.152239   \n",
       "4 -0.222903 -0.272131  0.045757  ... -0.156090 -0.046029 -0.003645  0.113972   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0  0.068264  0.207776  0.063666 -0.071212  0.028563 -0.037898  \n",
       "1  0.025211  0.088929 -0.035327 -0.222433 -0.289926  0.179659  \n",
       "2 -0.057612 -0.119156  0.057782 -0.109142 -0.032817 -0.156690  \n",
       "3 -0.073318  0.094006 -0.030412 -0.052817 -0.041079 -0.104955  \n",
       "4  0.056319  0.396197  0.043700 -0.218440 -0.007843  0.140811  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "avg_df.to_csv('/Users/shubh1/Desktop/CSCI 544/avg_vector_multi.csv',index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "ret_avg_df = pd.read_csv('/Users/shubh1/Desktop/CSCI 544/avg_vector_multi.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "(ret_avg_df.head())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038945</td>\n",
       "      <td>0.206727</td>\n",
       "      <td>-0.067343</td>\n",
       "      <td>-0.112090</td>\n",
       "      <td>0.054422</td>\n",
       "      <td>-0.227041</td>\n",
       "      <td>0.085277</td>\n",
       "      <td>0.186996</td>\n",
       "      <td>-0.074366</td>\n",
       "      <td>-0.122684</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119227</td>\n",
       "      <td>0.036371</td>\n",
       "      <td>0.137847</td>\n",
       "      <td>-0.013985</td>\n",
       "      <td>0.068264</td>\n",
       "      <td>0.207776</td>\n",
       "      <td>0.063666</td>\n",
       "      <td>-0.071212</td>\n",
       "      <td>0.028563</td>\n",
       "      <td>-0.037898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.472058</td>\n",
       "      <td>0.115312</td>\n",
       "      <td>-0.502373</td>\n",
       "      <td>-0.254824</td>\n",
       "      <td>0.550768</td>\n",
       "      <td>-0.803153</td>\n",
       "      <td>-0.388678</td>\n",
       "      <td>-0.719717</td>\n",
       "      <td>0.151161</td>\n",
       "      <td>-0.172232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117870</td>\n",
       "      <td>-0.482158</td>\n",
       "      <td>-0.257723</td>\n",
       "      <td>0.337146</td>\n",
       "      <td>0.025211</td>\n",
       "      <td>0.088929</td>\n",
       "      <td>-0.035327</td>\n",
       "      <td>-0.222433</td>\n",
       "      <td>-0.289926</td>\n",
       "      <td>0.179659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.077275</td>\n",
       "      <td>0.270581</td>\n",
       "      <td>0.095362</td>\n",
       "      <td>-0.042503</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>-0.138072</td>\n",
       "      <td>0.141207</td>\n",
       "      <td>0.129736</td>\n",
       "      <td>-0.081879</td>\n",
       "      <td>0.033735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072841</td>\n",
       "      <td>-0.147933</td>\n",
       "      <td>-0.086988</td>\n",
       "      <td>0.124434</td>\n",
       "      <td>-0.057612</td>\n",
       "      <td>-0.119156</td>\n",
       "      <td>0.057782</td>\n",
       "      <td>-0.109142</td>\n",
       "      <td>-0.032817</td>\n",
       "      <td>-0.156690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.135579</td>\n",
       "      <td>0.187834</td>\n",
       "      <td>0.065052</td>\n",
       "      <td>-0.085146</td>\n",
       "      <td>-0.072632</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>0.087453</td>\n",
       "      <td>0.163439</td>\n",
       "      <td>-0.021071</td>\n",
       "      <td>-0.064506</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005571</td>\n",
       "      <td>-0.011158</td>\n",
       "      <td>0.032949</td>\n",
       "      <td>0.152239</td>\n",
       "      <td>-0.073318</td>\n",
       "      <td>0.094006</td>\n",
       "      <td>-0.030412</td>\n",
       "      <td>-0.052817</td>\n",
       "      <td>-0.041079</td>\n",
       "      <td>-0.104955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016743</td>\n",
       "      <td>-0.012309</td>\n",
       "      <td>-0.125040</td>\n",
       "      <td>-0.259933</td>\n",
       "      <td>0.085846</td>\n",
       "      <td>-0.268520</td>\n",
       "      <td>-0.156323</td>\n",
       "      <td>-0.222903</td>\n",
       "      <td>-0.272131</td>\n",
       "      <td>0.045757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156090</td>\n",
       "      <td>-0.046029</td>\n",
       "      <td>-0.003645</td>\n",
       "      <td>0.113972</td>\n",
       "      <td>0.056319</td>\n",
       "      <td>0.396197</td>\n",
       "      <td>0.043700</td>\n",
       "      <td>-0.218440</td>\n",
       "      <td>-0.007843</td>\n",
       "      <td>0.140811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.038945  0.206727 -0.067343 -0.112090  0.054422 -0.227041  0.085277   \n",
       "1 -0.472058  0.115312 -0.502373 -0.254824  0.550768 -0.803153 -0.388678   \n",
       "2 -0.077275  0.270581  0.095362 -0.042503  0.000374 -0.138072  0.141207   \n",
       "3  0.135579  0.187834  0.065052 -0.085146 -0.072632  0.002635  0.087453   \n",
       "4  0.016743 -0.012309 -0.125040 -0.259933  0.085846 -0.268520 -0.156323   \n",
       "\n",
       "          7         8         9  ...       290       291       292       293  \\\n",
       "0  0.186996 -0.074366 -0.122684  ... -0.119227  0.036371  0.137847 -0.013985   \n",
       "1 -0.719717  0.151161 -0.172232  ...  0.117870 -0.482158 -0.257723  0.337146   \n",
       "2  0.129736 -0.081879  0.033735  ... -0.072841 -0.147933 -0.086988  0.124434   \n",
       "3  0.163439 -0.021071 -0.064506  ... -0.005571 -0.011158  0.032949  0.152239   \n",
       "4 -0.222903 -0.272131  0.045757  ... -0.156090 -0.046029 -0.003645  0.113972   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0  0.068264  0.207776  0.063666 -0.071212  0.028563 -0.037898  \n",
       "1  0.025211  0.088929 -0.035327 -0.222433 -0.289926  0.179659  \n",
       "2 -0.057612 -0.119156  0.057782 -0.109142 -0.032817 -0.156690  \n",
       "3 -0.073318  0.094006 -0.030412 -0.052817 -0.041079 -0.104955  \n",
       "4  0.056319  0.396197  0.043700 -0.218440 -0.007843  0.140811  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y_orig = cleaned_data_multi[\"bin_class\"]\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(ret_avg_df, y_orig, test_size=0.2, random_state=42, stratify = y_orig)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "#word2vec_df = pd.read_csv(word2vec_filename)\n",
    "#word2vec_df.head(-1)\n",
    "#len(word2vec_df)\n",
    "perc = Perceptron(random_state=42)\n",
    "perc.fit(X_train2, y_train2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Perceptron(random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions_train = perc.predict(X_train2)\n",
    "predictions_test = perc.predict(X_test2)\n",
    "train_score = accuracy_score(predictions_train, y_train2)\n",
    "print(\"score on train data: \", train_score)\n",
    "test_score = accuracy_score(predictions_test, y_test2)\n",
    "print(\"score on test data: \", test_score)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "score on train data:  0.5538541666666666\n",
      "score on test data:  0.55425\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm_model = LinearSVC(random_state=8)\n",
    "svm_model.fit(X_train2, y_train2)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/17/jys7jgwn3x37cltk9w8j0l080000gq/T/ipykernel_78131/1292357805.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msvm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msvm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/svm/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0msolver_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_liblinear_solver_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m     raw_coef_, n_iter_ = liblinear.train_wrap(\n\u001b[0m\u001b[1;32m    976\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "source": [
    "predictions_train = svm_model.predict(X_train2)\n",
    "predictions_test = svm_model.predict(X_test2)\n",
    "train_score = accuracy_score(predictions_train, y_train2)\n",
    "print(\"score on train data: \", train_score)\n",
    "test_score = accuracy_score(predictions_test, y_test2)\n",
    "print(\"score on test data: \", test_score)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "score on train data:  0.8548\n",
      "score on test data:  0.8531\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "pip install torch"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\shubh\\anaconda3\\lib\\site-packages (1.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING: You are using pip version 20.0.2; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\shubh\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device available for running: \")\n",
    "print(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Device available for running: \n",
      "cpu\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "class FF_NL(nn.Module):\n",
    "    def __init__(self, input_val, hidden_v1, hidden_v2, output_val):\n",
    "        \n",
    "        super(FF_NL, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.fcl1 = nn.Linear(input_val, hidden_v1) \n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # Linear function 2: 500 --> 500\n",
    "        self.fcl2 = nn.Linear(hidden_v1, hidden_v2)\n",
    "        # Non-linearity 2\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Linear function 3 (readout): 500 --> 3\n",
    "        self.fcl3 = nn.Linear(hidden_v2, output_val)  \n",
    "\n",
    "    def forward(self, x_val):\n",
    "        # Linear function 1\n",
    "        out_val = self.fcl1(x_val)\n",
    "        out_val = self.relu1(out_val)\n",
    "        out_val = self.fcl2(out_val)\n",
    "        out_val = self.relu2(out_val)\n",
    "        out_val = self.fcl3(out_val)\n",
    "\n",
    "        return torch.softmax(out_val,dim=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "model = FF_NL(300,50,10,3)\n",
    "x = torch.randn(50,300)\n",
    "print(model(x).shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([50, 3])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "#print(b[0])\n",
    "ret_avg_df_nn = pd.read_csv('/Users/shubh1/Desktop/CSCI 544/avg_vector_multi.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "y2_nn = cleaned_data_multi[\"bin_class\"]\n",
    "X_train2_nn, X_test2_nn, y_train2_nn, y_test2_nn = train_test_split(ret_avg_df_nn, y2_nn, test_size=0.2, random_state=42, stratify = y2_nn)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "\n",
    "\n",
    "input_dim = 300\n",
    "hidden_dim1 = 50\n",
    "hidden_dim2 =10\n",
    "output_dim = 3\n",
    "num_epochs = 50\n",
    "\n",
    "ff_nn_w2v_my_model = FF_NL(input_dim, hidden_dim1,hidden_dim2, output_dim)\n",
    "#ff_nn_bow_model.to(device)\n",
    "\n",
    "loss_fn_est = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(ff_nn_w2v_my_model.parameters(), lr=0.0001)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "ff_nn_w2v_my_model.eval()\n",
    "#print(X_test2_nn.iloc[0])\n",
    "d =torch.tensor(X_test2_nn.iloc[0])\n",
    "#print(d)\n",
    "d = torch.reshape(d,(1,300)).float()\n",
    "#print(y_test2_nn.iloc[0])\n",
    "e = torch.tensor(y_test2_nn.iloc[0])\n",
    "#print(e)\n",
    "\n",
    "#print(type(d))\n",
    "y_pred = ff_nn_w2v_my_model(d)\n",
    "y_pred = torch.reshape(y_pred,(1,3))\n",
    "\n",
    "e = torch.reshape(e,(1,))\n",
    "#print(y_pred,e.size())\n",
    "before_train = loss_fn_est(y_pred, e)\n",
    "print('Test loss before training' , before_train.item())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test loss before training 1.1759212017059326\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "def make_target(label):\n",
    "    #print(label[0])\n",
    "    if label[0] == 0:\n",
    "        return torch.tensor([0], dtype=torch.long, device=device)\n",
    "    elif label[0] == 1:\n",
    "        return torch.tensor([1], dtype=torch.long, device=device)\n",
    "    else:\n",
    "        return torch.tensor([2], dtype=torch.long, device=device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "temp =0\n",
    "tr= 0\n",
    "ff_nn_w2v_my_model.train()\n",
    "# Start training\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    if (epoch+1) % 25 == 0:\n",
    "        print(\"Epoch completed: \" + str(epoch+1))\n",
    "    loss_train = 0\n",
    "    \n",
    "    #optimizer.zero_grad()\n",
    "    for idx in range(len(X_train2_nn)):\n",
    "        \n",
    "        # Clearing the accumulated gradients\n",
    "        \n",
    "        x_inp = X_train2_nn.iloc[idx]\n",
    "        x_inp = torch.tensor(x_inp)\n",
    "        x_inp = torch.reshape(x_inp,(1,300)).float()\n",
    "        #print(x_inp.shape)\n",
    "        # Forward pass to get output\n",
    "        x_prob = ff_nn_w2v_my_model(x_inp)\n",
    "        x_prob = torch.reshape(x_prob,(1,3))\n",
    "        #print('xpr',x_prob)\n",
    "        y_inp = make_target([y_train2_nn.iloc[idx]])\n",
    "        #print(probs.size())\n",
    "        #print('yinp',y_inp)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn_est(x_prob, y_inp)\n",
    "        # Accumulating the loss over time\n",
    "        loss_train += loss.item()\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        tr+=1\n",
    "        temp+=1\n",
    "\n",
    "    \n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format((loss_train / len(X_train2_nn))))\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0001 cost = 0.945759\n",
      "Epoch: 0002 cost = 0.924076\n",
      "Epoch: 0003 cost = 0.920244\n",
      "Epoch: 0004 cost = 0.917612\n",
      "Epoch: 0005 cost = 0.915286\n",
      "Epoch: 0006 cost = 0.913240\n",
      "Epoch: 0007 cost = 0.911211\n",
      "Epoch: 0008 cost = 0.909285\n",
      "Epoch: 0009 cost = 0.907283\n",
      "Epoch: 0010 cost = 0.905525\n",
      "Epoch: 0011 cost = 0.903897\n",
      "Epoch: 0012 cost = 0.902400\n",
      "Epoch: 0013 cost = 0.900891\n",
      "Epoch: 0014 cost = 0.899508\n",
      "Epoch: 0015 cost = 0.897945\n",
      "Epoch: 0016 cost = 0.896520\n",
      "Epoch: 0017 cost = 0.895206\n",
      "Epoch: 0018 cost = 0.893952\n",
      "Epoch: 0019 cost = 0.892714\n",
      "Epoch: 0020 cost = 0.891494\n",
      "Epoch: 0021 cost = 0.890423\n",
      "Epoch: 0022 cost = 0.889391\n",
      "Epoch: 0023 cost = 0.888411\n",
      "Epoch: 0024 cost = 0.887331\n",
      "Epoch completed: 25\n",
      "Epoch: 0025 cost = 0.886397\n",
      "Epoch: 0026 cost = 0.885373\n",
      "Epoch: 0027 cost = 0.884438\n",
      "Epoch: 0028 cost = 0.883463\n",
      "Epoch: 0029 cost = 0.882725\n",
      "Epoch: 0030 cost = 0.881664\n",
      "Epoch: 0031 cost = 0.880839\n",
      "Epoch: 0032 cost = 0.879976\n",
      "Epoch: 0033 cost = 0.878973\n",
      "Epoch: 0034 cost = 0.878226\n",
      "Epoch: 0035 cost = 0.877508\n",
      "Epoch: 0036 cost = 0.876748\n",
      "Epoch: 0037 cost = 0.876058\n",
      "Epoch: 0038 cost = 0.875325\n",
      "Epoch: 0039 cost = 0.874362\n",
      "Epoch: 0040 cost = 0.873688\n",
      "Epoch: 0041 cost = 0.873013\n",
      "Epoch: 0042 cost = 0.872463\n",
      "Epoch: 0043 cost = 0.871781\n",
      "Epoch: 0044 cost = 0.871130\n",
      "Epoch: 0045 cost = 0.870541\n",
      "Epoch: 0046 cost = 0.869864\n",
      "Epoch: 0047 cost = 0.868931\n",
      "Epoch: 0048 cost = 0.868242\n",
      "Epoch: 0049 cost = 0.867707\n",
      "Epoch completed: 50\n",
      "Epoch: 0050 cost = 0.867217\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "ff_nn_w2v_my_model.eval()\n",
    "#print(X_test2_nn.iloc[0])\n",
    "d =torch.tensor(X_test2_nn.iloc[0])\n",
    "d = torch.reshape(d,(1,300)).float()\n",
    "#print(y_test2_nn.iloc[0])\n",
    "e = torch.tensor(y_test2_nn.iloc[0])\n",
    "#print(e)\n",
    "\n",
    "#print(d)\n",
    "y_pred = ff_nn_w2v_my_model(d)\n",
    "y_pred = torch.reshape(y_pred,(1,3))\n",
    "\n",
    "e = torch.reshape(e,(1,))\n",
    "print(y_pred,e.size())\n",
    "before_train = loss_fn_est(y_pred, e)\n",
    "print('Test loss after training' , before_train.item())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1.0110e-17, 9.1844e-01, 8.1562e-02]], grad_fn=<ViewBackward>) torch.Size([1])\n",
      "Test loss after training 0.6055189967155457\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "from sklearn.metrics import classification_report\n",
    "bow_ff_nn_predictions = []\n",
    "original_lables_ff_bow = []\n",
    "tp = 0\n",
    "sa = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for index, row in X_test2_nn.iterrows():\n",
    "        \n",
    "        cxv = X_test2_nn.iloc[tp]\n",
    "        #print(cxv[0])\n",
    "        cxv = torch.tensor(cxv)\n",
    "        \n",
    "        cxv = torch.reshape(cxv,(1,300)).float()\n",
    "        #bow_vec = make_bow_vector(review_dict, row['stemmed_tokens'])\n",
    "        \n",
    "        probs_t = ff_nn_w2v_my_model(cxv)\n",
    "        #print('pr,probs',probs_t)\n",
    "        vcx = make_target([y_test2_nn.iloc[tp]])\n",
    "        #print(probs.size())\n",
    "        probs_t = torch.reshape(probs_t,(1,3))\n",
    "        #print(probs_t)\n",
    "        #print('max',torch.argmax(probs_t, dim=1))\n",
    "        #print('vcx',vcx)\n",
    "        bow_ff_nn_predictions.append(torch.argmax(probs_t, dim=1).cpu().numpy()[0])\n",
    "        original_lables_ff_bow.append(vcx.cpu().numpy()[0])\n",
    "        tp+=1\n",
    "        sa+=1\n",
    "#print(bow_ff_nn_predictions)\n",
    "#print(original_lables_ff_bow)\n",
    "print(classification_report(original_lables_ff_bow,bow_ff_nn_predictions))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.65      4000\n",
      "           1       0.68      0.70      0.69      4000\n",
      "           2       0.51      0.50      0.51      4000\n",
      "\n",
      "    accuracy                           0.62     12000\n",
      "   macro avg       0.61      0.62      0.61     12000\n",
      "weighted avg       0.61      0.62      0.61     12000\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Train Test Split Function\n",
    "def split_train_test(dataset1, test_size=0.2, shuffle_state=True):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(dataset1[['review_body','tokens']], \n",
    "                                                        dataset1['class'], \n",
    "                                                        shuffle=shuffle_state,\n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=5)\n",
    "    print(\"Value counts for Train sentiments\")\n",
    "    print(Y_train.value_counts())\n",
    "    print(\"Value counts for Test sentiments\")\n",
    "    print(Y_test.value_counts())\n",
    "    print(type(X_train))\n",
    "    print(type(Y_train))\n",
    "    X_train = X_train.reset_index()\n",
    "    X_test = X_test.reset_index()\n",
    "    Y_train = Y_train.to_frame()\n",
    "    Y_train = Y_train.reset_index()\n",
    "    Y_test = Y_test.to_frame()\n",
    "    Y_test = Y_test.reset_index()\n",
    "    print(X_train.head())\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "# Call the train_test_split\n",
    "X_train, X_test, Y_train, Y_test = split_train_test(dataset1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Value counts for Train sentiments\n",
      "1    80114\n",
      "0    79886\n",
      "Name: class, dtype: int64\n",
      "Value counts for Test sentiments\n",
      "0    20114\n",
      "1    19886\n",
      "Name: class, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "    index                                        review_body  \\\n",
      "0    5485  cosmos pack stainless pie cakei hate look like...   \n",
      "1   52399  far worst piece kitchen equipment I ever purch...   \n",
      "2  116477  ordered set four coaster opened box two set co...   \n",
      "3  138959  owned blomus coffeetea measurer several year b...   \n",
      "4   56635               excellent service received described   \n",
      "\n",
      "                                              tokens  \n",
      "0  [cosmos, pack, stainless, pie, cakei, hate, lo...  \n",
      "1  [far, worst, piece, kitchen, equipment, I, eve...  \n",
      "2  [ordered, set, four, coaster, opened, box, two...  \n",
      "3  [owned, blomus, coffeetea, measurer, several, ...  \n",
      "4          [excellent, service, received, described]  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "source": [
    "X_train"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>review_body</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5485</td>\n",
       "      <td>cosmos pack stainless pie cakei hate look like...</td>\n",
       "      <td>[cosmos, pack, stainless, pie, cakei, hate, lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52399</td>\n",
       "      <td>far worst piece kitchen equipment I ever purch...</td>\n",
       "      <td>[far, worst, piece, kitchen, equipment, I, eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116477</td>\n",
       "      <td>ordered set four coaster opened box two set co...</td>\n",
       "      <td>[ordered, set, four, coaster, opened, box, two...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138959</td>\n",
       "      <td>owned blomus coffeetea measurer several year b...</td>\n",
       "      <td>[owned, blomus, coffeetea, measurer, several, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56635</td>\n",
       "      <td>excellent service received described</td>\n",
       "      <td>[excellent, service, received, described]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159995</th>\n",
       "      <td>121974</td>\n",
       "      <td>say always loved rubbermaid price cheaper tupp...</td>\n",
       "      <td>[say, always, loved, rubbermaid, price, cheape...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159996</th>\n",
       "      <td>124605</td>\n",
       "      <td>please remove question guide thank customer li...</td>\n",
       "      <td>[please, remove, question, guide, thank, custo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159997</th>\n",
       "      <td>20463</td>\n",
       "      <td>found item dangerous timidchanging blade close...</td>\n",
       "      <td>[found, item, dangerous, timidchanging, blade,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159998</th>\n",
       "      <td>18638</td>\n",
       "      <td>essential coffee machine</td>\n",
       "      <td>[essential, coffee, machine]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159999</th>\n",
       "      <td>35683</td>\n",
       "      <td>may completely necessary work rip waffle apart</td>\n",
       "      <td>[may, completely, necessary, work, rip, waffle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                        review_body  \\\n",
       "0         5485  cosmos pack stainless pie cakei hate look like...   \n",
       "1        52399  far worst piece kitchen equipment I ever purch...   \n",
       "2       116477  ordered set four coaster opened box two set co...   \n",
       "3       138959  owned blomus coffeetea measurer several year b...   \n",
       "4        56635               excellent service received described   \n",
       "...        ...                                                ...   \n",
       "159995  121974  say always loved rubbermaid price cheaper tupp...   \n",
       "159996  124605  please remove question guide thank customer li...   \n",
       "159997   20463  found item dangerous timidchanging blade close...   \n",
       "159998   18638                           essential coffee machine   \n",
       "159999   35683     may completely necessary work rip waffle apart   \n",
       "\n",
       "                                                   tokens  \n",
       "0       [cosmos, pack, stainless, pie, cakei, hate, lo...  \n",
       "1       [far, worst, piece, kitchen, equipment, I, eve...  \n",
       "2       [ordered, set, four, coaster, opened, box, two...  \n",
       "3       [owned, blomus, coffeetea, measurer, several, ...  \n",
       "4               [excellent, service, received, described]  \n",
       "...                                                   ...  \n",
       "159995  [say, always, loved, rubbermaid, price, cheape...  \n",
       "159996  [please, remove, question, guide, thank, custo...  \n",
       "159997  [found, item, dangerous, timidchanging, blade,...  \n",
       "159998                       [essential, coffee, machine]  \n",
       "159999  [may, completely, necessary, work, rip, waffle...  \n",
       "\n",
       "[160000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 147
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "source": [
    "Y_train"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116477</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138959</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56635</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159995</th>\n",
       "      <td>121974</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159996</th>\n",
       "      <td>124605</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159997</th>\n",
       "      <td>20463</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159998</th>\n",
       "      <td>18638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159999</th>\n",
       "      <td>35683</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  class\n",
       "0         5485      0\n",
       "1        52399      0\n",
       "2       116477      0\n",
       "3       138959      1\n",
       "4        56635      1\n",
       "...        ...    ...\n",
       "159995  121974      1\n",
       "159996  124605      0\n",
       "159997   20463      0\n",
       "159998   18638      1\n",
       "159999   35683      1\n",
       "\n",
       "[160000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 148
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "My_model1 = Word2Vec(sentences=dataset1['tokens'], vector_size=300, window=11, min_count=10, workers=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "source": [
    "print(wordmodel.similarity('expected', 'result'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.22434078\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "source": [
    "#dataset['tokens'] = dataset['review_body'].apply(word_tokenize)\n",
    "#dataset1.head(5)\n",
    "dataset1['tokens'][1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['work', 'expected', 'hold', 'close', 'quicker', 'result']"
      ]
     },
     "metadata": {},
     "execution_count": 157
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "source": [
    "word2vec_filename = '/Users/shubh1/Desktop/CSCI 544/train_review_word2vec1.csv'\n",
    "with open(word2vec_filename, 'w+') as word2vec_file:\n",
    "    count = 0\n",
    "    crow = 0\n",
    "    cat = 0\n",
    "    temp =[]\n",
    "    v = 0\n",
    "    nv =[]\n",
    "    for index, row in X_train.iterrows():\n",
    "        x = []\n",
    "        for i in row['tokens']:\n",
    "            crow+=1\n",
    "            for word in i:\n",
    "                if(word not in wordmodel):\n",
    "                    x.append([0]*300)\n",
    "                    \n",
    "                else:\n",
    "                    x.append(wordmodel[word])\n",
    "        #print(x)\n",
    "        x = np.array(x)\n",
    "        model_vector = (np.mean(x, axis=0)).tolist()\n",
    "        \n",
    "        #print('model',model_vector)\n",
    "        temp= np.mean(x, axis=0)\n",
    "        nv.append(temp)\n",
    "        if index == 0:\n",
    "            header = \",\".join(str(ele) for ele in range(300))\n",
    "            word2vec_file.write(header)\n",
    "            word2vec_file.write(\"\\n\")\n",
    "        # Check if the line exists else it is vector of zeros\n",
    "        if type(model_vector) is list:  \n",
    "            count+=1\n",
    "            line1 = \",\".join( [str(vector_element) for vector_element in model_vector] )\n",
    "        else:\n",
    "            cat+=1\n",
    "            line1 = \",\".join([str(0) for i in range(300)])\n",
    "        word2vec_file.write(line1)\n",
    "        word2vec_file.write('\\n')\n",
    "        v+=1\n",
    "    nv = np.array(nv)\n",
    "    print(nv.shape)\n",
    "    print(count,crow,cat)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(160000,)\n",
      "159907 4901039 93\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "source": [
    "print(len(wordmodel))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3000000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "source": [
    "x = []\n",
    "#print(\"Initial dataframe size\" ,len(df_upsampled))\n",
    "for token in dataset1['tokens']:\n",
    "  vec = np.zeros(300)\n",
    "  count = 0\n",
    "  for word in token:\n",
    "    if(word not in My_model1.wv):\n",
    "      continue\n",
    "    vec+= My_model1.wv[word]\n",
    "    count +=1\n",
    "  if (count!=0):\n",
    "    vec/=count\n",
    "  x.append(vec)\n",
    "print(\"Number of training rows: \",len(x))\n",
    "print(\"Sample row \" , x[0] , x[0].shape);"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of training rows:  200000\n",
      "Sample row  [-1.26308737e-01  9.31984541e-02 -4.02358251e-02  4.01177260e-01\n",
      " -1.92499325e-01 -6.44479585e-02  5.25028230e-01  3.29042014e-01\n",
      "  8.63918015e-02  5.30645285e-01 -4.58126972e-03 -5.89273982e-01\n",
      " -1.82362715e-01 -1.98464125e-01  8.91880034e-02 -4.32597887e-03\n",
      "  6.83399041e-02  2.22296318e-02  5.04428156e-01 -3.70796870e-02\n",
      " -1.66770067e-01 -2.41881933e-02  5.54798702e-02  2.58344361e-01\n",
      "  1.22011755e-01  2.16496863e-01 -1.43374175e-01 -8.18108280e-02\n",
      "  1.59351431e-01 -5.11149345e-01  3.42937236e-01  6.17775917e-02\n",
      " -2.09414740e-01 -3.20789389e-01 -3.27622422e-01 -2.94239262e-01\n",
      "  3.05031479e-01  7.02270924e-02 -3.44554258e-02  5.51369905e-01\n",
      " -1.80781800e-01 -5.00811617e-01 -2.64783752e-01  2.85016772e-01\n",
      " -1.71115822e-01 -8.01587634e-02 -1.39432037e-01 -2.76980186e-02\n",
      "  1.21737435e-01  3.77202226e-01  1.25815186e-01  4.20883884e-03\n",
      "  1.75288504e-02 -1.90090255e-02  1.34493092e-01  1.40602888e-01\n",
      " -1.66724124e-01 -4.64197844e-01 -1.27871346e-01  2.69484780e-01\n",
      " -2.30531133e-01  5.41131236e-02 -2.98892666e-01 -1.21774690e-01\n",
      "  3.56754843e-01 -3.11566346e-01 -2.19330563e-01 -3.98030078e-02\n",
      " -2.50773203e-01  3.05161036e-01 -4.67695332e-02  8.40942925e-02\n",
      "  4.33320449e-02 -5.34432820e-01  1.64909351e-02  4.41719334e-01\n",
      " -2.66313436e-01  1.03574509e-01  1.95669824e-01  1.76121471e-01\n",
      " -5.24519396e-01 -2.89374064e-01  5.94382371e-01  2.55533654e-01\n",
      "  2.33393643e-01 -1.23568065e-01 -6.33752823e-01  2.37741531e-01\n",
      "  1.75622618e-01  3.60701213e-01  7.42510751e-03  4.74425632e-02\n",
      "  1.18161051e-01  2.07968021e-01 -2.42084314e-01  1.29672157e-01\n",
      " -1.02919188e-01  5.06309177e-02 -8.22139761e-01  5.18220330e-01\n",
      "  1.63381940e-01 -3.51140334e-01  3.93231586e-01  4.89243742e-01\n",
      "  2.50995242e-01 -3.02642397e-01 -2.00318454e-01  6.55249855e-01\n",
      " -2.06930010e-01 -5.87448453e-01 -3.28210252e-01  3.25542294e-01\n",
      "  2.56596113e-01 -2.23987362e-01 -4.60747827e-01  2.33842195e-01\n",
      "  6.63568702e-01  3.59716828e-01 -3.33830865e-01  4.76942982e-01\n",
      " -4.70954094e-02 -9.99251525e-02 -1.24936447e-01 -2.63426629e-01\n",
      "  5.68161008e-01 -7.19638235e-01 -1.98712811e-01  5.27692644e-01\n",
      "  2.28863150e-01  5.92686051e-02 -3.02549485e-01 -1.52597944e-01\n",
      "  1.64559836e-01  7.25402612e-01 -5.04522733e-01 -4.90051223e-01\n",
      " -1.25289489e-01  7.31406995e-02 -2.12386154e-01  4.31395207e-01\n",
      "  6.29812046e-02  4.19704031e-02  6.67467422e-01  1.89266810e-01\n",
      " -7.49215303e-04 -4.59991427e-03 -3.47547266e-01  3.90954556e-01\n",
      " -1.02316117e-01  3.33676441e-01 -1.21146417e-01  1.25508659e-01\n",
      " -5.82219762e-01 -1.69100699e-01  6.13761291e-02 -3.60977921e-01\n",
      "  9.48664494e-02  6.82994277e-03  4.69469559e-01  1.06453772e-01\n",
      " -1.00956738e-01 -3.62428025e-02  8.79339042e-02  3.94654652e-02\n",
      "  5.14654747e-01 -2.30591780e-01 -7.49406502e-02  1.91285576e-01\n",
      "  9.02385076e-02  2.13799509e-01 -1.00205323e-01 -2.96663823e-01\n",
      " -3.99943661e-01 -6.84016330e-01 -2.39122037e-01 -9.83637335e-02\n",
      "  6.86956906e-01 -2.12060029e-01 -3.63921843e-01  1.69935423e-01\n",
      " -2.25194811e-01  8.78983144e-02  2.68184898e-01 -2.46590652e-01\n",
      "  2.63825994e-02 -3.15071740e-01 -2.57561566e-01 -3.81497219e-01\n",
      " -3.58252814e-02  1.69874188e-01  1.27727497e-02  4.19254965e-01\n",
      " -2.37947166e-01 -1.53777326e-01  2.44603729e-01 -3.78871928e-02\n",
      " -1.21174434e-01 -1.56849812e-01  1.89461350e-01  1.95738223e-01\n",
      " -1.80637685e-01  5.63865503e-01  1.92653156e-01 -2.73208407e-02\n",
      "  1.35503710e-01  5.29959622e-01 -3.73199416e-02 -2.00009716e-01\n",
      "  2.20424669e-01  3.26891411e-01  2.50422578e-01  3.49769327e-01\n",
      " -7.75788731e-02 -5.53716969e-01 -9.48612804e-02  1.76638587e-01\n",
      "  3.26671367e-01  8.81479853e-02  6.13952390e-02 -3.84402322e-01\n",
      " -3.15548555e-01 -2.84917593e-01  5.77471697e-02  3.47896552e-01\n",
      " -1.52402153e-01  1.22017611e-01 -1.77473053e-01  7.66212274e-01\n",
      "  3.78250255e-01  1.07663610e-01  1.82306434e-01 -2.46653386e-01\n",
      " -2.09163304e-01 -2.82844377e-01  4.45056867e-01 -3.90779493e-01\n",
      " -1.63244812e-01  2.54230771e-01  1.09216519e-01 -2.15994135e-01\n",
      " -2.58393252e-01  3.56826393e-01  1.10042956e-01 -1.25245212e-01\n",
      " -1.09938646e-01  3.25554500e-02  2.63277878e-02  4.57449881e-01\n",
      " -5.92759729e-01 -3.58424740e-01 -1.27638798e-02 -1.05090175e-01\n",
      " -1.76306477e-01  4.56825895e-01  6.25770806e-02 -5.38571243e-01\n",
      "  2.23042581e-01  2.44935075e-01 -1.70007041e-01  4.90551542e-01\n",
      " -2.14736054e-01 -2.15671328e-01 -2.04923853e-01  3.51349370e-01\n",
      "  1.63930696e-01  4.03333493e-02 -6.79046091e-01 -1.66741866e-01\n",
      "  5.78294287e-01 -6.84805200e-02  1.86971732e-01  6.12963794e-02\n",
      " -1.20724123e-01 -8.57286196e-02  1.72884221e-01 -4.99656483e-01\n",
      "  1.50730025e-01 -4.44931097e-01  6.20120309e-01  3.19730722e-02\n",
      "  4.08604487e-01  2.10786979e-01  4.57118837e-01  1.32028679e-01\n",
      " -2.39983075e-01 -3.39675018e-01  1.98188523e-01 -1.18663261e-01\n",
      " -2.06038007e-01 -2.55488935e-01 -5.67214271e-02 -2.55231940e-01\n",
      "  6.42706451e-01  1.21708382e-01  1.56767834e-02  6.29054906e-01\n",
      " -4.18257046e-01 -5.81659164e-02  1.50123580e-01  2.43194804e-01] (300,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "y = dataset1['class']\n",
    "y.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(200000,)"
      ]
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "source": [
    "# Splitting the data into train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, train_size=0.8,test_size=0.2,random_state=100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "p = Perceptron(random_state=4,max_iter=10000000, tol = 0.0001)\n",
    "p.fit(x_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Perceptron(max_iter=10000000, random_state=4, tol=0.0001)"
      ]
     },
     "metadata": {},
     "execution_count": 144
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "print(nv)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[array([ 0.073504  , -0.05910097,  0.0472167 ,  0.04541981, -0.17202498,\n",
      "        -0.24774246,  0.19701886,  0.33202492,  0.06303625,  0.20254863,\n",
      "         0.14343267,  0.05175706,  0.17675396, -0.00241221,  0.12386493,\n",
      "        -0.17118656, -0.03299934,  0.02526745,  0.06685463, -0.03767918,\n",
      "         0.13376742,  0.04661358, -0.29549691, -0.10193627,  0.49662612,\n",
      "        -0.00315734,  0.11025718,  0.11982211, -0.23187412, -0.05197921,\n",
      "         0.14354435, -0.15208652,  0.10201634, -0.04137455,  0.19392552,\n",
      "         0.09266667,  0.16606652,  0.12612396,  0.10244258,  0.02827034,\n",
      "        -0.31879349, -0.17077401, -0.45359932,  0.05739098, -0.28321992,\n",
      "        -0.04824089, -0.08953074,  0.18674519, -0.2685397 ,  0.10401432,\n",
      "        -0.21621488,  0.08359378, -0.11051077,  0.04534454,  0.18161493,\n",
      "         0.19106722,  0.00926939,  0.17199244,  0.09518068,  0.34452219,\n",
      "         0.172559  ,  0.21139665, -0.34945301, -0.0398066 ,  0.3384888 ,\n",
      "        -0.03415529,  0.0575885 , -0.16642055, -0.15948341,  0.14641814,\n",
      "         0.10358985,  0.00606292,  0.04822185, -0.2769853 ,  0.4270073 ,\n",
      "         0.11665604, -0.09391671, -0.05541795, -0.07095394,  0.13721995,\n",
      "        -0.13589521, -0.0717133 ,  0.28508418,  0.12573529,  0.19240707,\n",
      "         0.07358642, -0.25425267,  0.23545915, -0.03801447,  0.12472816,\n",
      "        -0.16226655, -0.18661856,  0.27361944,  0.04103697, -0.25385398,\n",
      "         0.1795253 ,  0.0533504 , -0.22162044, -0.1123662 ,  0.18149777,\n",
      "         0.02979384,  0.04584507,  0.05833132,  0.15335252,  0.22181358,\n",
      "        -0.13543607,  0.12888126,  0.18242741, -0.04438475, -0.03412845,\n",
      "        -0.05231987, -0.09295643, -0.03441991,  0.05773768, -0.13235957,\n",
      "        -0.0362226 ,  0.25563404, -0.09426351, -0.20890078, -0.06496654,\n",
      "         0.13746893, -0.0574024 ,  0.03390778, -0.18015626,  0.38773525,\n",
      "        -0.00733835, -0.09002903, -0.16575734, -0.09532688, -0.2547159 ,\n",
      "        -0.06238013,  0.01240931, -0.01891109, -0.00212267,  0.09618269,\n",
      "        -0.10266359, -0.0860876 , -0.10969607, -0.12409743, -0.12865076,\n",
      "        -0.0576504 , -0.03427729,  0.19225251,  0.07710036,  0.15077821,\n",
      "         0.11078928, -0.0188112 ,  0.23333061, -0.01087546, -0.04298847,\n",
      "        -0.06580641, -0.24150911, -0.54320286, -0.15424491,  0.1342465 ,\n",
      "        -0.21721689, -0.20684943, -0.02272775,  0.17737534,  0.09172343,\n",
      "        -0.1064919 , -0.15140475, -0.03252823,  0.24812651,  0.11495623,\n",
      "         0.18180465, -0.17594532, -0.06577598,  0.10129921,  0.30889979,\n",
      "        -0.15892065,  0.11752057,  0.37728842, -0.36805527, -0.23588245,\n",
      "        -0.176324  ,  0.32026878, -0.1507728 ,  0.00566199, -0.0511775 ,\n",
      "        -0.00483766, -0.03505973, -0.05117216, -0.27719603,  0.05877826,\n",
      "        -0.12285062, -0.02913491, -0.10722772,  0.07464468, -0.21859468,\n",
      "         0.12021454, -0.08142418, -0.1642632 ,  0.03925331,  0.28802611,\n",
      "        -0.22688531, -0.2071327 ,  0.06181796,  0.55528098, -0.20420403,\n",
      "        -0.26085905,  0.40879824, -0.0878854 , -0.13137076,  0.07841045,\n",
      "         0.30889736,  0.10906601,  0.14327313,  0.06584977,  0.05963448,\n",
      "        -0.11218092,  0.22333886, -0.28612597, -0.16262313,  0.0830158 ,\n",
      "         0.06420082,  0.2342697 , -0.38327015, -0.41656932, -0.19346004,\n",
      "        -0.08512019,  0.16885006,  0.01487169, -0.14101247, -0.01188235,\n",
      "        -0.36795336,  0.16211643,  0.07141818, -0.08777723,  0.11328863,\n",
      "         0.4231958 , -0.09977922, -0.11025285,  0.10358341, -0.15378233,\n",
      "         0.09591952, -0.13737421, -0.019225  , -0.04744467, -0.36319933,\n",
      "         0.01259064, -0.09545546, -0.05489042, -0.21038222,  0.07588052,\n",
      "        -0.27012926, -0.01695664, -0.09054187,  0.01436037,  0.14341183,\n",
      "        -0.14727672, -0.03212241, -0.00967618,  0.00213323, -0.11239965,\n",
      "        -0.15347414,  0.32063117, -0.13503898, -0.24507982,  0.04687817,\n",
      "         0.14439485,  0.24904464, -0.00910379, -0.16219563, -0.2132376 ,\n",
      "        -0.21907808,  0.05997516,  0.28803809, -0.02484545, -0.27884598,\n",
      "         0.03159955,  0.04726757,  0.03484147,  0.07138922,  0.51317249,\n",
      "        -0.0909131 ,  0.31067392, -0.0090444 , -0.02461849, -0.19803041,\n",
      "         0.31085979, -0.09002545, -0.06985905,  0.32370441, -0.41142721,\n",
      "        -0.09431203, -0.40571075, -0.40919687,  0.0074504 ,  0.12462404,\n",
      "        -0.56989924,  0.27637544,  0.697108  ,  0.14681   ,  0.42815286,\n",
      "         0.52219662, -0.09260886, -0.31999879, -0.01569807, -0.23511772])\n",
      " array([-0.09559048,  0.07592674,  0.04713829,  0.06802606, -0.2010194 ,\n",
      "        -0.3082846 ,  0.20665751,  0.28567313,  0.06035494,  0.18075981,\n",
      "         0.07502726,  0.00769935,  0.18361079, -0.04287872,  0.05299504,\n",
      "        -0.23030099, -0.06219135,  0.0419597 ,  0.1042785 , -0.05865766,\n",
      "         0.13904408,  0.1531152 , -0.30099655, -0.16522953,  0.47248254,\n",
      "         0.02814258,  0.07358941,  0.14246621, -0.29308902, -0.12109246,\n",
      "         0.17271126, -0.03303151,  0.12646034, -0.00187797,  0.27066954,\n",
      "         0.13491542,  0.24064698,  0.03698134, -0.03764543, -0.15028392,\n",
      "        -0.32249402, -0.11802075, -0.35564062,  0.06056999, -0.26553262,\n",
      "        -0.03612951, -0.14822228,  0.19773584, -0.3503018 ,  0.15619106,\n",
      "        -0.22627516,  0.13262187, -0.06889988,  0.00569294,  0.12354831,\n",
      "         0.21235512,  0.00600939,  0.12203168,  0.08504684,  0.27180795,\n",
      "         0.06306107,  0.17973667, -0.41991851, -0.03064656,  0.29320655,\n",
      "        -0.01398328, -0.00410705, -0.11280874, -0.15435104,  0.08793963,\n",
      "        -0.10760168, -0.03578418,  0.06286378, -0.25225888,  0.39179652,\n",
      "         0.15083372, -0.11406394, -0.09208549, -0.08688649,  0.10651798,\n",
      "        -0.11972115, -0.10823168,  0.24172009,  0.09121716,  0.18313221,\n",
      "         0.01223679, -0.19415528,  0.07817283,  0.05468351,  0.21190086,\n",
      "        -0.14942066, -0.14999966,  0.25736488,  0.12553052, -0.285941  ,\n",
      "         0.23807817,  0.0653042 , -0.13807403, -0.12170284,  0.09837171,\n",
      "        -0.03144542,  0.01595866,  0.05398624,  0.12452896,  0.15579439,\n",
      "        -0.05617334,  0.1851946 ,  0.23953484,  0.02448156, -0.05999378,\n",
      "        -0.1023014 , -0.16669872, -0.12112726, -0.0035657 , -0.20658992,\n",
      "         0.07333365,  0.2831887 , -0.16420943, -0.17909576, -0.04469939,\n",
      "         0.01155589, -0.23233741, -0.01021623, -0.17208016,  0.18623904,\n",
      "        -0.03458256, -0.1013832 , -0.14928345, -0.15668701, -0.27748231,\n",
      "        -0.07242528,  0.10923952, -0.07097683, -0.03646984,  0.14956573,\n",
      "        -0.2567822 , -0.04738489, -0.10215068, -0.09322824, -0.12458676,\n",
      "         0.05930198, -0.0121572 ,  0.2172944 ,  0.09030888,  0.11330261,\n",
      "         0.06299109, -0.10192303,  0.32931895,  0.02369549, -0.07562463,\n",
      "        -0.02221246, -0.17379539, -0.56794647, -0.18481878,  0.06732562,\n",
      "        -0.3350998 , -0.3395027 ,  0.01926577,  0.20395873,  0.1516878 ,\n",
      "        -0.14999326,  0.05059184,  0.02122324,  0.20583661,  0.10381133,\n",
      "         0.14231378, -0.20357447, -0.06590546,  0.08516194,  0.37815278,\n",
      "        -0.08780898,  0.06390878,  0.43640897, -0.31759792, -0.23851649,\n",
      "        -0.17852884,  0.37794207, -0.10297362, -0.00814534, -0.02096895,\n",
      "        -0.02563457, -0.0434892 , -0.05498143, -0.26271496,  0.10357879,\n",
      "        -0.14306676, -0.03366663,  0.01263442,  0.03229835, -0.16393293,\n",
      "         0.21526358, -0.04154719, -0.10341114,  0.08346622,  0.26752885,\n",
      "        -0.16939202, -0.12140295,  0.08382664,  0.5837607 , -0.18898797,\n",
      "        -0.2920414 ,  0.44452899, -0.11013795, -0.18159352,  0.06097174,\n",
      "         0.23763743,  0.20318537,  0.05968487,  0.03093735, -0.05669667,\n",
      "        -0.0133737 ,  0.2815011 , -0.24572133, -0.19897189,  0.08581617,\n",
      "         0.00395831,  0.27223586, -0.45060883, -0.29405952, -0.15961895,\n",
      "        -0.03670419,  0.17825827,  0.17025569, -0.14999873, -0.07183196,\n",
      "        -0.37914101,  0.13527675,  0.08956191, -0.12696862,  0.11673498,\n",
      "         0.52695156,  0.0107321 , -0.11124967,  0.02725941, -0.21324223,\n",
      "         0.22886271, -0.09834228, -0.0514736 , -0.05725628, -0.52912383,\n",
      "        -0.00509101, -0.23139212,  0.00262911, -0.22338665,  0.01690305,\n",
      "        -0.14603415,  0.04292029, -0.06464193, -0.03730634,  0.20457358,\n",
      "        -0.06048397,  0.04399945, -0.07712607,  0.11231448, -0.03738817,\n",
      "        -0.16095864,  0.32680234, -0.18284489, -0.268237  ,  0.02927993,\n",
      "         0.15427145,  0.33901649, -0.02764146, -0.1034356 , -0.14902192,\n",
      "        -0.13791203,  0.02987119,  0.24899818, -0.0746145 , -0.12251088,\n",
      "        -0.00970147,  0.17728015,  0.10381055,  0.08461853,  0.46855275,\n",
      "        -0.1235101 ,  0.27770398, -0.00350308, -0.00127727, -0.16855067,\n",
      "         0.35866508, -0.09663278, -0.02874671,  0.35702025, -0.42915384,\n",
      "        -0.13734399, -0.42050957, -0.30403432, -0.11630738,  0.13735468,\n",
      "        -0.34518015,  0.34139288,  0.73390771,  0.02177536,  0.41434445,\n",
      "         0.50671429, -0.23545625, -0.32981137, -0.07129135, -0.07217623])\n",
      " array([-7.95476383e-02,  5.47372675e-02,  2.05641169e-02,  1.69223596e-02,\n",
      "        -2.02651066e-01, -3.05707404e-01,  1.02480552e-01,  3.32155315e-01,\n",
      "         1.05165536e-01,  9.40806511e-02,  8.88669321e-02, -7.50695294e-03,\n",
      "         1.41192009e-01,  3.53789740e-02,  1.90682472e-02, -2.34098634e-01,\n",
      "        -1.89049057e-02,  6.22842509e-02,  1.65505088e-01, -2.23611195e-03,\n",
      "         1.12884996e-01,  1.56861974e-01, -2.35641175e-01, -1.10932648e-01,\n",
      "         4.58807673e-01,  4.18332133e-02,  1.61321705e-02,  1.58765133e-01,\n",
      "        -3.74577905e-01, -9.83405777e-02,  1.50588289e-01, -2.93995798e-02,\n",
      "         1.23429933e-01,  1.35863883e-01,  2.71641590e-01,  1.96492008e-01,\n",
      "         2.23900419e-01, -8.19728049e-02, -5.38905205e-02, -1.40300401e-01,\n",
      "        -2.87457907e-01, -8.65009607e-02, -3.37631657e-01, -5.92185903e-03,\n",
      "        -1.75088283e-01, -4.69638182e-02, -1.10003592e-01,  1.84197183e-01,\n",
      "        -3.15285163e-01,  1.43754288e-01, -1.76706129e-01,  5.92557368e-02,\n",
      "        -3.33110933e-02,  4.34089431e-02,  1.09358134e-01,  1.55987814e-01,\n",
      "        -4.00483786e-02,  1.47623111e-01,  9.74551496e-02,  3.40872120e-01,\n",
      "         5.31977369e-02,  1.24609815e-01, -3.67439311e-01, -1.81349571e-05,\n",
      "         2.14642441e-01,  2.14219013e-02, -8.14952954e-03, -1.80871188e-01,\n",
      "        -1.70824902e-01,  1.11947614e-01, -1.28196540e-01,  1.43359916e-02,\n",
      "         7.75621716e-02, -2.80929930e-01,  2.78116827e-01,  1.48029705e-01,\n",
      "        -1.49295905e-01,  1.03675833e-02,  7.18979763e-03,  5.78027005e-02,\n",
      "        -9.31730884e-02, -1.39832645e-01,  1.56260444e-01,  7.42913673e-02,\n",
      "         1.65054369e-01,  5.69833714e-02, -2.00054932e-01,  1.08916995e-02,\n",
      "         8.13938729e-02,  1.93241166e-01, -1.20121586e-01, -6.44851137e-02,\n",
      "         2.47908954e-01,  7.14039738e-02, -2.69490647e-01,  1.23406038e-01,\n",
      "         7.64181157e-02, -1.40028530e-01, -2.07139948e-02,  7.60605033e-02,\n",
      "         1.30403129e-03,  1.36418402e-01,  2.14990441e-02,  5.71343767e-02,\n",
      "         1.84875330e-01, -5.67422946e-02,  1.22416494e-01,  2.23565446e-01,\n",
      "        -6.26703103e-02,  5.76490071e-02, -1.07255036e-01, -2.22559125e-01,\n",
      "        -1.63798912e-01,  1.40483374e-03, -1.26466068e-01,  1.14459545e-01,\n",
      "         2.04647498e-01, -1.64114098e-01, -1.08075013e-01, -6.46574070e-02,\n",
      "         3.34415130e-02, -1.24601914e-01, -5.10856521e-02, -1.39746990e-01,\n",
      "         1.02234847e-01, -1.17145222e-01, -1.23988725e-01, -2.06329484e-01,\n",
      "        -1.70208820e-01, -2.38189685e-01, -4.85405334e-02,  1.35883566e-01,\n",
      "        -8.91497764e-02, -3.40455970e-02,  1.75661625e-01, -1.87099588e-01,\n",
      "         7.48861828e-03, -9.15982662e-02, -7.67242306e-02, -1.45568892e-01,\n",
      "         1.36241482e-02, -1.64575210e-02,  9.72532129e-02,  9.08113084e-02,\n",
      "         1.19916265e-01,  7.81763037e-02, -7.68048037e-02,  3.30662361e-01,\n",
      "         4.31757001e-04, -1.19188520e-01, -3.99713078e-02, -1.29876634e-01,\n",
      "        -4.63093163e-01, -1.59913705e-01, -6.58892782e-04, -3.15485771e-01,\n",
      "        -2.93309631e-01, -1.64999407e-02,  2.06579116e-01,  2.29798356e-01,\n",
      "        -8.57076788e-02,  1.25711764e-01, -8.37341240e-02,  1.66738709e-01,\n",
      "         1.50196185e-01,  1.23909725e-01, -2.21797149e-01, -1.29811005e-01,\n",
      "         8.61038223e-02,  3.28744794e-01, -1.02969595e-02, -1.12336227e-02,\n",
      "         3.72329579e-01, -3.30622326e-01, -2.85219349e-01, -1.71380926e-01,\n",
      "         2.65554636e-01, -5.10505692e-02,  1.86477693e-02, -4.22551137e-02,\n",
      "        -3.47511869e-02, -2.77837761e-02, -1.46713329e-01, -2.34742982e-01,\n",
      "         5.48042049e-02, -9.14321176e-02, -2.81714738e-02, -3.17056246e-03,\n",
      "         6.40395314e-02, -2.38610909e-01,  1.29265727e-01, -3.01160799e-02,\n",
      "        -6.10923788e-02,  6.99464396e-02,  2.31395107e-01, -1.99432266e-01,\n",
      "        -1.05034571e-01,  5.45648908e-02,  5.91125082e-01, -2.45865475e-01,\n",
      "        -2.64850435e-01,  4.29864163e-01, -1.29696014e-01, -1.77062807e-01,\n",
      "         1.26907041e-01,  2.38074728e-01,  1.35540467e-01,  6.83520278e-02,\n",
      "        -2.22532700e-04,  4.25087320e-02, -4.24620216e-02,  2.31136279e-01,\n",
      "        -1.84622274e-01, -2.35490417e-01,  4.98595591e-02, -6.99457436e-02,\n",
      "         2.09041647e-01, -4.41439527e-01, -3.20646606e-01, -7.78722443e-02,\n",
      "         1.58177648e-03,  1.63617719e-01,  2.25592426e-01, -8.95021327e-02,\n",
      "        -1.20848381e-01, -3.49490881e-01,  1.15733593e-01,  9.74772930e-02,\n",
      "        -1.39909537e-01,  1.71344785e-01,  4.29531981e-01,  3.09102646e-02,\n",
      "        -1.21279814e-01, -6.96294227e-03, -1.76840425e-01,  1.89217771e-01,\n",
      "        -1.11712991e-01, -9.15501029e-02, -7.99686105e-02, -4.64406058e-01,\n",
      "         6.33802125e-02, -1.82735565e-01,  1.52193483e-02, -2.12594310e-01,\n",
      "         3.50635641e-02, -7.17886455e-02,  1.04616115e-02, -8.26084744e-02,\n",
      "        -6.20730687e-02,  1.80099426e-01, -7.78399617e-02,  1.30265672e-01,\n",
      "        -3.47619404e-02,  8.43079658e-02, -2.90305635e-02, -1.65584499e-01,\n",
      "         2.64867684e-01, -1.79476736e-01, -2.38528218e-01, -6.16229107e-02,\n",
      "         1.94859353e-01,  2.93674993e-01, -2.80522466e-02,  2.63300539e-03,\n",
      "        -1.13687122e-01, -6.26143980e-02,  6.32357861e-02,  1.59264534e-01,\n",
      "        -4.99812162e-02, -8.65760557e-02, -9.70338269e-02,  1.85299532e-01,\n",
      "         5.09728647e-03,  6.21665605e-02,  4.17805419e-01, -1.32168145e-01,\n",
      "         2.59900314e-01, -6.02614023e-04, -4.18376756e-02, -1.16266295e-01,\n",
      "         3.45551507e-01, -7.79782165e-02,  6.09261885e-03,  3.56310093e-01,\n",
      "        -3.56947778e-01, -1.45766062e-01, -4.40723933e-01, -2.22122971e-01,\n",
      "        -1.16778969e-01,  1.36111944e-01, -2.91561110e-01,  3.72376018e-01,\n",
      "         7.11754290e-01, -1.03731286e-02,  3.19346701e-01,  4.05300347e-01,\n",
      "        -1.97063050e-01, -2.83243558e-01, -2.61574134e-02, -3.03327288e-02])\n",
      " ...\n",
      " array([-0.07108266,  0.07104135,  0.06579871,  0.01533165, -0.17943166,\n",
      "        -0.32849008,  0.18754171,  0.28013706,  0.08655503,  0.09103835,\n",
      "         0.03932231, -0.01171795,  0.17618445,  0.00446465,  0.02722251,\n",
      "        -0.22711736, -0.0154853 ,  0.04864455,  0.09932096, -0.06384999,\n",
      "         0.08639833,  0.14048916, -0.26993293, -0.15081656,  0.40699828,\n",
      "         0.02546413,  0.04920731,  0.1730492 , -0.30542907, -0.15473092,\n",
      "         0.13706845, -0.06308261,  0.13372044,  0.0180717 ,  0.317619  ,\n",
      "         0.18037105,  0.28316557, -0.00477619, -0.07875627, -0.10459595,\n",
      "        -0.28309318, -0.07872326, -0.27329412,  0.00926818, -0.24011342,\n",
      "        -0.03441133, -0.11183338,  0.1472906 , -0.32558623,  0.15378977,\n",
      "        -0.18370159,  0.10752276, -0.08983701,  0.02698587,  0.11652216,\n",
      "         0.22983867,  0.02436126,  0.10376871,  0.10139631,  0.2792928 ,\n",
      "         0.11476608,  0.18951528, -0.3699535 ,  0.04222334,  0.23020086,\n",
      "        -0.00533031, -0.03598103, -0.14384364, -0.1138529 ,  0.06504146,\n",
      "        -0.13681388,  0.00435132,  0.06135225, -0.22208427,  0.34578913,\n",
      "         0.12620346, -0.09655949, -0.06013525,  0.00640189,  0.0881819 ,\n",
      "        -0.12528554, -0.1309656 ,  0.21534291,  0.08968778,  0.13447757,\n",
      "         0.04811629, -0.13571852,  0.04105755,  0.09369505,  0.19410476,\n",
      "        -0.10921238, -0.08143137,  0.25696793,  0.11639571, -0.21725039,\n",
      "         0.13565259,  0.02442943, -0.14056738, -0.10208573,  0.06963754,\n",
      "        -0.06241244,  0.06982434,  0.06875621,  0.07726279,  0.10443757,\n",
      "         0.01243825,  0.12935123,  0.22754298, -0.01531247, -0.03848526,\n",
      "        -0.08608731, -0.24720693, -0.08739466,  0.00073966, -0.19918978,\n",
      "         0.13865703,  0.29513398, -0.1862554 , -0.12613976, -0.05621228,\n",
      "        -0.00926713, -0.24913913, -0.04590255, -0.12499538,  0.13140875,\n",
      "        -0.03667882, -0.11009909, -0.16970263, -0.20620038, -0.29088053,\n",
      "        -0.07831498,  0.06963937, -0.06247396, -0.07875773,  0.11232686,\n",
      "        -0.2398397 , -0.04913335, -0.11872312, -0.03110664, -0.14825487,\n",
      "         0.0449068 , -0.04286309,  0.19681892,  0.06785545,  0.13014863,\n",
      "         0.00769865, -0.12025247,  0.36302453,  0.05543458, -0.1265831 ,\n",
      "        -0.02687618, -0.19204445, -0.5287661 , -0.18921562,  0.04378066,\n",
      "        -0.26725084, -0.37561667, -0.03898088,  0.20116875,  0.18540604,\n",
      "        -0.08019913,  0.124753  , -0.02281678,  0.21421652,  0.12564974,\n",
      "         0.14733955, -0.23949471, -0.09800474,  0.10346733,  0.36612043,\n",
      "        -0.01230804, -0.00214966,  0.39591342, -0.29567027, -0.19976525,\n",
      "        -0.12884338,  0.35957745, -0.08678272, -0.01590413, -0.0811903 ,\n",
      "        -0.00806555,  0.00356829, -0.06934343, -0.20385215,  0.08812408,\n",
      "        -0.15566365, -0.02278555,  0.04360568,  0.03965103, -0.21169241,\n",
      "         0.19222185, -0.05114252, -0.03699553,  0.10101096,  0.21956421,\n",
      "        -0.20798402, -0.03130608,  0.13643283,  0.5683732 , -0.26270938,\n",
      "        -0.2786211 ,  0.4043203 , -0.12197836, -0.17875426,  0.08753815,\n",
      "         0.24125242,  0.16875009,  0.11116407,  0.03346742, -0.06083047,\n",
      "        -0.01826585,  0.3249224 , -0.20541851, -0.1641854 ,  0.07105357,\n",
      "        -0.034734  ,  0.26104796, -0.46053496, -0.3129903 , -0.09867777,\n",
      "        -0.04742609,  0.19953585,  0.19752489, -0.14417079, -0.10305958,\n",
      "        -0.35547665,  0.1480039 ,  0.12275978, -0.16231747,  0.12329149,\n",
      "         0.49540314,  0.0084966 , -0.08185659,  0.01630723, -0.22958629,\n",
      "         0.21463344, -0.06591607, -0.09605785, -0.068682  , -0.52876335,\n",
      "        -0.01372769, -0.25212386, -0.03954486, -0.2381162 , -0.04210252,\n",
      "        -0.06418649,  0.02935989, -0.11094283, -0.03656055,  0.21923673,\n",
      "        -0.10566381,  0.04447784, -0.07572127,  0.10298149,  0.00381911,\n",
      "        -0.10326758,  0.26138973, -0.15220276, -0.2635915 , -0.01346852,\n",
      "         0.12632772,  0.33780798, -0.03647291, -0.0859056 , -0.12470771,\n",
      "        -0.13268812,  0.03557309,  0.2292058 , -0.13918917, -0.06324703,\n",
      "        -0.05310737,  0.21962605,  0.09091558,  0.05946843,  0.41789857,\n",
      "        -0.1265247 ,  0.2062129 , -0.03531715, -0.03186304, -0.12421817,\n",
      "         0.33112702, -0.09292882, -0.01137866,  0.33760062, -0.43498316,\n",
      "        -0.12498295, -0.44447127, -0.27378166, -0.16302131,  0.10883629,\n",
      "        -0.23534009,  0.34183046,  0.73317045,  0.04749401,  0.3507533 ,\n",
      "         0.49214286, -0.2820678 , -0.38121113, -0.08902865,  0.00980648],\n",
      "       dtype=float32)\n",
      " array([ 3.13979648e-02, -3.55629660e-02, -7.33273104e-02, -1.46140575e-01,\n",
      "        -2.10943207e-01, -3.49901050e-01,  1.27565831e-01,  2.52435088e-01,\n",
      "         1.67572081e-01,  1.10314347e-01,  5.85972406e-02, -1.38348108e-02,\n",
      "         1.85130373e-01, -4.79727015e-02,  5.87488264e-02, -4.24207807e-01,\n",
      "        -9.01098400e-02,  6.66968748e-02,  3.40413719e-01,  3.15442472e-03,\n",
      "         5.38557656e-02,  2.89854288e-01, -3.90692145e-01, -2.67394781e-01,\n",
      "         6.30055904e-01, -3.06906104e-02,  2.26062357e-01,  1.23214178e-01,\n",
      "        -4.21884447e-01, -2.77393311e-01,  1.88589901e-01, -1.10502534e-01,\n",
      "         1.46281391e-01,  1.08887345e-01,  4.10294533e-01,  1.79366112e-01,\n",
      "         4.02160168e-01, -7.57144615e-02, -5.52138910e-02, -1.56493083e-01,\n",
      "        -3.39456528e-01, -9.82378274e-02, -3.72331709e-01,  1.87899750e-02,\n",
      "        -1.92418486e-01,  3.15499417e-02, -1.59904391e-01,  2.22902119e-01,\n",
      "        -3.75318915e-01,  1.63561087e-02, -2.13068783e-01,  7.30203688e-02,\n",
      "         9.91013721e-02,  1.29223764e-01,  1.19513161e-02,  1.31374389e-01,\n",
      "         1.77024417e-02,  1.80873111e-01,  1.59544930e-01,  5.33355296e-01,\n",
      "         1.31769255e-01,  1.89789400e-01, -5.04210770e-01, -2.48103938e-03,\n",
      "         2.96108454e-01,  6.39414489e-02, -4.61889617e-02, -2.27072418e-01,\n",
      "        -2.44147360e-01,  1.30825266e-01, -3.67780387e-01,  3.99926566e-02,\n",
      "         4.99681868e-02, -4.22735959e-01,  4.18425202e-01,  2.14984074e-01,\n",
      "        -9.98851135e-02, -9.36029032e-02,  1.14921235e-01,  2.87725814e-02,\n",
      "        -1.51165932e-01, -5.64876795e-02,  3.47028524e-01,  4.58232127e-02,\n",
      "         1.82113588e-01,  1.09764345e-01, -5.67238927e-02, -5.19121252e-02,\n",
      "         1.20804854e-01,  3.27947080e-01, -1.59144610e-01, -3.13371606e-02,\n",
      "         2.65018642e-01,  2.87981272e-01, -3.73349071e-01,  1.39383495e-01,\n",
      "         4.70193056e-03, -2.29918495e-01, -7.46664479e-02,  1.20408654e-01,\n",
      "        -1.34097353e-01, -1.21214213e-02, -4.77899313e-02,  6.61343411e-02,\n",
      "         2.80227065e-01,  1.52653577e-02,  1.39954150e-01,  3.30824047e-01,\n",
      "        -4.77815904e-02,  1.39021516e-01, -5.67560308e-02, -2.47683674e-01,\n",
      "        -8.31369609e-02,  1.60088707e-02, -3.04284692e-01,  1.47416130e-01,\n",
      "         3.27174753e-01, -3.31319541e-01, -1.95267543e-01,  4.01348807e-02,\n",
      "         1.98999550e-02, -2.67730534e-01, -2.24362630e-02, -1.13187268e-01,\n",
      "         2.59072840e-01, -1.29092678e-01, -1.43865004e-01, -2.06457868e-01,\n",
      "        -2.98536181e-01, -4.39057231e-01,  1.06463939e-01,  1.21674187e-01,\n",
      "        -1.16053127e-01,  4.29943837e-02,  2.86756158e-01, -4.63356584e-01,\n",
      "        -7.48434737e-02, -1.28655970e-01, -1.02405936e-01, -8.17145556e-02,\n",
      "        -5.28240837e-02,  1.93798225e-02,  2.36823335e-02, -2.78813462e-03,\n",
      "         1.96488440e-01,  2.09278002e-01, -5.76661667e-03,  6.46682203e-01,\n",
      "        -7.82809332e-02, -2.94401765e-01, -9.08335671e-03, -1.12217002e-01,\n",
      "        -4.82252896e-01, -1.45130455e-02, -3.97408642e-02, -4.30451304e-01,\n",
      "        -3.75214964e-01,  8.67727399e-02,  2.00093493e-01,  2.33086884e-01,\n",
      "        -3.73766501e-03,  1.76154122e-01,  3.74957174e-02,  2.92093664e-01,\n",
      "         2.13585988e-01, -5.48477331e-03, -2.18158662e-01, -8.89976919e-02,\n",
      "         8.50139335e-02,  2.29302987e-01,  6.28499687e-02, -1.17642306e-01,\n",
      "         4.53389555e-01, -5.07182837e-01, -3.21346790e-01, -1.76984504e-01,\n",
      "         3.95343184e-01,  7.62490258e-02, -5.68649657e-02, -3.00227571e-02,\n",
      "         6.68247268e-02, -2.28604022e-02, -1.98296547e-01, -3.28276038e-01,\n",
      "         1.87630713e-01, -1.01945765e-01, -5.53176999e-02, -6.70317113e-02,\n",
      "        -3.09434962e-02, -2.76380599e-01,  3.00886601e-01,  1.52018607e-01,\n",
      "        -1.77406773e-01,  1.36778057e-01,  1.84928119e-01, -1.70629710e-01,\n",
      "        -1.78677440e-01,  6.23712316e-02,  7.74006844e-01, -2.44214162e-01,\n",
      "        -2.21889839e-01,  5.26653528e-01, -1.66846052e-01, -3.54580224e-01,\n",
      "         4.50105071e-02,  4.00283039e-01,  3.98886427e-02,  1.28198877e-01,\n",
      "        -3.99215706e-03,  1.01566821e-01, -8.81323889e-02,  2.89122552e-01,\n",
      "        -2.08015680e-01, -2.77925700e-01, -4.25245962e-04, -7.91918263e-02,\n",
      "         2.67586499e-01, -8.02377939e-01, -3.91421884e-01, -9.87613872e-02,\n",
      "        -5.74762970e-02,  2.26586401e-01,  2.01788902e-01, -1.07255109e-01,\n",
      "        -8.70349631e-02, -4.55919772e-01,  1.16363652e-01,  1.53263748e-01,\n",
      "        -1.00857779e-01,  2.49344960e-01,  5.06287456e-01,  1.88460574e-01,\n",
      "        -3.04775029e-01,  7.90232942e-02, -2.83042610e-01,  3.18775922e-01,\n",
      "        -9.58715230e-02, -4.92916703e-02, -1.10124730e-01, -6.28097653e-01,\n",
      "         1.38985112e-01, -3.05166751e-01, -1.02253268e-02, -2.84981638e-01,\n",
      "         7.31282905e-02, -3.56493592e-02, -8.96666944e-02, -1.13096148e-01,\n",
      "         3.06019355e-02,  3.92864674e-01, -2.02812374e-01,  2.25172862e-01,\n",
      "        -6.65371343e-02,  1.77582130e-01, -9.90106724e-03, -2.60614514e-01,\n",
      "         4.63443309e-01, -1.53392017e-01, -2.71667987e-01, -2.24528700e-01,\n",
      "         2.17682257e-01,  2.93869942e-01,  5.29936589e-02, -1.14667753e-03,\n",
      "        -6.23447858e-02, -1.37248456e-01, -2.22196244e-02,  1.59695745e-01,\n",
      "         8.70748088e-02, -1.38907224e-01, -1.18263371e-01,  3.16064298e-01,\n",
      "        -2.09058095e-02,  6.52508065e-02,  5.05136251e-01, -1.76303357e-01,\n",
      "         2.37787902e-01, -2.73607243e-02,  1.44833192e-01, -1.48828253e-01,\n",
      "         3.77744675e-01, -6.41447231e-02, -8.24159980e-02,  5.89836717e-01,\n",
      "        -4.67603028e-01, -2.61312395e-01, -5.49093485e-01, -3.29520494e-01,\n",
      "        -1.35407388e-01,  2.17152819e-01, -3.00406754e-01,  5.00437319e-01,\n",
      "         9.62730169e-01,  8.88346285e-02,  4.41206664e-01,  6.76902533e-01,\n",
      "        -3.13955903e-01, -3.12767208e-01, -3.30190435e-02,  4.45044041e-02],\n",
      "       dtype=float32)\n",
      " array([-1.06654542e-01,  3.62683416e-02,  9.22593303e-03,  1.81013436e-02,\n",
      "        -1.94915476e-01, -3.18379003e-01,  1.40398140e-01,  2.48874829e-01,\n",
      "         4.40773808e-02,  1.35095041e-01,  6.82749094e-02, -5.48660841e-02,\n",
      "         1.64185697e-01, -9.47230650e-02,  3.98555054e-02, -2.94990418e-01,\n",
      "        -6.09330084e-02,  4.91313934e-02,  1.74923298e-01, -1.66412454e-02,\n",
      "         3.60755182e-02,  1.73770798e-01, -2.42744836e-01, -2.04484012e-01,\n",
      "         4.75358330e-01,  3.56379899e-02,  1.08185775e-01,  9.82897365e-02,\n",
      "        -3.07864521e-01, -1.83052428e-01,  1.39543176e-01, -7.26327855e-02,\n",
      "         1.30585724e-01,  3.51678940e-02,  3.06215022e-01,  1.22036160e-01,\n",
      "         2.42014185e-01,  3.08076224e-02, -3.12395953e-04, -2.66673448e-02,\n",
      "        -2.82438271e-01, -1.40674565e-01, -3.83786560e-01, -1.21209107e-02,\n",
      "        -1.69125012e-01,  3.25516814e-02, -1.34660462e-01,  1.77520791e-01,\n",
      "        -3.89107283e-01,  1.16153933e-01, -2.27690063e-01,  1.21059947e-01,\n",
      "         2.91832770e-02,  4.99034063e-02,  6.10771183e-02,  1.60060772e-01,\n",
      "         3.69464396e-02,  1.23710397e-01,  5.91454694e-02,  3.97681279e-01,\n",
      "         8.18265083e-02,  1.62730357e-01, -3.84435025e-01, -9.82416253e-02,\n",
      "         3.08733020e-01, -1.90517083e-02, -3.98827250e-02, -1.11754589e-01,\n",
      "        -2.06851403e-01,  1.59284608e-01, -1.48384014e-01, -1.29830379e-02,\n",
      "         4.32849660e-02, -3.28317283e-01,  3.33388974e-01,  1.95873384e-01,\n",
      "        -1.04276712e-01, -9.09323076e-02, -7.13701816e-02,  9.19655036e-02,\n",
      "        -1.63586650e-01, -4.15555187e-02,  2.57557270e-01,  8.45995063e-02,\n",
      "         1.21296412e-01,  6.35607201e-02, -1.59214841e-01,  4.66447165e-02,\n",
      "         3.88367900e-02,  2.10211005e-01, -1.41231620e-01, -1.41681641e-01,\n",
      "         2.46861459e-01,  1.73327711e-01, -2.71889404e-01,  1.57967340e-01,\n",
      "         1.07021192e-01, -1.68061574e-01, -1.92673457e-01,  1.47175103e-01,\n",
      "        -2.13114777e-02,  4.06674067e-02, -5.57303722e-03,  8.32245629e-02,\n",
      "         2.27068946e-01, -8.16398268e-02,  1.08022017e-01,  2.34108750e-01,\n",
      "         1.28920316e-02,  2.82359282e-02, -4.28107415e-02, -2.10238904e-01,\n",
      "        -4.18056481e-02,  5.46203917e-03, -1.95071802e-01,  1.14841600e-01,\n",
      "         2.20029979e-01, -2.01387952e-01, -1.41660537e-01, -3.29949140e-03,\n",
      "         2.39789156e-02, -1.44096632e-01, -1.32761451e-02, -1.46326656e-01,\n",
      "         1.68486282e-01, -1.28971818e-01, -1.07241153e-01, -1.73949109e-01,\n",
      "        -2.03225659e-01, -3.01735051e-01,  4.97690073e-02,  1.03075339e-01,\n",
      "        -1.29493439e-01, -2.07799663e-02,  2.12366185e-01, -2.71183883e-01,\n",
      "        -2.52165204e-02, -6.94114858e-02, -1.31760644e-01, -3.97013733e-02,\n",
      "        -2.02695915e-02,  2.46666572e-02,  9.30080007e-02, -1.60066574e-02,\n",
      "         1.41122353e-01,  1.15874696e-01, -5.03505764e-02,  4.06733016e-01,\n",
      "         2.03092188e-02, -8.26745350e-02, -2.30427621e-02, -1.47946255e-01,\n",
      "        -3.82609251e-01, -6.48421973e-02, -2.80464344e-02, -3.20962296e-01,\n",
      "        -2.80185043e-01, -1.03044259e-02,  1.64711449e-01,  1.45600631e-01,\n",
      "        -9.41820107e-03,  2.83105679e-02,  6.22651882e-02,  2.51963090e-01,\n",
      "         1.29691402e-01,  7.00750624e-02, -1.43783364e-01, -6.14736191e-02,\n",
      "         9.25854434e-02,  3.18549431e-01, -5.56630039e-02, -2.86182752e-02,\n",
      "         3.57094457e-01, -3.76516896e-01, -2.41123280e-01, -1.97269177e-01,\n",
      "         3.22294453e-01, -6.79658941e-02, -2.47859424e-02, -1.34067766e-03,\n",
      "         5.54323075e-02,  1.21375210e-02, -3.18548425e-02, -2.78567673e-01,\n",
      "         1.23482018e-01, -1.21857800e-01, -8.27399759e-02, -6.98036527e-02,\n",
      "         1.54028165e-02, -1.67309648e-01,  1.68679914e-01,  2.09341432e-02,\n",
      "        -1.01216781e-01,  5.65609730e-02,  2.25544382e-01, -1.04661226e-01,\n",
      "        -2.00101213e-01,  2.74014378e-02,  5.42797749e-01, -1.48451151e-01,\n",
      "        -2.14422780e-01,  4.44981528e-01, -7.77632335e-02, -2.11397635e-01,\n",
      "         3.81674042e-02,  2.56151979e-01,  1.06817373e-01,  1.08564998e-01,\n",
      "        -1.88436080e-04,  4.03387558e-02, -6.54236962e-02,  2.48940559e-01,\n",
      "        -1.82067349e-01, -2.16919336e-01,  5.64696234e-02, -1.68609875e-02,\n",
      "         2.39917929e-01, -5.40571605e-01, -3.10241157e-01, -1.69930026e-01,\n",
      "        -4.06344775e-02,  1.35896882e-01,  1.38415543e-01, -3.14665298e-02,\n",
      "        -6.29621815e-02, -3.43648986e-01,  8.26162361e-02,  8.21116482e-02,\n",
      "        -8.81481341e-02,  2.01320767e-01,  4.30812632e-01,  4.92751569e-02,\n",
      "        -1.80157407e-01,  1.05626636e-01, -2.37676570e-01,  1.88211052e-01,\n",
      "        -1.41398235e-01,  1.18114250e-03, -6.92824262e-02, -4.98981478e-01,\n",
      "         8.27973906e-02, -2.17492611e-01, -5.16557683e-02, -2.02248191e-01,\n",
      "         7.02670959e-02, -1.05308052e-01,  2.02198360e-02, -8.16442857e-02,\n",
      "         1.45948587e-02,  2.52940891e-01, -1.55588508e-01,  1.11969917e-01,\n",
      "         1.93102044e-03,  8.04166005e-02, -9.26636594e-02, -2.24420090e-01,\n",
      "         3.77879922e-01, -1.63345705e-01, -2.16803586e-01, -7.46160361e-02,\n",
      "         1.83878710e-01,  2.07189437e-01,  3.69029260e-02, -5.75970164e-02,\n",
      "        -7.08632631e-02, -1.37866359e-01,  9.17618312e-03,  1.54537281e-01,\n",
      "        -4.00063687e-02, -1.26649216e-01, -2.26497070e-02,  1.57844893e-01,\n",
      "         3.95064643e-02,  8.15016699e-02,  4.33064249e-01, -1.41989354e-01,\n",
      "         2.58277452e-01,  3.90022756e-03,  4.26240042e-02, -1.70401276e-01,\n",
      "         3.89997257e-01, -2.38261827e-02, -5.55332254e-02,  3.77742054e-01,\n",
      "        -3.32653929e-01, -2.01189079e-01, -3.85312329e-01, -3.23775312e-01,\n",
      "        -2.14472058e-02,  2.11402564e-01, -3.51964399e-01,  3.29479924e-01,\n",
      "         7.67143134e-01,  7.78775516e-02,  3.61260690e-01,  5.15757048e-01,\n",
      "        -1.88484644e-01, -2.60067379e-01, -4.59820896e-02, -7.46049114e-02])]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "#x\n",
    "len(temp)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "160000"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "word2vec_df = pd.read_csv(word2vec_filename)\n",
    "#word2vec_df.head(-1)\n",
    "#len(word2vec_df)\n",
    "p = Perceptron(random_state=99999)\n",
    "p.fit(word2vec_df, Y_train['class'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Perceptron(random_state=99999)"
      ]
     },
     "metadata": {},
     "execution_count": 166
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions_train = p.predict(word2vec_df)\n",
    "#predictions_test = p.predict(x_test)\n",
    "train_score = accuracy_score(predictions_train, Y_train['class'])\n",
    "print(\"score on train data: \", train_score)\n",
    "#test_score = accuracy_score(predictions_test, y_test)\n",
    "#print(\"score on test data: \", test_score)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "score on train data:  0.54550625\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(np.mean(vec))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Index of the word 'action':\")\n",
    "print(My_model1.wv.key_to_index[\"action\"])\n",
    "# Total number of the words \n",
    "print(len(My_model1.wv))\n",
    "# Print the size of the word2vec vector for one word\n",
    "print(\"Length of the vector generated for a word\")\n",
    "print(len(My_model1.wv['action']))\n",
    "# Get the mean for the vectors for an example review\n",
    "print(\"Print the length after taking average of all word vectors in a sentence:\")\n",
    "#print(dataset['tokens'])\n",
    "k = 0\n",
    "\n",
    "'''for ind in dataset1.index:\n",
    "    \n",
    "    for i in dataset1['tokens'][ind]:\n",
    "        \n",
    "        #print('i',i)\n",
    "        try:\n",
    "            My_model1.wv[i]\n",
    "        except KeyError:\n",
    "                #print(dataset1['tokens'][ind].remove(i))\n",
    "                #print('i=',i,ind)\n",
    "                #print(dataset1['tokens'][ind])\n",
    "                dataset1['tokens'][ind] = dataset1['tokens'][ind].remove(i)\n",
    "                #dataset['tokens'][ind] = dataset['tokens'][ind].remove(i)'''\n",
    "        \n",
    "        \n",
    "    \n",
    "#dataset1.head(10)\n",
    "#print(np.mean(mean_val,axis=0))\n",
    "print(np.mean([My_model1.wv[token]  for token in dataset1['tokens']  ], axis=0))\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index of the word 'action':\n",
      "1937\n",
      "13802\n",
      "Length of the vector generated for a word\n",
      "300\n",
      "Print the length after taking average of all word vectors in a sentence:\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"Key 'allvery' not present\"",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/17/jys7jgwn3x37cltk9w8j0l080000gq/T/ipykernel_40372/2191435099.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#dataset1.head(10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#print(np.mean(mean_val,axis=0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMy_model1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/17/jys7jgwn3x37cltk9w8j0l080000gq/T/ipykernel_40372/2191435099.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#dataset1.head(10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#print(np.mean(mean_val,axis=0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMy_model1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \"\"\"\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'allvery' not present\""
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset1.head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>class</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>description say suitable type surface truewe o...</td>\n",
       "      <td>0</td>\n",
       "      <td>[description, say, suitable, type, surface, or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>grind coffee like bos static issue plastic wei...</td>\n",
       "      <td>1</td>\n",
       "      <td>[grind, coffee, like, bos, static, issue, plas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1</td>\n",
       "      <td>tried get canner work many month went instruct...</td>\n",
       "      <td>0</td>\n",
       "      <td>[tried, get, canner, work, many, month, went, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5</td>\n",
       "      <td>great glass using boat well tested</td>\n",
       "      <td>1</td>\n",
       "      <td>[great, glass, using, boat, well, tested]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>4</td>\n",
       "      <td>I used week kiddos ' lunch box worked well sep...</td>\n",
       "      <td>1</td>\n",
       "      <td>[I, used, week, kiddos, ', lunch, box, worked,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>4</td>\n",
       "      <td>like dish color clear redcranberry color swirl...</td>\n",
       "      <td>1</td>\n",
       "      <td>[like, dish, color, clear, color, swirly, desi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>4</td>\n",
       "      <td>first know three cup european style coffee mea...</td>\n",
       "      <td>1</td>\n",
       "      <td>[first, know, three, cup, european, style, cof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>4</td>\n",
       "      <td>great deal best found anywhere</td>\n",
       "      <td>1</td>\n",
       "      <td>[great, deal, best, found, anywhere]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>1</td>\n",
       "      <td>bought refrigerator keep beverage cold porch t...</td>\n",
       "      <td>0</td>\n",
       "      <td>[bought, refrigerator, keep, beverage, cold, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>5</td>\n",
       "      <td>super sparkly actually brand called sunflower ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[super, sparkly, actually, brand, called, sunf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     star_rating                                        review_body  class  \\\n",
       "5              1  description say suitable type surface truewe o...      0   \n",
       "36             4  grind coffee like bos static issue plastic wei...      1   \n",
       "88             1  tried get canner work many month went instruct...      0   \n",
       "90             5                 great glass using boat well tested      1   \n",
       "108            4  I used week kiddos ' lunch box worked well sep...      1   \n",
       "124            4  like dish color clear redcranberry color swirl...      1   \n",
       "203            4  first know three cup european style coffee mea...      1   \n",
       "206            4                     great deal best found anywhere      1   \n",
       "215            1  bought refrigerator keep beverage cold porch t...      0   \n",
       "234            5  super sparkly actually brand called sunflower ...      1   \n",
       "\n",
       "                                                tokens  \n",
       "5    [description, say, suitable, type, surface, or...  \n",
       "36   [grind, coffee, like, bos, static, issue, plas...  \n",
       "88   [tried, get, canner, work, many, month, went, ...  \n",
       "90           [great, glass, using, boat, well, tested]  \n",
       "108  [I, used, week, kiddos, ', lunch, box, worked,...  \n",
       "124  [like, dish, color, clear, color, swirly, desi...  \n",
       "203  [first, know, three, cup, european, style, cof...  \n",
       "206               [great, deal, best, found, anywhere]  \n",
       "215  [bought, refrigerator, keep, beverage, cold, p...  \n",
       "234  [super, sparkly, actually, brand, called, sunf...  "
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "for i in dataset1['tokens']:\n",
    "    if len(i)==0:\n",
    "        print('hee',i)\n",
    "        \n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset1.head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>class</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>description say suitable type surface truewe o...</td>\n",
       "      <td>0</td>\n",
       "      <td>[description, say, suitable, type, surface, or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>grind coffee like bos static issue plastic wei...</td>\n",
       "      <td>1</td>\n",
       "      <td>[grind, coffee, like, bos, static, issue, plas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1</td>\n",
       "      <td>tried get canner work many month went instruct...</td>\n",
       "      <td>0</td>\n",
       "      <td>[tried, get, canner, work, many, month, went, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5</td>\n",
       "      <td>great glass using boat well tested</td>\n",
       "      <td>1</td>\n",
       "      <td>[great, glass, using, boat, well, tested]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>4</td>\n",
       "      <td>I used week kiddos ' lunch box worked well sep...</td>\n",
       "      <td>1</td>\n",
       "      <td>[I, used, week, kiddos, ', lunch, box, worked,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>4</td>\n",
       "      <td>like dish color clear redcranberry color swirl...</td>\n",
       "      <td>1</td>\n",
       "      <td>[like, dish, color, clear, color, swirly, desi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>4</td>\n",
       "      <td>first know three cup european style coffee mea...</td>\n",
       "      <td>1</td>\n",
       "      <td>[first, know, three, cup, european, style, cof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>4</td>\n",
       "      <td>great deal best found anywhere</td>\n",
       "      <td>1</td>\n",
       "      <td>[great, deal, best, found, anywhere]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>1</td>\n",
       "      <td>bought refrigerator keep beverage cold porch t...</td>\n",
       "      <td>0</td>\n",
       "      <td>[bought, refrigerator, keep, beverage, cold, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>5</td>\n",
       "      <td>super sparkly actually brand called sunflower ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[super, sparkly, actually, brand, called, sunf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     star_rating                                        review_body  class  \\\n",
       "5              1  description say suitable type surface truewe o...      0   \n",
       "36             4  grind coffee like bos static issue plastic wei...      1   \n",
       "88             1  tried get canner work many month went instruct...      0   \n",
       "90             5                 great glass using boat well tested      1   \n",
       "108            4  I used week kiddos ' lunch box worked well sep...      1   \n",
       "124            4  like dish color clear redcranberry color swirl...      1   \n",
       "203            4  first know three cup european style coffee mea...      1   \n",
       "206            4                     great deal best found anywhere      1   \n",
       "215            1  bought refrigerator keep beverage cold porch t...      0   \n",
       "234            5  super sparkly actually brand called sunflower ...      1   \n",
       "\n",
       "                                                tokens  \n",
       "5    [description, say, suitable, type, surface, or...  \n",
       "36   [grind, coffee, like, bos, static, issue, plas...  \n",
       "88   [tried, get, canner, work, many, month, went, ...  \n",
       "90           [great, glass, using, boat, well, tested]  \n",
       "108  [I, used, week, kiddos, ', lunch, box, worked,...  \n",
       "124  [like, dish, color, clear, color, swirly, desi...  \n",
       "203  [first, know, three, cup, european, style, cof...  \n",
       "206               [great, deal, best, found, anywhere]  \n",
       "215  [bought, refrigerator, keep, beverage, cold, p...  \n",
       "234  [super, sparkly, actually, brand, called, sunf...  "
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset1 = dataset1[~dataset1.tokens.str.len().eq(0)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nan_value = float(\"NaN\")\n",
    "#Convert NaN values to empty string\n",
    "\n",
    "dataset1.replace([], nan_value, inplace=True)\n",
    "\n",
    "dataset1.dropna(subset = [\"tokens\"], inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(np.mean([My_model.wv[token] for token in dataset1['tokens']], axis=0))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"Key 'bos' not present\"",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/17/jys7jgwn3x37cltk9w8j0l080000gq/T/ipykernel_34894/78357170.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/17/jys7jgwn3x37cltk9w8j0l080000gq/T/ipykernel_34894/78357170.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \"\"\"\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'bos' not present\""
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset.head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>class</th>\n",
       "      <th>review_body1</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>hate cook regular pot</td>\n",
       "      <td>0</td>\n",
       "      <td>hate cook regular pot</td>\n",
       "      <td>[hate, cook, regular, pot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>velcro hold well stat cold could use sie pocket</td>\n",
       "      <td>0</td>\n",
       "      <td>velcro hold well stat cold could use sie pocket</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>4</td>\n",
       "      <td>good valu price screen look like cut slightli ...</td>\n",
       "      <td>1</td>\n",
       "      <td>good valu price screen look like cut slightli ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1</td>\n",
       "      <td>concept great one best featur bottl tea basket...</td>\n",
       "      <td>0</td>\n",
       "      <td>concept great one best featur bottl tea basket...</td>\n",
       "      <td>[concept, great, one, best, featur, bottl, tea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2</td>\n",
       "      <td>lose break plastic brew basketwithout machin w...</td>\n",
       "      <td>0</td>\n",
       "      <td>lose break plastic brew basketwithout machin w...</td>\n",
       "      <td>[lose, break, plastic, brew, basketwithout, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2</td>\n",
       "      <td>i blender year put outsid warranti week ago ru...</td>\n",
       "      <td>0</td>\n",
       "      <td>i blender year put outsid warranti week ago ru...</td>\n",
       "      <td>[i, blender, year, put, outsid, warranti, week...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>4</td>\n",
       "      <td>work well even peopl use cook recommend anyon</td>\n",
       "      <td>1</td>\n",
       "      <td>work well even peopl use cook recommend anyon</td>\n",
       "      <td>[work, well, even, peopl, use, cook, recommend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>5</td>\n",
       "      <td>excel party</td>\n",
       "      <td>1</td>\n",
       "      <td>excel party</td>\n",
       "      <td>[excel, party]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>1</td>\n",
       "      <td>cheap first issu even start unscrew see connec...</td>\n",
       "      <td>0</td>\n",
       "      <td>cheap first issu even start unscrew see connec...</td>\n",
       "      <td>[cheap, first, issu, even, start, unscrew, see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>5</td>\n",
       "      <td>love gingerbread boy right gingerbread sugar s...</td>\n",
       "      <td>1</td>\n",
       "      <td>love gingerbread boy right gingerbread sugar s...</td>\n",
       "      <td>[love, gingerbread, boy, right, gingerbread, s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     star_rating                                        review_body  class  \\\n",
       "24             1                              hate cook regular pot      0   \n",
       "25             2    velcro hold well stat cold could use sie pocket      0   \n",
       "143            4  good valu price screen look like cut slightli ...      1   \n",
       "180            1  concept great one best featur bottl tea basket...      0   \n",
       "186            2  lose break plastic brew basketwithout machin w...      0   \n",
       "190            2  i blender year put outsid warranti week ago ru...      0   \n",
       "199            4      work well even peopl use cook recommend anyon      1   \n",
       "220            5                                        excel party      1   \n",
       "241            1  cheap first issu even start unscrew see connec...      0   \n",
       "270            5  love gingerbread boy right gingerbread sugar s...      1   \n",
       "\n",
       "                                          review_body1  \\\n",
       "24                               hate cook regular pot   \n",
       "25     velcro hold well stat cold could use sie pocket   \n",
       "143  good valu price screen look like cut slightli ...   \n",
       "180  concept great one best featur bottl tea basket...   \n",
       "186  lose break plastic brew basketwithout machin w...   \n",
       "190  i blender year put outsid warranti week ago ru...   \n",
       "199      work well even peopl use cook recommend anyon   \n",
       "220                                        excel party   \n",
       "241  cheap first issu even start unscrew see connec...   \n",
       "270  love gingerbread boy right gingerbread sugar s...   \n",
       "\n",
       "                                                tokens  \n",
       "24                          [hate, cook, regular, pot]  \n",
       "25                                                None  \n",
       "143                                               None  \n",
       "180  [concept, great, one, best, featur, bottl, tea...  \n",
       "186  [lose, break, plastic, brew, basketwithout, ma...  \n",
       "190  [i, blender, year, put, outsid, warranti, week...  \n",
       "199  [work, well, even, peopl, use, cook, recommend...  \n",
       "220                                     [excel, party]  \n",
       "241  [cheap, first, issu, even, start, unscrew, see...  \n",
       "270  [love, gingerbread, boy, right, gingerbread, s...  "
      ]
     },
     "metadata": {},
     "execution_count": 172
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "word2vec_filename = 'train_review_word2vec.csv'\n",
    "with open(word2vec_filename, 'w+') as word2vec_file:\n",
    "    for index, row in X_train.iterrows():\n",
    "        model_vector = (np.mean([My_model.wv[token] for token in row['tokens']], axis=0)).tolist()\n",
    "        if index == 0:\n",
    "            header = \",\".join(str(ele) for ele in range(300))\n",
    "            word2vec_file.write(header)\n",
    "            word2vec_file.write(\"\\n\")\n",
    "        # Check if the line exists else it is vector of zeros\n",
    "        if type(model_vector) is list:  \n",
    "            line1 = \",\".join( [str(vector_element) for vector_element in model_vector] )\n",
    "        else:\n",
    "            line1 = \",\".join([str(0) for i in range(300)])\n",
    "        word2vec_file.write(line1)\n",
    "        word2vec_file.write('\\n')"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"Key 'nuianc' not present\"",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/17/jys7jgwn3x37cltk9w8j0l080000gq/T/ipykernel_30354/3848102114.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mword2vec_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mmodel_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\",\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mele\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/17/jys7jgwn3x37cltk9w8j0l080000gq/T/ipykernel_30354/3848102114.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mword2vec_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mmodel_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\",\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mele\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \"\"\"\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \"\"\"\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'nuianc' not present\""
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Balancing the dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Word Embedding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pip install -U gensim"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in /Users/shubh1/Library/Python/3.8/lib/python/site-packages (4.1.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/shubh1/Library/Python/3.8/lib/python/site-packages (from gensim) (1.7.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/shubh1/Library/Python/3.8/lib/python/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/shubh1/Library/Python/3.8/lib/python/site-packages (from gensim) (1.21.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from gensim.models import Word2Vec"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "wordmodelfile=r\"C:\\Users\\krish\\OneDrive\\Desktop\\USC StudyList\\NLP\\hw2\\GoogleNews-vectors-negative300.bin.gz\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "wordmodel= gensim.models.KeyedVectors.load_word2vec_format(wordmodelfile, binary=True)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NotImplementedError",
     "evalue": "Unable to handle scheme 'c', expected one of ('', 'file', 'hdfs', 'scp', 'sftp', 'ssh'). Extra dependencies required by 'c' may be missing. See <https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst> for details.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/17/jys7jgwn3x37cltk9w8j0l080000gq/T/ipykernel_30354/887228058.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwordmodel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordmodelfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m         \"\"\"\n\u001b[0;32m-> 1629\u001b[0;31m         return _load_word2vec_format(\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1955\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1956\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mno_header\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m             \u001b[0;31m# deduce both vocab_size & vector_size from 1st pass over file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mve\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0mbinary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_binary_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0mdecompressed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mso_compression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_open_binary_stream\u001b[0;34m(uri, mode, transport_params)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0mscheme\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sniff_scheme\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m     \u001b[0msubmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheme\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m     \u001b[0mfobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/smart_open/transport.py\u001b[0m in \u001b[0;36mget_transport\u001b[0;34m(scheme)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mscheme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_REGISTRY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_REGISTRY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscheme\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Unable to handle scheme 'c', expected one of ('', 'file', 'hdfs', 'scp', 'sftp', 'ssh'). Extra dependencies required by 'c' may be missing. See <https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst> for details."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dog = wordmodel['dog']\n",
    "print(dog.shape)\n",
    "print(dog[:10])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(300,)\n",
      "[ 0.05126953 -0.02233887 -0.17285156  0.16113281 -0.08447266  0.05737305\n",
      "  0.05859375 -0.08251953 -0.01538086 -0.06347656]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(wordmodel.most_similar(positive=['woman', 'king'], negative=['man']))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('queen', 0.7118193507194519), ('monarch', 0.6189674735069275), ('princess', 0.5902431011199951), ('crown_prince', 0.5499460697174072), ('prince', 0.5377321243286133), ('kings', 0.5236844420433044), ('Queen_Consort', 0.5235945582389832), ('queens', 0.518113374710083), ('sultan', 0.5098593831062317), ('monarchy', 0.5087411999702454)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(wordmodel.similarity('excellent', 'outstanding'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5567486\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "df_upsampled['review_body'].dropna(inplace=True)\n",
    "tokens = df_upsampled['review_body'].apply(word_tokenize)\n",
    "#sentences=df_upsampled['review_body'].values\n",
    "#newsVec=[nltk.word_tokenize(title) for title in sentences]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = Word2Vec(sentences=tokens, vector_size=300, window=11, min_count=10, workers=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(model.wv.most_similar(positive=['woman', 'king'], negative=['man']))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('queen', 0.43097829818725586), ('half-sheet', 0.3716697692871094), ('petite', 0.3510390818119049), ('8.5', 0.3425050973892212), ('8-Quart', 0.3415023982524872), ('Sheets', 0.3391481935977936), ('pinky', 0.3357003629207611), ('Jumbo', 0.33416441082954407), ('generous', 0.3305935561656952), ('based', 0.3290439546108246)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(model.wv.similarity('excellent', 'outstanding'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.82568747\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.wv.most_similar(\"man\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('woman', 0.706481397151947),\n",
       " ('guy', 0.6354748010635376),\n",
       " ('teacher', 0.5989513993263245),\n",
       " ('student', 0.5796248912811279),\n",
       " ('child', 0.5733389854431152),\n",
       " ('kid', 0.5718080997467041),\n",
       " ('girl', 0.5683653354644775),\n",
       " ('baseball', 0.5331366658210754),\n",
       " ('lady', 0.5290523767471313),\n",
       " ('female', 0.5199171900749207)]"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pretrained model predicts the output more accurately than our model.We can clearly see that the pretrained model has better capacity to encode semantic similarity between the words\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Performing DataCleaning and Preprocesssing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Removing the neutral reviews\n",
    "index_names = df_upsampled[ df_upsampled['Sentiment_Class'] == '3' ].index\n",
    "  \n",
    "# drop these row indexes\n",
    "# from dataFrame\n",
    "df_upsampled.drop(index_names, inplace = True)\n",
    "  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Converting reviews to lower case"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Converting reviews to lower case\n",
    "\n",
    "df_upsampled[\"review_body\"] = df_upsampled[\"review_body\"].str.lower()\n",
    "df_upsampled=df_upsampled.dropna()\n",
    "df_upsampled.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>Sentiment_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3214104</th>\n",
       "      <td>1.0</td>\n",
       "      <td>after receiving these the other day, i noticed...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573047</th>\n",
       "      <td>1.0</td>\n",
       "      <td>i ordered 2 sets of two \\\\\"new\\\\\" churchill pi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372127</th>\n",
       "      <td>1.0</td>\n",
       "      <td>these glasses are a big dissapointment. first ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234160</th>\n",
       "      <td>1.0</td>\n",
       "      <td>when visiting my mother, i noticed that she wa...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550108</th>\n",
       "      <td>1.0</td>\n",
       "      <td>the galvanized bucket is great for chilling a ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body  \\\n",
       "3214104          1.0  after receiving these the other day, i noticed...   \n",
       "3573047          1.0  i ordered 2 sets of two \\\\\"new\\\\\" churchill pi...   \n",
       "372127           1.0  these glasses are a big dissapointment. first ...   \n",
       "234160           1.0  when visiting my mother, i noticed that she wa...   \n",
       "2550108          1.0  the galvanized bucket is great for chilling a ...   \n",
       "\n",
       "        Sentiment_Class  \n",
       "3214104               2  \n",
       "3573047               2  \n",
       "372127                2  \n",
       "234160                2  \n",
       "2550108               2  "
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Removing HTML Tags and URLS from reviews\n",
    "def html_parser(raw_html):\n",
    "    soup = str(raw_html) #The addition of this line solves the problem\n",
    "    soup = BeautifulSoup(raw_html, 'html.parser')\n",
    "    soup_string = soup.get_text()\n",
    "    soup_string = re.sub('<.*>', ' ', soup_string)\n",
    "    return soup_string"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_upsampled['review_body'] =[html_parser(text)for text in df_upsampled['review_body']]\n",
    "df_upsampled.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>Sentiment_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3214104</th>\n",
       "      <td>1.0</td>\n",
       "      <td>after receiving these the other day, i noticed...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573047</th>\n",
       "      <td>1.0</td>\n",
       "      <td>i ordered 2 sets of two \\\\\"new\\\\\" churchill pi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372127</th>\n",
       "      <td>1.0</td>\n",
       "      <td>these glasses are a big dissapointment. first ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234160</th>\n",
       "      <td>1.0</td>\n",
       "      <td>when visiting my mother, i noticed that she wa...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550108</th>\n",
       "      <td>1.0</td>\n",
       "      <td>the galvanized bucket is great for chilling a ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body  \\\n",
       "3214104          1.0  after receiving these the other day, i noticed...   \n",
       "3573047          1.0  i ordered 2 sets of two \\\\\"new\\\\\" churchill pi...   \n",
       "372127           1.0  these glasses are a big dissapointment. first ...   \n",
       "234160           1.0  when visiting my mother, i noticed that she wa...   \n",
       "2550108          1.0  the galvanized bucket is great for chilling a ...   \n",
       "\n",
       "        Sentiment_Class  \n",
       "3214104               2  \n",
       "3573047               2  \n",
       "372127                2  \n",
       "234160                2  \n",
       "2550108               2  "
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Removing HTML Tags and URLS from reviews\n",
    "df_upsampled['review_body'] = df_upsampled['review_body'].replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True)\n",
    "df_upsampled.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>Sentiment_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3214104</th>\n",
       "      <td>1.0</td>\n",
       "      <td>after receiving these the other day, i noticed...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573047</th>\n",
       "      <td>1.0</td>\n",
       "      <td>i ordered 2 sets of two \\\\\"new\\\\\" churchill pi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372127</th>\n",
       "      <td>1.0</td>\n",
       "      <td>these glasses are a big dissapointment. first ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234160</th>\n",
       "      <td>1.0</td>\n",
       "      <td>when visiting my mother, i noticed that she wa...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550108</th>\n",
       "      <td>1.0</td>\n",
       "      <td>the galvanized bucket is great for chilling a ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body  \\\n",
       "3214104          1.0  after receiving these the other day, i noticed...   \n",
       "3573047          1.0  i ordered 2 sets of two \\\\\"new\\\\\" churchill pi...   \n",
       "372127           1.0  these glasses are a big dissapointment. first ...   \n",
       "234160           1.0  when visiting my mother, i noticed that she wa...   \n",
       "2550108          1.0  the galvanized bucket is great for chilling a ...   \n",
       "\n",
       "        Sentiment_Class  \n",
       "3214104               2  \n",
       "3573047               2  \n",
       "372127                2  \n",
       "234160                2  \n",
       "2550108               2  "
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Removing non alphabetic characters and extra spaces\n",
    "def nospecial(text):\n",
    "\timport re\n",
    "\ttext = re.sub(\"[^a-zA-Z ]+\", \"\",text)\n",
    "\treturn text\n",
    "df_upsampled['review_body']=[nospecial(text) for text in df_upsampled['review_body']]\n",
    "df_upsampled.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>Sentiment_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3214104</th>\n",
       "      <td>1.0</td>\n",
       "      <td>after receiving these the other day i noticed ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573047</th>\n",
       "      <td>1.0</td>\n",
       "      <td>i ordered  sets of two new churchill pink will...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372127</th>\n",
       "      <td>1.0</td>\n",
       "      <td>these glasses are a big dissapointment first o...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234160</th>\n",
       "      <td>1.0</td>\n",
       "      <td>when visiting my mother i noticed that she was...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550108</th>\n",
       "      <td>1.0</td>\n",
       "      <td>the galvanized bucket is great for chilling a ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body  \\\n",
       "3214104          1.0  after receiving these the other day i noticed ...   \n",
       "3573047          1.0  i ordered  sets of two new churchill pink will...   \n",
       "372127           1.0  these glasses are a big dissapointment first o...   \n",
       "234160           1.0  when visiting my mother i noticed that she was...   \n",
       "2550108          1.0  the galvanized bucket is great for chilling a ...   \n",
       "\n",
       "        Sentiment_Class  \n",
       "3214104               2  \n",
       "3573047               2  \n",
       "372127                2  \n",
       "234160                2  \n",
       "2550108               2  "
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Removing the stop words using NLTK\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\krish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_upsampled['review_body_without_stopwords'] = df_upsampled['review_body'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Performing Lemmetization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# Define the sentence to be lemmatized\n",
    "def lemmetization(text):\n",
    "    \n",
    "\n",
    "    # Tokenize: Split the sentence into words\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    #print(word_list)\n",
    "    #> ['The', 'striped', 'bats', 'are', 'hanging', 'on', 'their', 'feet', 'for', 'best']\n",
    "\n",
    "    # Lemmatize list of words and join\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "    return lemmatized_output\n",
    "df_upsampled['review_body_without_stopwords']=[lemmetization(text) for text in df_upsampled['review_body_without_stopwords']]\n",
    "df_upsampled.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>Sentiment_Class</th>\n",
       "      <th>review_body_without_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3214104</th>\n",
       "      <td>1.0</td>\n",
       "      <td>after receiving these the other day i noticed ...</td>\n",
       "      <td>2</td>\n",
       "      <td>receiving day noticed box said nonstick coatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573047</th>\n",
       "      <td>1.0</td>\n",
       "      <td>i ordered  sets of two new churchill pink will...</td>\n",
       "      <td>2</td>\n",
       "      <td>ordered set two new churchill pink willow mug ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372127</th>\n",
       "      <td>1.0</td>\n",
       "      <td>these glasses are a big dissapointment first o...</td>\n",
       "      <td>2</td>\n",
       "      <td>glass big dissapointment first seem flimsy sus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234160</th>\n",
       "      <td>1.0</td>\n",
       "      <td>when visiting my mother i noticed that she was...</td>\n",
       "      <td>2</td>\n",
       "      <td>visiting mother noticed still using old swinga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550108</th>\n",
       "      <td>1.0</td>\n",
       "      <td>the galvanized bucket is great for chilling a ...</td>\n",
       "      <td>2</td>\n",
       "      <td>galvanized bucket great chilling half dozen bo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body  \\\n",
       "3214104          1.0  after receiving these the other day i noticed ...   \n",
       "3573047          1.0  i ordered  sets of two new churchill pink will...   \n",
       "372127           1.0  these glasses are a big dissapointment first o...   \n",
       "234160           1.0  when visiting my mother i noticed that she was...   \n",
       "2550108          1.0  the galvanized bucket is great for chilling a ...   \n",
       "\n",
       "        Sentiment_Class                      review_body_without_stopwords  \n",
       "3214104               2  receiving day noticed box said nonstick coatin...  \n",
       "3573047               2  ordered set two new churchill pink willow mug ...  \n",
       "372127                2  glass big dissapointment first seem flimsy sus...  \n",
       "234160                2  visiting mother noticed still using old swinga...  \n",
       "2550108               2  galvanized bucket great chilling half dozen bo...  "
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x224b52a5b20>"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "wordmodel"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x22505cbbf70>"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
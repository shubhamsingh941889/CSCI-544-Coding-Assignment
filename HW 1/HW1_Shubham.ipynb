{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    " "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1129)>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#! pip install bs4 # in case you don't have it installed\n",
    "\n",
    "# Dataset: https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Kitchen_v1_00.tsv.gz"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "amazon_reviews = pd.read_csv('/Users/shubh1/Downloads/amazon.tsv', sep ='\\t', error_bad_lines=False,warn_bad_lines=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Keep Reviews and Ratings"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "source": [
    "rev_rat = amazon_reviews[['star_rating','review_body']]\n",
    " #rev_rat.head(3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "source": [
    "# Statistics of ratings\n",
    "rev_rat['star_rating'].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5.0    3124759\n",
       "4.0     731733\n",
       "1.0     426900\n",
       "3.0     349547\n",
       "2.0     241948\n",
       "Name: star_rating, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 573
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "source": [
    "rev_rat=rev_rat.dropna() # Dropping reviews that have type NaN as this will cause when randomly selecting classes with a particular class\n",
    "rev_rat = rev_rat.reset_index(drop=True) # reseting the index tso that it covers up for the dropped values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Labelling Reviews:\n",
    "## The reviews with rating 4,5 are labelled to be 1 and 1,2 are labelled as 0. Discard the reviews with rating 3'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "source": [
    "rev_rat['star_rating']=rev_rat['star_rating'].astype(int) # convert values of star_rating to int so that we can use numpy where clause\n",
    "rev_rat['class']=np.where(rev_rat['star_rating']<3,0,1) # set class based on the given requirements\n",
    "rev_rat['class']=np.where(rev_rat['star_rating']==3,3,rev_rat['class']) # we will now change class of ratings 3 as on previous step we added it to class 1\n",
    "\n",
    " #rev_rat.head(50)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "source": [
    "# Statistics of ratings after classes\n",
    "ans = rev_rat['class'].value_counts()\n",
    "#print(ans)\n",
    "print('Class 1:',ans[0],', Class 0:',ans[1],', Class Neutral or 3:',ans[3])\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Class 1: 668809 , Class 0: 3856296 , Class Neutral or 3: 349539\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "# Discarding reviews with ratings 3 and class 3\n",
    "rev_rat = rev_rat.loc[rev_rat[\"class\"] != 3]\n",
    "#rev_rat.head(50)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "#rev_rat['class'].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1    3856296\n",
       "0     668809\n",
       "Name: class, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " ## We select 200000 reviews randomly with 100,000 positive and 100,000 negative reviews.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "class0_random = rev_rat.star_rating[rev_rat['class'].eq(0)].sample(100000).index #randomly select class 0 sample\n",
    "class1_random = rev_rat.star_rating[rev_rat['class'].eq(1)].sample(100000).index \n",
    "rev_rat = rev_rat.loc[class0_random.union(class1_random)] #unify both the dataframes\n",
    "#display(rev_rat['class'].value_counts())\n",
    "\n",
    "#rev_rat.head(50)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "1    100000\n",
       "0    100000\n",
       "Name: class, dtype: int64"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "# 3 samples before Data Cleaning\n",
    "rev_rat.head(3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>sharp and look great</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>I've been waiting my whole life for these!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5</td>\n",
       "      <td>Good water bottle.  Water tastes so much bette...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    star_rating                                        review_body  class\n",
       "8             5                               sharp and look great      1\n",
       "27            5         I've been waiting my whole life for these!      1\n",
       "64            5  Good water bottle.  Water tastes so much bette...      1"
      ]
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "#Average char length in review_body before data cleaning\n",
    "from statistics import mean\n",
    "char_len=[len(char) for char in rev_rat['review_body']]\n",
    "print(mean(char_len))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "323.796825\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Cleaning\n",
    "\n",
    "## Convert the all reviews into the lower case."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "rev_rat['review_body'] =rev_rat['review_body'].str.lower()\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>sharp and look great</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>i've been waiting my whole life for these!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5</td>\n",
       "      <td>good water bottle.  water tastes so much bette...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>5</td>\n",
       "      <td>perfect thickness for my vegetable-prep needs,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>4</td>\n",
       "      <td>i like the pot very much. it heats very quickl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     star_rating                                        review_body  class\n",
       "8              5                               sharp and look great      1\n",
       "27             5         i've been waiting my whole life for these!      1\n",
       "64             5  good water bottle.  water tastes so much bette...      1\n",
       "78             5  perfect thickness for my vegetable-prep needs,...      1\n",
       "115            4  i like the pot very much. it heats very quickl...      1"
      ]
     },
     "metadata": {},
     "execution_count": 127
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## remove the HTML and URLs from the reviews"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "rev_rat['review_body'] = rev_rat['review_body'].replace(r'<.*?>+', '', regex=True) #removes html tags\n",
    "rev_rat['review_body'] = rev_rat['review_body'].replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True) #removes url\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## remove non-alphabetical characters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "source": [
    "rev_rat['review_body'] = rev_rat['review_body'].replace(r'[^a-zA-Z\\' ]+', '', regex=True) #I am not removing apostrophe as they will help in contractions\n",
    "#rev_rat.head(5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Remove the extra spaces between the words"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "source": [
    "rev_rat['review_body']=rev_rat['review_body'].replace(r' +',' ',regex=True) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "source": [
    "import sys  \n",
    "!{sys.executable} -m pip install contractions\n",
    "import contractions"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: contractions in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (0.0.52)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from contractions) (0.0.21)\n",
      "Requirement already satisfied: pyahocorasick in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from textsearch>=0.0.21->contractions) (1.4.2)\n",
      "Requirement already satisfied: anyascii in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from textsearch>=0.0.21->contractions) (0.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## perform contractions on the reviews."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "source": [
    "rev_rat['review_body']= [contractions.fix(words) for words in rev_rat['review_body']]\n",
    "#rev_rat.head(5)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "source": [
    "#Average char length in review_body after data cleaning\n",
    "from statistics import mean\n",
    "char_len_after=[len(char) for char in rev_rat['review_body']]\n",
    "print(mean(char_len_after))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "309.058895\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre-processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## remove the stop words "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "source": [
    "from nltk.corpus import stopwords\n",
    "st_words = stopwords.words('english')\n",
    "rev_rat['review_body'] = rev_rat['review_body'].apply(lambda x: ' '.join([i for i in x.split() if i not in (st_words)]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## perform lemmatization  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "rev_rat['review_body']=rev_rat['review_body'].apply(lambda x: \" \".join([lemmatizer.lemmatize(j) for j in nltk.word_tokenize(x)]))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "source": [
    "# 3 samples after preprocessing\n",
    "rev_rat.head(3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>sharp look great</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>I waiting whole life</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5</td>\n",
       "      <td>good water bottle water taste much better old ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    star_rating                                        review_body  class\n",
       "8             5                                   sharp look great      1\n",
       "27            5                               I waiting whole life      1\n",
       "64            5  good water bottle water taste much better old ...      1"
      ]
     },
     "metadata": {},
     "execution_count": 148
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "source": [
    "#Average char length in review_body after data preprocessing\n",
    "from statistics import mean\n",
    "char_len_af_pre=[len(char) for char in rev_rat['review_body']]\n",
    "print(mean(char_len_af_pre))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "191.49201\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "source": [
    "print('Change in Avg char length from normal to Data Cleaning')\n",
    "print(str(mean(char_len))+\",\"+str(mean(char_len_after)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "323.796825,309.058895\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "source": [
    "print('Change in Avg char length from Data Cleaning to Data Preprocessing')\n",
    "print(str(mean(char_len_after))+\",\"+str(mean(char_len_af_pre)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "309.058895,191.49201\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "source": [
    "pip install -U scikit-learn"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (0.24.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn) (1.21.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn) (1.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TF-IDF Feature Extraction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vec = TfidfVectorizer()\n",
    "tf_idf_ft = vec.fit_transform(rev_rat['review_body'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "class_val=rev_rat['class']\n",
    "amazoz_data = train_test_split(tf_idf_ft, \n",
    "                            class_val,\n",
    "                            test_size=0.2)\n",
    "\n",
    "train_x, test_x, train_y, test_y = amazoz_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Perceptron"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "perc = Perceptron(random_state=53,\n",
    "               max_iter=100000,\n",
    "               tol = 0.0001\n",
    "               )\n",
    "perc.fit(train_x, train_y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Perceptron(max_iter=100000, random_state=53, tol=0.0001)"
      ]
     },
     "metadata": {},
     "execution_count": 309
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "final_report = classification_report(perc.predict(test_x), test_y)\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "print('Perceptron Model')\n",
    "#print(accuracy_score(test_y,perc.predict(test_x) ) * 100,'%',\n",
    "#',',precision_score(test_y, perc.predict(test_x), average='macro') *100,'%',\n",
    "#',',recall_score(test_y,perc.predict(test_x) ) * 100,'%',\n",
    "#',',f1_score(test_y,perc.predict(test_x) ) * 100,'%',\n",
    "#',',accuracy_score(train_y,perc.predict(train_x) ) * 100,'%',\n",
    "#',',precision_score(train_y, perc.predict(train_x), average='macro') *100,'%',\n",
    "#',',recall_score(train_y,perc.predict(train_x) ) * 100,'%',\n",
    "#',',f1_score(train_y,perc.predict(train_x) ) * 100,'%')\n",
    "\n",
    "print('Accuracy of Test: ', accuracy_score(test_y,perc.predict(test_x) ) * 100,'%')\n",
    "print('Precision of Test: ',precision_score(test_y, perc.predict(test_x), average='macro') *100,'%')\n",
    "print('Recall of Test: ', recall_score(test_y,perc.predict(test_x) ) * 100,'%')\n",
    "print('F1 Score of Test: ', f1_score(test_y,perc.predict(test_x) ) * 100,'%')\n",
    "\n",
    "print('Accuracy of Train: ', accuracy_score(train_y,perc.predict(train_x) ) * 100,'%')\n",
    "print('Precision of Train: ',precision_score(train_y, perc.predict(train_x), average='macro') *100,'%')\n",
    "print('Recall of Train: ', recall_score(train_y,perc.predict(train_x) ) * 100,'%')\n",
    "print('F1 Score of Train: ', f1_score(train_y,perc.predict(train_x) ) * 100,'%')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Perceptron Model\n",
      "Accuracy of Test:  85.4275 %\n",
      "Precision of Test:  85.46517552113897 %\n",
      "Recall of Test:  87.06732216313836 %\n",
      "F1 Score of Test:  85.62196295108654 %\n",
      "Accuracy of Train:  93.16187500000001 %\n",
      "Precision of Train:  93.19302715779874 %\n",
      "Recall of Train:  94.4920440636475 %\n",
      "F1 Score of Train:  93.2568273005738 %\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm_model = LinearSVC(random_state=8)\n",
    "svm_model.fit(train_x, train_y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearSVC(random_state=8)"
      ]
     },
     "metadata": {},
     "execution_count": 359
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "source": [
    "print('SVM Model')\n",
    "#print(accuracy_score(test_y,svm_model.predict(test_x) ) * 100,'%',\n",
    "#',',precision_score(test_y, svm_model.predict(test_x), average='macro') *100,'%',\n",
    "#',',recall_score(test_y,svm_model.predict(test_x) ) * 100,'%',\n",
    "#',',f1_score(test_y,svm_model.predict(test_x) ) * 100,'%',\n",
    "#',',accuracy_score(train_y,svm_model.predict(train_x) ) * 100,'%',\n",
    "#',',precision_score(train_y, svm_model.predict(train_x), average='macro') *100,'%',\n",
    "#',',recall_score(train_y,svm_model.predict(train_x) ) * 100,'%',\n",
    "#',',f1_score(train_y,svm_model.predict(train_x) ) * 100,'%')\n",
    "\n",
    "print('Accuracy of Test: ', accuracy_score(test_y,svm_model.predict(test_x) ) * 100,'%')\n",
    "print('Precision of Test: ',precision_score(test_y, svm_model.predict(test_x), average='macro') *100,'%')\n",
    "print('Recall of Test: ', recall_score(test_y,svm_model.predict(test_x) ) * 100,'%')\n",
    "print('F1 Score of Test: ', f1_score(test_y,svm_model.predict(test_x) ) * 100,'%')\n",
    "\n",
    "print('Accuracy of Train: ', accuracy_score(train_y,svm_model.predict(train_x) ) * 100,'%')\n",
    "print('Precision of Train: ',precision_score(train_y, svm_model.predict(train_x), average='macro') *100,'%')\n",
    "print('Recall of Train: ', recall_score(train_y,svm_model.predict(train_x) ) * 100,'%')\n",
    "print('F1 Score of Train: ', f1_score(train_y,svm_model.predict(train_x) ) * 100,'%')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVM Model\n",
      "Accuracy of Test:  89.3475 %\n",
      "Precision of Test:  89.34906891308866 %\n",
      "Recall of Test:  89.03882813283836 %\n",
      "F1 Score of Test:  89.28292965114817 %\n",
      "Accuracy of Train:  94.03375 %\n",
      "Precision of Train:  94.0338741763167 %\n",
      "Recall of Train:  93.93375465241176 %\n",
      "F1 Score of Train:  94.03240729164062 %\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(max_iter=10000,solver='saga',tol=0.0001)\n",
    "log_reg.fit(train_x, train_y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, solver='saga')"
      ]
     },
     "metadata": {},
     "execution_count": 478
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "source": [
    "print('Logistic Regression Model')\n",
    "#print(accuracy_score(test_y,log_reg.predict(test_x) ) * 100,'%',\n",
    "#',',precision_score(test_y, log_reg.predict(test_x), average='macro') *100,'%',\n",
    "#',',recall_score(test_y,log_reg.predict(test_x) ) * 100,'%',\n",
    "#',',f1_score(test_y,log_reg.predict(test_x) ) * 100,'%',\n",
    "#',',accuracy_score(train_y,log_reg.predict(train_x) ) * 100,'%',\n",
    "#',',precision_score(train_y, log_reg.predict(train_x), average='macro') *100,'%',\n",
    "#',',recall_score(train_y,log_reg.predict(train_x) ) * 100,'%',\n",
    "#',',f1_score(train_y,log_reg.predict(train_x) ) * 100,'%')\n",
    "\n",
    "\n",
    "print('Accuracy of Test: ', accuracy_score(test_y,log_reg.predict(test_x) ) * 100,'%')\n",
    "print('Precision of Test: ',precision_score(test_y, log_reg.predict(test_x), average='macro') *100,'%')\n",
    "print('Recall of Test: ', recall_score(test_y,log_reg.predict(test_x) ) * 100,'%')\n",
    "print('F1 Score of Test: ', f1_score(test_y,log_reg.predict(test_x) ) * 100,'%')\n",
    "\n",
    "print('Accuracy of Train: ', accuracy_score(train_y,log_reg.predict(train_x) ) * 100,'%')\n",
    "print('Precision of Train: ',precision_score(train_y, log_reg.predict(train_x), average='macro') *100,'%')\n",
    "print('Recall of Train: ', recall_score(train_y,log_reg.predict(train_x) ) * 100,'%')\n",
    "print('F1 Score of Train: ', f1_score(train_y,log_reg.predict(train_x) ) * 100,'%')\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Logistic Regression Model\n",
      "Accuracy of Test:  89.58500000000001 %\n",
      "Precision of Test:  89.5887996961635 %\n",
      "Recall of Test:  89.10905989766229 %\n",
      "F1 Score of Test:  89.50418220296281 %\n",
      "Accuracy of Train:  91.31937500000001 %\n",
      "Precision of Train:  91.32108997598142 %\n",
      "Recall of Train:  90.9874353658232 %\n",
      "F1 Score of Train:  91.29701921811655 %\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Naive Bayes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "multi_nb = MultinomialNB()\n",
    "multi_nb.fit(train_x, train_y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "metadata": {},
     "execution_count": 486
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "source": [
    "print('Multinomial Naive Bayes Model')\n",
    "#print(accuracy_score(test_y,multi_nb.predict(test_x) ) * 100,'%',\n",
    "#',',precision_score(test_y, multi_nb.predict(test_x), average='macro') *100,'%',\n",
    "#',',recall_score(test_y,multi_nb.predict(test_x) ) * 100,'%',\n",
    "#',',f1_score(test_y,multi_nb.predict(test_x) ) * 100,'%',\n",
    "#',',accuracy_score(train_y,multi_nb.predict(train_x) ) * 100,'%',\n",
    "#',',precision_score(train_y, multi_nb.predict(train_x), average='macro') *100,'%',\n",
    "#',',recall_score(train_y,multi_nb.predict(train_x) ) * 100,'%',\n",
    "#',',f1_score(train_y,multi_nb.predict(train_x) ) * 100,'%')\n",
    "\n",
    "print('Accuracy of Test: ', accuracy_score(test_y,multi_nb.predict(test_x) ) * 100,'%')\n",
    "print('Precision of Test: ',precision_score(test_y, multi_nb.predict(test_x), average='macro') *100,'%')\n",
    "print('Recall of Test: ', recall_score(test_y,multi_nb.predict(test_x) ) * 100,'%')\n",
    "print('F1 Score of Test: ', f1_score(test_y,multi_nb.predict(test_x) ) * 100,'%')\n",
    "\n",
    "print('Accuracy of Train: ', accuracy_score(train_y,multi_nb.predict(train_x) ) * 100,'%')\n",
    "print('Precision of Train: ',precision_score(train_y, multi_nb.predict(train_x), average='macro') *100,'%')\n",
    "print('Recall of Train: ', recall_score(train_y,multi_nb.predict(train_x) ) * 100,'%')\n",
    "print('F1 Score of Train: ', f1_score(train_y,multi_nb.predict(train_x) ) * 100,'%')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Multinomial Naive Bayes Model\n",
      "Accuracy of Test:  86.815 %\n",
      "Precision of Test:  86.83457319324135 %\n",
      "Recall of Test:  85.66268686665998 %\n",
      "F1 Score of Test:  86.62304063308477 %\n",
      "Accuracy of Train:  89.08625 %\n",
      "Precision of Train:  89.1171864079181 %\n",
      "Recall of Train:  87.67516798641121 %\n",
      "F1 Score of Train:  88.93815961180302 %\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
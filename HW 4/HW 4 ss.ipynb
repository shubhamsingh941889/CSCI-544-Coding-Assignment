{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import os,sys\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from sklearn.utils import class_weight\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "cbab513a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/train\"\n",
    "dev_path = \"data/dev\"\n",
    "test_path = \"data/test\"\n",
    "unk = \"<unk>\"\n",
    "pad = \"<pad>\"\n",
    "num = \"<num>\"\n",
    "max_len = 128\n",
    "numbers = ['one','two','three','four','five', 'six','seven','eight','nine', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen', 'twenty', 'thirty', 'forty', 'fifty', 'sixty', 'seventy', 'eighty', 'ninety', 'zero', 'hundred', 'thousand', 'million', 'billion', 'trillion', 'quadrillion', 'quintillion', 'sextillion', 'septillion', 'octillion', 'nonillion', 'decillion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    f=open(os.path.join(sys.path[0],filename),\"r\")\n",
    "    lines=f.read().splitlines()\n",
    "    lst_sent =[]\n",
    "    for x in lines:\n",
    "        y = x.split()\n",
    "        #print(x.split())\n",
    "        if len(y)==3:\n",
    "            lst_sent.append(y)\n",
    "    f.close()\n",
    "#print(result)\n",
    "\n",
    "    return lst_sent\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = read_data(train_path)\n",
    "dev_set = read_data(dev_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "        if \",\" in s:\n",
    "            s = s.replace(\",\", \"\")\n",
    "        if \":\" in s:\n",
    "            s = s.replace(\":\", \"\")\n",
    "        if \"\\/\" in s:\n",
    "            s = s.replace(\"\\/\", \"\")\n",
    "        if \"-\" in s:\n",
    "            s = s.replace(\"-\", \"\")\n",
    "        if \"/\" in s:\n",
    "            s = s.replace(\"/\", \"\")\n",
    "        if s.lower() in numbers:\n",
    "            #print(s)\n",
    "            return True\n",
    "        elif s.isdecimal():\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "v = is_number('12,:/2')\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "tag_to_idx = {}\n",
    "idx_to_tag = {}\n",
    "just_tags = []\n",
    "idx = 0\n",
    "threshold = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in train_set:\n",
    "    word = line[1]\n",
    "    tag = line[2]\n",
    "    if is_number(word):\n",
    "        word = num\n",
    "    if word in vocab:\n",
    "        vocab[word] += 1\n",
    "    else:\n",
    "        vocab[word] = 1\n",
    "    if tag not in tag_to_idx:\n",
    "        tag_to_idx[tag] = idx\n",
    "        idx_to_tag[idx] = tag\n",
    "        idx += 1\n",
    "    just_tags.append(tag_to_idx[tag])\n",
    "for word, freq in  list(vocab.items()):\n",
    "    if freq < threshold:\n",
    "        del vocab[word]\n",
    "vocab[\"<unk>\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7703\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = {}\n",
    "idx_to_word = {}\n",
    "idx = 0\n",
    "for word in vocab:\n",
    "    if word not in word_to_idx:\n",
    "        word_to_idx[word] = idx\n",
    "        idx_to_word[idx] = word\n",
    "        idx += 1\n",
    "word_to_idx[pad] = idx\n",
    "idx_to_word[idx] = pad\n",
    "pad_idx = word_to_idx[pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "7703\n",
      "7703\n"
     ]
    }
   ],
   "source": [
    "print(word_to_idx['EU'])\n",
    "print(len(vocab))\n",
    "print(pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_creation(sentence):\n",
    "    global word_to_idx, tag_to_idx, unk, max_len\n",
    "    #sen_len = len(sentence)\n",
    "    pad_len = max_len - len(sentence)\n",
    "    words = np.array([])\n",
    "    tags = np.array([])\n",
    "    #print('sen:',sentence)\n",
    "    for idx, word, tag in sentence:\n",
    "        if word not in word_to_idx:\n",
    "            if is_number(word):\n",
    "                word = num\n",
    "\n",
    "            else:\n",
    "                word = unk\n",
    "        #print('word:',word)\n",
    "        words= np.append(words,word_to_idx[word])\n",
    "        tags= np.append(tags,tag_to_idx[tag])\n",
    "    #words = np.array(words)\n",
    "    #tags = np.array(tags)\n",
    "    #print('w,t:',words,tags)\n",
    "    pad_seq = pad_idx * np.ones(pad_len)\n",
    "    pad_tag = -1 * np.ones(pad_len)\n",
    "    words = np.concatenate((words, pad_seq), axis = 0)\n",
    "    tags = np.concatenate((tags, pad_tag), axis = 0)\n",
    "    return words, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_ip(dataset):\n",
    "    x_lstm = []\n",
    "    y_lstm = []\n",
    "    sentence = []\n",
    "    sentence.append(dataset[0])\n",
    "    j = 0\n",
    "    for i in range(1,len(dataset)):\n",
    "        #print(sentence)\n",
    "        \n",
    "        \n",
    "        if dataset[i][0] != '1':\n",
    "            sentence.append(dataset[i])\n",
    "        else:\n",
    "            x, y = dataset_creation(sentence)\n",
    "            #print('xy:',x,y)\n",
    "            x_lstm.append(x)\n",
    "            y_lstm.append(y)\n",
    "            #print(x_lstm)\n",
    "            sentence = []\n",
    "            sentence.append(dataset[i])\n",
    "\n",
    "    #print(x_lstm)  \n",
    "    return np.array(x_lstm), np.array(y_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lstm_train, y_lstm_train = create_lstm_ip(train_set)\n",
    "x_lstm_dev, y_lstm_dev = create_lstm_ip(dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "6958e52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x_lstm_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "0bc5e760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.100e+01 1.500e+01 7.200e+01 4.700e+01 7.300e+01 4.800e+01 7.400e+01\n",
      " 7.500e+01 7.600e+01 1.800e+01 4.800e+01 7.700e+01 7.800e+01 7.900e+01\n",
      " 4.800e+01 8.000e+01 1.800e+01 4.000e+01 3.000e+01 8.100e+01 8.200e+01\n",
      " 3.500e+01 1.300e+01 3.600e+01 7.000e+00 7.703e+03 7.703e+03 7.703e+03\n",
      " 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03\n",
      " 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03\n",
      " 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03\n",
      " 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03\n",
      " 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03\n",
      " 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03\n",
      " 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03\n",
      " 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03\n",
      " 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03\n",
      " 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03\n",
      " 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03\n",
      " 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03\n",
      " 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03\n",
      " 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03 7.703e+03\n",
      " 7.703e+03 7.703e+03]\n"
     ]
    }
   ],
   "source": [
    "print(x_lstm_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class data(Dataset):\n",
    "    def __init__(self, inputs, transform = None):\n",
    "        self.data = inputs\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        inputs = self.data[index][0]\n",
    "        label = self.data[index][1]\n",
    "        if self.transform is not None:\n",
    "            inputs = self.transform(inputs)\n",
    "            \n",
    "        return inputs, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lstm_train, x_lstm_dev = torch.LongTensor(x_lstm_train), torch.LongTensor(x_lstm_dev)\n",
    "y_lstm_train, y_lstm_dev = torch.LongTensor(y_lstm_train), torch.LongTensor(y_lstm_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c333b3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-ORG': 0, 'O': 1, 'B-MISC': 2, 'B-PER': 3, 'I-PER': 4, 'B-LOC': 5, 'I-ORG': 6, 'I-MISC': 7, 'I-LOC': 8}\n"
     ]
    }
   ],
   "source": [
    "print(tag_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "86fe4b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14986\n"
     ]
    }
   ],
   "source": [
    "print(len(x_lstm_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fc281f87310>\n"
     ]
    }
   ],
   "source": [
    "lstm_train_dataset = TensorDataset(x_lstm_train, y_lstm_train)\n",
    "#print(len(lstm_train_dataset))\n",
    "lstm_train_dataset = data(lstm_train_dataset)\n",
    "\n",
    "lstm_dev_dataset = TensorDataset(x_lstm_dev, y_lstm_dev)\n",
    "lstm_dev_dataset = data(lstm_dev_dataset)\n",
    "\n",
    "lstm_train_loader = DataLoader(lstm_train_dataset, batch_size = 8, drop_last = True, shuffle = True)\n",
    "print(lstm_train_loader)\n",
    "lstm_dev_loader = DataLoader(lstm_dev_dataset, batch_size = 8, drop_last = True, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(word_to_idx)\n",
    "embed_dim = 100\n",
    "hidden_dim = 256\n",
    "linear_dim = 128\n",
    "output_dim = len(tag_to_idx)\n",
    "pad_idx = word_to_idx[pad]\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(just_tags), just_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "fd04d7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-ORG': 0, 'O': 1, 'B-MISC': 2, 'B-PER': 3, 'I-PER': 4, 'B-LOC': 5, 'I-ORG': 6, 'I-MISC': 7, 'I-LOC': 8}\n",
      "[ 3.59589727  0.13329307  6.61130502  3.44388889  5.01980271  3.1834267\n",
      "  6.13651908 19.67936508 19.64534716]\n"
     ]
    }
   ],
   "source": [
    "print(tag_to_idx)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bLSTM(torch.nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, hidden_dim, linear_dim, output_dim, pad_idx):\n",
    "        super(bLSTM, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_embeddings = input_dim, embedding_dim = embed_dim, padding_idx = pad_idx)\n",
    "        self.LSTM_dropout = torch.nn.Dropout(0.33)\n",
    "        self.lstm = torch.nn.LSTM(input_size = embed_dim, hidden_size = hidden_dim, num_layers = 1, bidirectional = True)\n",
    "        self.fc = torch.nn.Linear(hidden_dim * 2, linear_dim)\n",
    "        self.out = torch.nn.Linear(linear_dim, output_dim)\n",
    "        self.elu = torch.nn.ELU()\n",
    "    def forward(self, x):\n",
    "        embedding_out = self.LSTM_dropout(self.embedding(x))\n",
    "        lstm_out, _ = self.lstm(embedding_out)\n",
    "        fc_in = self.LSTM_dropout(lstm_out)\n",
    "        fc_out = self.fc(fc_in)\n",
    "        output = self.out(self.elu(fc_out))\n",
    "        return torch.softmax(output)\n",
    "    def init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            torch.nn.init.normal_(param.data, mean=0, std=0.1)\n",
    "\n",
    "    def init_embeddings(self, word_pad_idx):\n",
    "        self.embedding.weight.data[pad_idx] = torch.zeros(self.embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, optimizer, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bLSTM(\n",
      "  (embedding): Embedding(7704, 100, padding_idx=7703)\n",
      "  (LSTM_dropout): Dropout(p=0.33, inplace=False)\n",
      "  (lstm): LSTM(100, 256, bidirectional=True)\n",
      "  (fc): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (out): Linear(in_features=128, out_features=9, bias=True)\n",
      "  (elu): ELU(alpha=1.0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = bLSTM(input_dim, embed_dim, hidden_dim, linear_dim, output_dim, pad_idx)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = torch.FloatTensor(class_weights)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight = class_weights, ignore_index = -1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ip: tensor([[7702,  544,  261,  ..., 7703, 7703, 7703],\n",
      "        [  71,   15,  346,  ..., 7703, 7703, 7703],\n",
      "        [5294,   48, 2785,  ..., 7703, 7703, 7703],\n",
      "        ...,\n",
      "        [7654, 7655, 1066,  ..., 7703, 7703, 7703],\n",
      "        [7702,  103, 1635,  ..., 7703, 7703, 7703],\n",
      "        [ 988,   11, 7703,  ..., 7703, 7703, 7703]])  t: tensor([[ 3,  1,  1,  ..., -1, -1, -1],\n",
      "        [ 1,  1,  1,  ..., -1, -1, -1],\n",
      "        [ 3,  1,  1,  ..., -1, -1, -1],\n",
      "        ...,\n",
      "        [ 1,  1,  1,  ..., -1, -1, -1],\n",
      "        [ 1,  1,  3,  ..., -1, -1, -1],\n",
      "        [ 5,  1, -1,  ..., -1, -1, -1]])\n",
      "op: tensor([[[-6.6658e-02,  6.8406e-02, -7.1835e-02,  ..., -4.5560e-02,\n",
      "          -5.1182e-02, -3.1826e-02],\n",
      "         [-7.4208e-02, -1.3199e-02, -5.8881e-02,  ..., -8.0428e-02,\n",
      "          -7.9540e-02, -6.8284e-02],\n",
      "         [-9.9876e-03,  2.0948e-02,  5.3568e-02,  ..., -1.1345e-01,\n",
      "          -2.9239e-02, -2.0851e-02],\n",
      "         ...,\n",
      "         [-6.6707e-02,  3.7815e-02, -3.6454e-02,  ..., -6.4429e-02,\n",
      "          -6.1701e-02, -2.8237e-03],\n",
      "         [-7.0760e-02,  3.8615e-02, -4.2353e-02,  ..., -6.8293e-02,\n",
      "          -6.0232e-02, -4.3751e-03],\n",
      "         [-6.3155e-02,  3.3016e-02, -3.2478e-02,  ..., -6.6368e-02,\n",
      "          -6.5158e-02, -3.8738e-04]],\n",
      "\n",
      "        [[-7.3139e-02, -7.0685e-02, -8.0946e-02,  ..., -8.9941e-02,\n",
      "          -3.6017e-02, -7.0430e-02],\n",
      "         [-1.1396e-01,  4.8995e-03, -1.4302e-02,  ..., -5.9210e-02,\n",
      "          -3.1912e-02, -3.4353e-02],\n",
      "         [ 9.0754e-03,  6.5771e-02,  3.5794e-03,  ..., -3.6591e-02,\n",
      "          -1.3592e-02, -5.7800e-02],\n",
      "         ...,\n",
      "         [-6.2021e-02,  3.4113e-02, -3.5895e-02,  ..., -6.5354e-02,\n",
      "          -6.6818e-02, -5.2709e-03],\n",
      "         [-6.3663e-02,  4.1120e-02, -3.2559e-02,  ..., -5.8712e-02,\n",
      "          -5.1457e-02,  9.5853e-05],\n",
      "         [-6.0561e-02,  4.0054e-02, -3.2117e-02,  ..., -6.0100e-02,\n",
      "          -6.9066e-02, -5.0725e-03]],\n",
      "\n",
      "        [[-8.2483e-02, -4.7643e-02, -1.6008e-02,  ..., -1.1055e-01,\n",
      "          -7.2109e-02, -1.2850e-02],\n",
      "         [-1.0408e-01,  3.3317e-02, -2.1070e-02,  ..., -7.4722e-02,\n",
      "          -2.2424e-02, -4.4780e-02],\n",
      "         [-3.4527e-02,  2.4133e-02,  5.3112e-02,  ..., -2.1280e-02,\n",
      "          -8.8125e-03, -5.2088e-02],\n",
      "         ...,\n",
      "         [-6.5818e-02,  3.7990e-02, -4.6735e-02,  ..., -6.7160e-02,\n",
      "          -7.3928e-02,  7.8381e-04],\n",
      "         [-5.9005e-02,  2.6024e-02, -4.0097e-02,  ..., -7.0545e-02,\n",
      "          -5.8004e-02, -1.3103e-02],\n",
      "         [-5.5637e-02,  4.2288e-02, -4.3498e-02,  ..., -6.7721e-02,\n",
      "          -7.3313e-02, -2.0016e-04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1393e-01,  3.4052e-02, -2.8833e-02,  ..., -5.9849e-02,\n",
      "          -7.5480e-02, -3.4444e-02],\n",
      "         [-7.8293e-02,  5.1702e-02, -1.0487e-01,  ..., -8.5228e-03,\n",
      "           9.0703e-03, -7.4550e-03],\n",
      "         [-4.5288e-02,  8.6975e-03, -7.0255e-02,  ..., -6.1865e-03,\n",
      "          -7.7343e-02, -2.4142e-02],\n",
      "         ...,\n",
      "         [-6.5415e-02,  3.4321e-02, -4.0680e-02,  ..., -6.5292e-02,\n",
      "          -5.8531e-02, -3.5834e-03],\n",
      "         [-6.2739e-02,  4.3892e-02, -3.9003e-02,  ..., -6.0268e-02,\n",
      "          -5.7237e-02, -7.6127e-04],\n",
      "         [-7.3205e-02,  3.9160e-02, -3.8235e-02,  ..., -5.8951e-02,\n",
      "          -6.5325e-02, -4.7883e-03]],\n",
      "\n",
      "        [[-6.9988e-02,  4.6865e-02,  7.5661e-03,  ..., -4.7378e-02,\n",
      "          -8.1040e-02, -4.0198e-02],\n",
      "         [-2.5373e-02, -3.5342e-02, -2.4624e-02,  ..., -1.2769e-02,\n",
      "          -7.7761e-02,  3.6307e-02],\n",
      "         [-1.2184e-01,  1.8143e-02, -1.0660e-02,  ..., -3.8437e-02,\n",
      "          -8.9603e-02, -2.6491e-02],\n",
      "         ...,\n",
      "         [-6.2437e-02,  3.6361e-02, -4.4879e-02,  ..., -6.5040e-02,\n",
      "          -6.3962e-02, -4.7713e-03],\n",
      "         [-6.2840e-02,  4.0150e-02, -4.4085e-02,  ..., -6.8062e-02,\n",
      "          -6.2027e-02, -6.1717e-03],\n",
      "         [-6.7709e-02,  3.3233e-02, -3.2340e-02,  ..., -5.9532e-02,\n",
      "          -6.7918e-02, -5.8217e-03]],\n",
      "\n",
      "        [[-2.6060e-02, -1.8374e-02,  2.5405e-02,  ..., -6.2269e-02,\n",
      "          -1.2468e-01, -5.3993e-02],\n",
      "         [-3.2995e-02,  1.8893e-02, -1.2433e-01,  ..., -6.5559e-02,\n",
      "          -5.1465e-02,  1.2322e-02],\n",
      "         [-7.0636e-02,  2.1119e-02, -2.2347e-02,  ..., -3.3156e-02,\n",
      "          -7.1256e-02, -2.6001e-02],\n",
      "         ...,\n",
      "         [-5.9090e-02,  4.1408e-02, -4.0353e-02,  ..., -4.9971e-02,\n",
      "          -7.2921e-02, -1.2064e-02],\n",
      "         [-5.7386e-02,  3.7682e-02, -2.7936e-02,  ..., -5.5917e-02,\n",
      "          -6.5429e-02, -9.3508e-03],\n",
      "         [-6.3730e-02,  3.6131e-02, -2.9518e-02,  ..., -5.7527e-02,\n",
      "          -5.8972e-02, -4.7804e-03]]], grad_fn=<AddBackward0>)\n",
      "ip: tensor([[2370, 6459,  111,  ..., 7703, 7703, 7703],\n",
      "        [ 873,   62,  678,  ..., 7703, 7703, 7703],\n",
      "        [2854,   11,   11,  ..., 7703, 7703, 7703],\n",
      "        ...,\n",
      "        [2328,   11, 5621,  ..., 7703, 7703, 7703],\n",
      "        [1183,   11, 7703,  ..., 7703, 7703, 7703],\n",
      "        [ 246,   35,  247,  ..., 7703, 7703, 7703]])  t: tensor([[ 3,  4,  1,  ..., -1, -1, -1],\n",
      "        [ 2,  1,  1,  ..., -1, -1, -1],\n",
      "        [ 0,  1,  1,  ..., -1, -1, -1],\n",
      "        ...,\n",
      "        [ 0,  1,  0,  ..., -1, -1, -1],\n",
      "        [ 5,  1, -1,  ..., -1, -1, -1],\n",
      "        [ 1,  1,  1,  ..., -1, -1, -1]])\n",
      "op: tensor([[[-4.7015e-02,  2.6217e-02, -2.0344e-02,  ..., -1.1343e-01,\n",
      "          -4.3906e-02, -1.1028e-02],\n",
      "         [-9.3430e-02,  2.4174e-02, -2.0251e-02,  ..., -9.1689e-02,\n",
      "          -8.2055e-02,  1.3103e-02],\n",
      "         [-1.0171e-01,  7.6526e-02, -5.3343e-02,  ..., -1.2026e-01,\n",
      "          -6.4047e-02,  1.0206e-02],\n",
      "         ...,\n",
      "         [-6.6329e-02,  3.2652e-02, -4.6357e-02,  ..., -7.0630e-02,\n",
      "          -6.7114e-02, -7.2393e-04],\n",
      "         [-4.9762e-02,  2.9016e-02, -3.9566e-02,  ..., -6.5390e-02,\n",
      "          -7.1728e-02, -8.0868e-03],\n",
      "         [-6.0344e-02,  3.7372e-02, -2.6383e-02,  ..., -6.6106e-02,\n",
      "          -5.8085e-02,  4.9125e-03]],\n",
      "\n",
      "        [[ 1.2861e-02,  1.1709e-02,  1.6581e-02,  ..., -1.1449e-01,\n",
      "          -9.6881e-02, -1.9981e-02],\n",
      "         [-9.3154e-02,  5.9568e-02,  1.0403e-02,  ..., -1.2805e-01,\n",
      "          -7.2295e-02,  7.6470e-02],\n",
      "         [-7.2118e-02,  3.1290e-03, -6.3976e-02,  ..., -7.2075e-02,\n",
      "          -1.2021e-01,  2.8772e-02],\n",
      "         ...,\n",
      "         [-7.1224e-02,  2.3085e-02, -3.1027e-02,  ..., -6.5327e-02,\n",
      "          -5.9107e-02, -1.4412e-03],\n",
      "         [-5.7912e-02,  2.9750e-02, -4.1888e-02,  ..., -6.7810e-02,\n",
      "          -6.1288e-02, -3.5495e-03],\n",
      "         [-6.6785e-02,  3.6771e-02, -2.6207e-02,  ..., -5.9613e-02,\n",
      "          -6.0375e-02,  2.5500e-04]],\n",
      "\n",
      "        [[-3.5963e-02, -1.6577e-02,  6.2714e-02,  ..., -5.8386e-02,\n",
      "          -1.9838e-02,  2.5972e-02],\n",
      "         [-3.8007e-02, -2.1882e-02, -5.1911e-02,  ..., -1.0802e-01,\n",
      "          -1.2142e-01,  1.8789e-02],\n",
      "         [-1.1675e-02,  1.2257e-02, -7.6984e-02,  ..., -5.5390e-02,\n",
      "          -1.4996e-01,  3.8531e-02],\n",
      "         ...,\n",
      "         [-6.4353e-02,  3.8551e-02, -4.4502e-02,  ..., -7.5465e-02,\n",
      "          -5.9700e-02, -6.7144e-03],\n",
      "         [-6.2207e-02,  3.0268e-02, -3.1901e-02,  ..., -6.6946e-02,\n",
      "          -6.6768e-02, -1.7229e-02],\n",
      "         [-6.1877e-02,  4.2261e-02, -4.1225e-02,  ..., -7.2319e-02,\n",
      "          -5.8248e-02, -8.5907e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.4719e-02, -6.8056e-03, -1.1748e-02,  ..., -3.0020e-02,\n",
      "          -1.9544e-02, -6.4684e-02],\n",
      "         [-7.5620e-02,  4.6913e-02, -6.9994e-02,  ..., -8.9572e-02,\n",
      "          -1.2157e-01, -1.4567e-02],\n",
      "         [-4.1239e-02,  1.2674e-01, -3.4667e-02,  ..., -1.5484e-02,\n",
      "          -8.2596e-02,  1.4139e-05],\n",
      "         ...,\n",
      "         [-7.4098e-02,  4.3075e-02, -3.3797e-02,  ..., -5.4150e-02,\n",
      "          -6.3244e-02, -1.0392e-02],\n",
      "         [-6.9116e-02,  4.9692e-02, -4.0121e-02,  ..., -5.4201e-02,\n",
      "          -6.1944e-02, -7.2251e-03],\n",
      "         [-6.2349e-02,  4.7713e-02, -3.6835e-02,  ..., -6.5208e-02,\n",
      "          -5.7079e-02, -6.9444e-03]],\n",
      "\n",
      "        [[-4.9390e-02,  2.6012e-02, -1.0655e-01,  ..., -7.0041e-02,\n",
      "          -1.1083e-02, -4.3955e-02],\n",
      "         [-2.5315e-02,  7.6843e-02, -2.2023e-02,  ..., -5.0518e-02,\n",
      "          -8.4227e-02,  6.9847e-02],\n",
      "         [-4.6666e-02,  4.9215e-02, -3.7686e-02,  ..., -5.3296e-02,\n",
      "          -7.9034e-02,  1.7487e-02],\n",
      "         ...,\n",
      "         [-6.3674e-02,  2.9126e-02, -3.5312e-02,  ..., -6.8012e-02,\n",
      "          -6.2763e-02, -6.0815e-03],\n",
      "         [-6.2488e-02,  4.3514e-02, -4.5258e-02,  ..., -6.3397e-02,\n",
      "          -5.2351e-02, -3.5705e-03],\n",
      "         [-6.9266e-02,  3.3339e-02, -3.3388e-02,  ..., -5.3904e-02,\n",
      "          -6.5279e-02, -1.1591e-02]],\n",
      "\n",
      "        [[-1.0291e-01,  7.6966e-02, -1.1605e-01,  ..., -3.8896e-02,\n",
      "          -4.1705e-02, -9.6974e-03],\n",
      "         [-6.7182e-02,  1.0044e-01, -7.8541e-02,  ..., -8.2190e-02,\n",
      "          -9.3316e-02, -7.4272e-02],\n",
      "         [-1.9243e-02,  6.2750e-02,  5.8118e-03,  ..., -1.7277e-02,\n",
      "          -1.4759e-01,  5.8755e-02],\n",
      "         ...,\n",
      "         [-6.1300e-02,  3.0093e-02, -3.0505e-02,  ..., -5.7852e-02,\n",
      "          -6.2391e-02, -9.7577e-03],\n",
      "         [-6.3437e-02,  3.9520e-02, -2.7017e-02,  ..., -5.7351e-02,\n",
      "          -6.1480e-02, -1.7888e-03],\n",
      "         [-6.5700e-02,  3.2879e-02, -2.8099e-02,  ..., -6.1419e-02,\n",
      "          -5.4128e-02, -1.2152e-02]]], grad_fn=<AddBackward0>)\n",
      "Epoch: 1 \tTraining Loss: 0.000292 \tDev Set Loss: 0.000000\n",
      "Validation loss decreased (inf --> 0.000000). Saving model...\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "dev_min_loss = np.inf\n",
    "train_loader = lstm_train_loader\n",
    "dev_loader = lstm_dev_loader\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    dev_loss = 0.0\n",
    "    batch = 0\n",
    "    j = 0\n",
    "    for inputs, target in train_loader:\n",
    "        if j==2:\n",
    "            break\n",
    "        j+=1\n",
    "        print(batch, end = \"\\r\")\n",
    "        batch += 1\n",
    "        inputs, target = inputs, target\n",
    "        print('ip:',inputs,' t:',target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inputs)\n",
    "        print('op:',output)\n",
    "        output = output.view(-1, output.shape[-1])\n",
    "        target = target.view(-1)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    for inputs, target in dev_loader:\n",
    "        if j==2:\n",
    "            break\n",
    "        j+=1\n",
    "        inputs, target = inputs, target\n",
    "        #inputs, target = inputs, target\n",
    "        output = model(inputs)\n",
    "        output = output.view(-1, output.shape[-1])\n",
    "        target = target.view(-1)\n",
    "        loss = loss_fn(output, target)\n",
    "        dev_loss += loss.item()\n",
    "    \n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    dev_loss = dev_loss/len(dev_loader.dataset)\n",
    "    \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tDev Set Loss: {:.6f}'.format(epoch+1, train_loss,dev_loss))\n",
    "    if dev_loss <= dev_min_loss:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}). Saving model...'.format(dev_min_loss, dev_loss))\n",
    "        torch.save(model.state_dict(), 'simple_blstm.pt')\n",
    "        dev_min_loss = dev_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sentence(x):\n",
    "    global idx_to_word\n",
    "    sent = ''\n",
    "    for idx in x:\n",
    "        if idx != pad_idx:\n",
    "            sent = sent + \" \" + idx_to_word[idx]\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_op_file(x, y, model, dataset):\n",
    "    model.load_state_dict(torch.load('simple_blstm.pt'))\n",
    "    model.eval()\n",
    "    line_num = 0\n",
    "    global idx_to_word, idx_to_tag\n",
    "    with torch.no_grad():\n",
    "        with open(\"output\", \"w\") as fp:\n",
    "            for i in range(len(x)):\n",
    "                print(i, end = \"\\r\")\n",
    "                idx = 1\n",
    "                ip = x[i]\n",
    "                ip = torch.unsqueeze(ip, 0)\n",
    "                op = model(ip)\n",
    "                op = op.view(-1, op.shape[-1])\n",
    "                target = y[i]\n",
    "                _, pred = torch.max(op, 1)\n",
    "                for j in range(len(target)):\n",
    "                    if target[j] == -1:\n",
    "                        fp.write(\"\\n\")\n",
    "                        break\n",
    "                    pred_tag = int(pred[j].item())\n",
    "                    targ_tag = int(target[j].item())\n",
    "                    z = int(x[i][j].item())\n",
    "                    z = idx_to_word[z]\n",
    "                    if z != dataset[line_num][1]:\n",
    "                        z = dataset[line_num][1]\n",
    "                    fp.write(\"{} {} {} {}\\n\".format(idx, z, idx_to_tag[targ_tag], idx_to_tag[pred_tag]))\n",
    "                    idx += 1\n",
    "                    line_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e00b2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "model = bLSTM(input_dim, embed_dim, hidden_dim, linear_dim, output_dim, pad_idx)\n",
    "create_op_file(x_lstm_train, y_lstm_train, model, train_set)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

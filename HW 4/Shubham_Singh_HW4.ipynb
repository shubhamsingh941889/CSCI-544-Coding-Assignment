{"cells":[{"cell_type":"code","execution_count":1,"id":"u3JZdSi8QhWq","metadata":{"executionInfo":{"elapsed":26908,"status":"ok","timestamp":1636757541791,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"u3JZdSi8QhWq"},"outputs":[],"source":["from gensim.models import Word2Vec, KeyedVectors\n","from collections import Counter\n","from torch.utils.data import DataLoader, TensorDataset, Dataset\n","from sklearn.utils import class_weight\n","import torch\n","from gensim.scripts.glove2word2vec import glove2word2vec\n","import pandas as pd\n","import numpy as np\n","import random\n","import re\n","import os,sys\n","import gensim\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","from torch.optim.lr_scheduler import ReduceLROnPlateau as lr_scheduler\n","from torch.optim.lr_scheduler import StepLR\n","import num2words\n","from num2words import num2words\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","unknown_tag = \"<unknown_tag>\"\n","number_tag = \"<number_tag>\"\n","curr_batch_len = 8\n"]},{"cell_type":"code","execution_count":2,"id":"ddd88229","metadata":{"executionInfo":{"elapsed":354,"status":"ok","timestamp":1636757549386,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"ddd88229"},"outputs":[],"source":["my_num_list = []\n","for i in range(100):\n","    my_num_list.append(num2words(i))\n","other_number = ['hundred', 'thousand', 'million', 'billion', 'trillion', 'quadrillion', 'quintillion', 'sextillion', 'septillion', 'octillion', 'nonillion', 'decillion']\n","for i in other_number:\n","    my_num_list.append(i)\n","\n","   \n","    "]},{"cell_type":"code","execution_count":3,"id":"Lea_g39yQhWw","metadata":{"executionInfo":{"elapsed":287,"status":"ok","timestamp":1636757553247,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"Lea_g39yQhWw"},"outputs":[],"source":["def process_input(filename):\n","\n","    f=open(os.path.join(sys.path[0],filename),\"r\")\n","    lines=f.read().splitlines()\n","    curr_sentence =[]\n","    curr_word = []\n","    get_all_words = []\n","    for x in lines:\n","        y = x.split()\n","\n","        if len(y)==3:\n","            curr_sentence.append(y)\n","            curr_word.append(y[1])\n","        else:\n","          get_all_words.append(curr_word)\n","          curr_word = []\n","    get_all_words.append(curr_word)\n","        \n","    f.close()\n","\n","\n","    return curr_sentence,get_all_words\n","    "]},{"cell_type":"code","execution_count":4,"id":"7b0oAxpKQhWx","metadata":{"executionInfo":{"elapsed":3177,"status":"ok","timestamp":1636757565534,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"7b0oAxpKQhWx"},"outputs":[],"source":["pre_train,pre_train_words = process_input(\"train\")\n","pre_dev,pre_dev_words = process_input(\"dev\")\n"]},{"cell_type":"code","execution_count":6,"id":"oSMqq8p1Qiws","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1636757568522,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"oSMqq8p1Qiws"},"outputs":[],"source":["def process_test_input(filename):\n","    f=open(os.path.join(sys.path[0],filename),\"r\")\n","    lines=f.read().splitlines()\n","    curr_sentence =[]\n","    curr_word = []\n","    get_all_words = []\n","    for x in lines:\n","        y = x.split()\n","        if len(y)==2:\n","            curr_sentence.append(y)\n","            curr_word.append(y[1])\n","        else:\n","          get_all_words.append(curr_word)\n","          curr_word = []\n","        \n","    get_all_words.append(curr_word)\n","    f.close()\n","\n","\n","    return curr_sentence,get_all_words\n","    "]},{"cell_type":"code","execution_count":7,"id":"1vBTndzBQaFO","metadata":{"executionInfo":{"elapsed":701,"status":"ok","timestamp":1636757574108,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"1vBTndzBQaFO"},"outputs":[],"source":["pre_test,pre_test_words = process_test_input(\"test\")"]},{"cell_type":"code","execution_count":8,"id":"NC7PN-7vQhWx","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1636757576623,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"NC7PN-7vQhWx"},"outputs":[],"source":["def chk_num_tag(given_string):\n","    try:\n","        \n","        f=filter(str.isalnum,given_string)\n","        given_string=\"\".join(f)\n","        \n","        if given_string.lower() in my_num_list:\n","            \n","            return True\n","        \n","        elif given_string.isdecimal():\n","            return True\n","        \n","        float(given_string)\n","        return True\n","    except ValueError:\n","            return False\n","        \n","    "]},{"cell_type":"code","execution_count":9,"id":"eJHjioSNQhW1","metadata":{"executionInfo":{"elapsed":1082,"status":"ok","timestamp":1636757579912,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"eJHjioSNQhW1"},"outputs":[],"source":["curr_indx = 0\n","all_ner_tags = []\n","my_vocab = {}\n","wordidx_dict = {}\n","tagidx_dict = {}\n","\n","for curr_line in pre_train:\n","    my_word = curr_line[1]\n","    my_tag = curr_line[2]\n","    if chk_num_tag(my_word):\n","        my_word = number_tag\n","    if my_word in my_vocab:\n","        my_vocab[my_word] += 1\n","    else:\n","        my_vocab[my_word] = 1\n","    if my_tag not in tagidx_dict:\n","        tagidx_dict[my_tag] = curr_indx\n","        \n","        curr_indx += 1\n","    all_ner_tags.append(tagidx_dict[my_tag])\n","\n","my_vocab[\"<unknown_tag>\"] = 0\n","\n","\n","curr_indx = 0\n","for my_word in my_vocab:\n","    if my_word not in wordidx_dict:\n","        wordidx_dict[my_word] = curr_indx\n","        \n","        curr_indx += 1\n"]},{"cell_type":"code","execution_count":12,"id":"lhTUhI-GQhW2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1636757579913,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"lhTUhI-GQhW2","outputId":"5b09df1e-3eff-4e86-974a-160f6c41b4a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["20178\n","{'B-ORG': 0, 'O': 1, 'B-MISC': 2, 'B-PER': 3, 'I-PER': 4, 'B-LOC': 5, 'I-ORG': 6, 'I-MISC': 7, 'I-LOC': 8}\n"]}],"source":["print(len(my_vocab))\n","print(tagidx_dict)"]},{"cell_type":"code","execution_count":13,"id":"HMcThIL-QhW4","metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1636757582559,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"HMcThIL-QhW4"},"outputs":[],"source":["def make_x_y_blstm(pre_data):\n","    blstm_word_idx = []\n","    blstm_tag_idx = []\n","    list_of_sen = []\n","    list_of_sen.append(pre_data[0])\n","    for i in range(1,len(pre_data)):\n","        if pre_data[i][0] != '1':\n","            list_of_sen.append(pre_data[i])\n","        else:\n","            words = np.array([])\n","            tags = np.array([])\n","            my_word =''\n","            for curr_indx in range(len(list_of_sen)):\n","                my_word = list_of_sen[curr_indx][1]\n","                if my_word not in wordidx_dict:\n","         \n","                    if chk_num_tag(list_of_sen[curr_indx][1]):\n","                        my_word  = number_tag\n","\n","                    else:\n","                        my_word  = unknown_tag\n","       \n","                words= np.append(words,wordidx_dict[my_word])\n","                tags= np.append(tags,tagidx_dict[list_of_sen[curr_indx][2]])            \n","            \n","            blstm_word_idx.append(words)\n","            blstm_tag_idx.append(tags)\n","\n","            list_of_sen = []\n","            list_of_sen.append(pre_data[i])\n","    \n","    \n","    blstm_word_idx.append(np.array([257.]))\n","    blstm_tag_idx.append(np.array([1]))\n","\n","    return np.array(blstm_word_idx), np.array(blstm_tag_idx)"]},{"cell_type":"code","execution_count":14,"id":"qELeULcKQhW5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4222,"status":"ok","timestamp":1636757588581,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"qELeULcKQhW5","outputId":"3e5cb66f-88d5-4c7d-fb88-30063492fb74"},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/17/jys7jgwn3x37cltk9w8j0l080000gq/T/ipykernel_59682/258108467.py:36: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  return np.array(blstm_word_idx), np.array(blstm_tag_idx)\n"]}],"source":["train_blstm_x, train_blstm_y = make_x_y_blstm(pre_train)\n","dev_blstm_x, dev_blstm_y = make_x_y_blstm(pre_dev)"]},{"cell_type":"code","execution_count":22,"id":"1757736c","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[ 9. 10.]\n"]}],"source":["print(train_blstm_x[1])"]},{"cell_type":"code","execution_count":23,"id":"rVPIV99ZgL3L","metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1636757591898,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"rVPIV99ZgL3L"},"outputs":[],"source":["class PadSequence:\n","    def __call__(self, batch):\n","      sorted_batch = sorted(batch, key=lambda x: x[0].shape[0], reverse=True)\n","      sequences = [torch.LongTensor(x[0]) for x in sorted_batch]\n","      sequences_padded = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True,padding_value=0)\n","      lengths = torch.LongTensor([len(x) for x in sequences])\n","      labels = [torch.LongTensor(x[1]) for x in sorted_batch]\n","      labels_padded = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True,padding_value=-1)\n","      return torch.LongTensor(sequences_padded),  torch.LongTensor(labels_padded),lengths\n","\n","\n","      "]},{"cell_type":"code","execution_count":24,"id":"7JqNk8k0Wj5s","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1636757592481,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"7JqNk8k0Wj5s"},"outputs":[],"source":["task1_train_dataset = list(zip(train_blstm_x,train_blstm_y))\n","task1_dev_dataset = list(zip(dev_blstm_x,dev_blstm_y))\n","\n","task1_train_loader = DataLoader(task1_train_dataset, batch_size = curr_batch_len, drop_last = True, shuffle = True,collate_fn=PadSequence())\n","task1_dev_loader = DataLoader(task1_dev_dataset, batch_size = curr_batch_len, drop_last = True, shuffle = True,collate_fn=PadSequence())\n"]},{"cell_type":"code","execution_count":28,"id":"1FVBUZMZaoBJ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1636757592788,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"1FVBUZMZaoBJ","outputId":"afc2e3eb-09ff-4671-e2cf-03a6c0c9cdd8"},"outputs":[{"ename":"TypeError","evalue":"'DataLoader' object is not subscriptable","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/var/folders/17/jys7jgwn3x37cltk9w8j0l080000gq/T/ipykernel_59682/626578283.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask1_train_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"]}],"source":["print((task1_train_loader[0]))"]},{"cell_type":"code","execution_count":52,"id":"NQ20pZFMQhW6","metadata":{"executionInfo":{"elapsed":340,"status":"ok","timestamp":1636758453861,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"NQ20pZFMQhW6"},"outputs":[],"source":["ip_dim = len(wordidx_dict)\n","op_dim = len(tagidx_dict)\n","em_dim = 100\n","hidden_dim = 256\n","fc_dim = 128\n"]},{"cell_type":"code","execution_count":53,"id":"_-LOLRzzQhW7","metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1636758454344,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"_-LOLRzzQhW7"},"outputs":[],"source":["class task1_simple_BLSTM(torch.nn.Module):\n","    def __init__(self, ip_dim, em_dim, hidden_dim, fc_dim, op_dim):\n","        super(task1_simple_BLSTM, self).__init__()\n","        self.embed_layer = torch.nn.Embedding(num_embeddings = ip_dim, embedding_dim = em_dim)\n","        self.blstm_layer = torch.nn.LSTM(input_size = em_dim, hidden_size = hidden_dim, num_layers = 1, bidirectional = True, batch_first = True, dropout = 0.33)\n","        self.linear_layer = torch.nn.Linear(hidden_dim*2, fc_dim)\n","        self.elu_layer = torch.nn.ELU()\n","        self.classifier_layer = torch.nn.Linear(fc_dim, op_dim)\n","    def forward(self, x,x_len):\n","        embed_layer_out = self.embed_layer(x)\n","        blstm_packed = pack_padded_sequence(embed_layer_out,x_len,batch_first=True,enforce_sorted=True)\n","        blstm_layer_out, _ = self.blstm_layer(blstm_packed)\n","        blstm_layer_out, _ = pad_packed_sequence(blstm_layer_out, batch_first=True)\n","        classifier_layer_out = self.elu_layer(self.linear_layer(blstm_layer_out))\n","        target_output = self.classifier_layer(classifier_layer_out)\n","        return target_output\n","\n","    \n","    def wt_initalize(self):\n","        for name, param in self.named_parameters():\n","            torch.nn.init.normal_(param.data, mean=0, std=0.1)\n","\n","    "]},{"cell_type":"code","execution_count":null,"id":"P2SadeBFv_tU","metadata":{"id":"P2SadeBFv_tU"},"outputs":[],"source":["del model, optimizer, loss_fn"]},{"cell_type":"code","execution_count":55,"id":"pmRYVhUUQhW8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1636758455517,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"pmRYVhUUQhW8","outputId":"f3a0ee6f-36f8-4e64-c624-850ed6d112ed"},"outputs":[{"name":"stdout","output_type":"stream","text":["task1_simple_BLSTM(\n","  (embed_layer): Embedding(20178, 100)\n","  (blstm_layer): LSTM(100, 256, batch_first=True, dropout=0.33, bidirectional=True)\n","  (linear_layer): Linear(in_features=512, out_features=128, bias=True)\n","  (elu_layer): ELU(alpha=1.0)\n","  (classifier_layer): Linear(in_features=128, out_features=9, bias=True)\n",")\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.33 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"]}],"source":["model = task1_simple_BLSTM(ip_dim, em_dim, hidden_dim, fc_dim, op_dim).to(device)\n","model.wt_initalize()\n","print(model)"]},{"cell_type":"code","execution_count":56,"id":"w9JscVkMQhW8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":417,"status":"ok","timestamp":1636758457498,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"w9JscVkMQhW8","outputId":"8953c4dc-b0a7-461b-d023-50f9bd674dda"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([ 3.5959,  0.1333,  6.6113,  3.4439,  5.0198,  3.1834,  6.1365, 19.6794,\n","        19.6453])\n"]}],"source":["tag_weightage = torch.FloatTensor(class_weight.compute_class_weight('balanced', np.unique(all_ner_tags), all_ner_tags))\n","loss_fn = torch.nn.CrossEntropyLoss(weight = tag_weightage, ignore_index = -1).to(device)\n","optimizer = torch.optim.SGD(model.parameters(), lr = 0.017,momentum = 0.9)\n","scheduler = StepLR(optimizer, step_size = 25) "]},{"cell_type":"code","execution_count":57,"id":"wm7AOqYsTXE9","metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1636758459542,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"wm7AOqYsTXE9"},"outputs":[],"source":["def find_epoch_accuracy(pred,targ):\n","  pred = pred.argmax(dim=1,keepdim=True)\n","  find_targ_val = (targ!=-1).nonzero()\n","  correct = pred[find_targ_val].squeeze(1).eq(targ[find_targ_val])\n","  return correct.sum() / torch.FloatTensor([targ[find_targ_val].shape[0]]).to(device)"]},{"cell_type":"code","execution_count":58,"id":"9Jy---NtQhW9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":543690,"status":"ok","timestamp":1636759019583,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"9Jy---NtQhW9","outputId":"b1335b0f-e2d2-4170-d468-1d8f5cc06779"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 1 \n","Training Loss: 0.16193246425725352  Devset Loss: 0.10054690041727092\n","Training Accuracy: 0.575452885150466  Devset Accuracy: 0.7760861672491127\n","\n","\n","Devset Accuracy increased hence saving model as checkpoint\n","\n","\n","Previous Best: 0  Current Best: 0.7760861672491127\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2 \n","Training Loss: 0.06424895281973479  Devset Loss: 0.06924725811610367\n","Training Accuracy: 0.8029010481518472  Devset Accuracy: 0.828526852107502\n","\n","\n","Devset Accuracy increased hence saving model as checkpoint\n","\n","\n","Previous Best: 0.7760861672491127  Current Best: 0.828526852107502\n","\n","\n","Epoch: 3 \n","Training Loss: 0.030167968466215753  Devset Loss: 0.07920056530846786\n","Training Accuracy: 0.8887509689119791  Devset Accuracy: 0.8901260713587176\n","\n","\n","Devset Accuracy increased hence saving model as checkpoint\n","\n","\n","Previous Best: 0.828526852107502  Current Best: 0.8901260713587176\n","\n","\n","Epoch: 4 \n","Training Loss: 0.016253252220303098  Devset Loss: 0.07993777479844213\n","Training Accuracy: 0.9328758752058893  Devset Accuracy: 0.9193809840009175\n","\n","\n","Devset Accuracy increased hence saving model as checkpoint\n","\n","\n","Previous Best: 0.8901260713587176  Current Best: 0.9193809840009175\n","\n","\n","Epoch: 5 \n","Training Loss: 0.010567443027575113  Devset Loss: 0.0786224362824383\n","Training Accuracy: 0.9548599400402284  Devset Accuracy: 0.9237193487588891\n","\n","\n","Devset Accuracy increased hence saving model as checkpoint\n","\n","\n","Previous Best: 0.9193809840009175  Current Best: 0.9237193487588891\n","\n","\n","Epoch: 6 \n","Training Loss: 0.007106813309864458  Devset Loss: 0.0936765558321719\n","Training Accuracy: 0.9667594536394228  Devset Accuracy: 0.9230818465068309\n","\n","\n","Epoch: 7 \n","Training Loss: 0.0052158652888706965  Devset Loss: 0.10736327150495033\n","Training Accuracy: 0.9775580711438561  Devset Accuracy: 0.9524897266108385\n","\n","\n","Devset Accuracy increased hence saving model as checkpoint\n","\n","\n","Previous Best: 0.9237193487588891  Current Best: 0.9524897266108385\n","\n","\n","Epoch: 8 \n","Training Loss: 0.004089862755553902  Devset Loss: 0.1212219828564266\n","Training Accuracy: 0.9805217786699726  Devset Accuracy: 0.9560416866022936\n","\n","\n","Devset Accuracy increased hence saving model as checkpoint\n","\n","\n","Previous Best: 0.9524897266108385  Current Best: 0.9560416866022936\n","\n","\n","Epoch: 9 \n","Training Loss: 0.0026401759462671083  Devset Loss: 0.13199980063887123\n","Training Accuracy: 0.9857190580056875  Devset Accuracy: 0.9586658226019787\n","\n","\n","Devset Accuracy increased hence saving model as checkpoint\n","\n","\n","Previous Best: 0.9560416866022936  Current Best: 0.9586658226019787\n","\n","\n","Epoch: 10 \n","Training Loss: 0.0020194442969819833  Devset Loss: 0.11877048455388124\n","Training Accuracy: 0.9891079241942952  Devset Accuracy: 0.9545144399190596\n","\n","\n","Epoch: 11 \n","Training Loss: 0.0016798893072928383  Devset Loss: 0.13801935459194634\n","Training Accuracy: 0.991129814794974  Devset Accuracy: 0.9601787520638106\n","\n","\n","Devset Accuracy increased hence saving model as checkpoint\n","\n","\n","Previous Best: 0.9586658226019787  Current Best: 0.9601787520638106\n","\n","\n","Epoch: 12 \n","Training Loss: 0.0011032153924626013  Devset Loss: 0.14487078968729822\n","Training Accuracy: 0.9933398146160674  Devset Accuracy: 0.9610243692469611\n","\n","\n","Devset Accuracy increased hence saving model as checkpoint\n","\n","\n","Previous Best: 0.9601787520638106  Current Best: 0.9610243692469611\n","\n","\n","Epoch: 13 \n","Training Loss: 0.0009235768035267686  Devset Loss: 0.14658504386575688\n","Training Accuracy: 0.9948436564995734  Devset Accuracy: 0.9602253380636225\n","\n","\n","Epoch: 14 \n","Training Loss: 0.0006750797733350408  Devset Loss: 0.15820992108817442\n","Training Accuracy: 0.9960624665616471  Devset Accuracy: 0.9631100994138723\n","\n","\n","Devset Accuracy increased hence saving model as checkpoint\n","\n","\n","Previous Best: 0.9610243692469611  Current Best: 0.9631100994138723\n","\n","\n","Epoch: 15 \n","Training Loss: 0.0007728844680616504  Devset Loss: 0.1590045379286829\n","Training Accuracy: 0.9963817142092809  Devset Accuracy: 0.9628141150609373\n","\n","\n","Epoch: 16 \n","Training Loss: 0.000798041637114386  Devset Loss: 0.16134650223173397\n","Training Accuracy: 0.9964550165558319  Devset Accuracy: 0.9629503497483066\n","\n","\n","Epoch: 17 \n","Training Loss: 0.0006246158721393561  Devset Loss: 0.1712879308054685\n","Training Accuracy: 0.9967697919500815  Devset Accuracy: 0.9627205541349875\n","\n","\n","Epoch: 18 \n","Training Loss: 0.0005544086714568333  Devset Loss: 0.16884444883795627\n","Training Accuracy: 0.9972701828658099  Devset Accuracy: 0.9639495830623938\n","\n","\n","Devset Accuracy increased hence saving model as checkpoint\n","\n","\n","Previous Best: 0.9631100994138723  Current Best: 0.9639495830623938\n","\n","\n","Epoch: 19 \n","Training Loss: 0.0006779041575505398  Devset Loss: 0.18680522220648935\n","Training Accuracy: 0.9975523608866882  Devset Accuracy: 0.9624637306871541\n","\n","\n","Epoch: 20 \n","Training Loss: 0.0004445001125981157  Devset Loss: 0.17507013648912004\n","Training Accuracy: 0.9980459336069368  Devset Accuracy: 0.9648522578149742\n","\n","\n","Devset Accuracy increased hence saving model as checkpoint\n","\n","\n","Previous Best: 0.9639495830623938  Current Best: 0.9648522578149742\n","\n","\n"]}],"source":["epochs = 20\n","devset_min_loss = np.inf\n","devset_max_accuracy = 0\n","curr_train_loader = task1_train_loader\n","curr_dev_loader = task1_dev_loader\n","\n","\n","for epoch in range(epochs):\n","    model.train()\n","    epoch_train_accuracy = 0.0\n","    epoch_dev_accuracy = 0.0\n","    trainset_loss = 0.0\n","    devset_loss = 0.0\n","    \n","    for ip_sen, targ_ner,x_len in curr_train_loader:\n","        ip_sen, targ_ner,x_len = ip_sen.to(device), targ_ner.to(device),x_len\n","        optimizer.zero_grad()\n","        output = model(ip_sen,x_len)\n","        output = output.view(-1, output.shape[-1])\n","        targ_ner = targ_ner.view(-1)\n","        loss = loss_fn(output, targ_ner)\n","        loss.backward()\n","        optimizer.step()\n","        epoch_train_accuracy += float(find_epoch_accuracy(output,targ_ner).item()) \n","        trainset_loss += loss.item()\n","    \n","    model.eval()\n","\n","    for ip_sen, targ_ner,x_len in curr_dev_loader:\n","        ip_sen, targ_ner = ip_sen.to(device), targ_ner.to(device)\n","        ip_sen, targ_ner = ip_sen, targ_ner\n","        output = model(ip_sen,x_len)\n","        output = output.view(-1, output.shape[-1])\n","        targ_ner = targ_ner.view(-1)\n","        loss = loss_fn(output, targ_ner)\n","        epoch_dev_accuracy += float(find_epoch_accuracy(output,targ_ner).item()) \n","        devset_loss += loss.item()\n","    \n","    epoch_train_accuracy = (epoch_train_accuracy * curr_batch_len)/len(curr_train_loader.dataset)\n","    epoch_dev_accuracy = (epoch_dev_accuracy * curr_batch_len)/len(curr_dev_loader.dataset)\n","    trainset_loss = trainset_loss/len(curr_train_loader.dataset)\n","    devset_loss = devset_loss/len(curr_dev_loader.dataset)\n","    \n","    \n","    print('Epoch:',epoch+1,'\\nTraining Loss:', trainset_loss,' Devset Loss:',devset_loss)\n","    print('Training Accuracy:',epoch_train_accuracy,' Devset Accuracy:',epoch_dev_accuracy)\n","    print('\\n')\n","    if epoch_dev_accuracy >= devset_max_accuracy:\n","        print('Devset Accuracy increased hence saving model as checkpoint')\n","        print('\\n')\n","        print(\"Previous Best:\",devset_max_accuracy,\" Current Best:\",epoch_dev_accuracy)\n","        print('\\n')\n","        torch.save(model.state_dict(), os.path.join(sys.path[0],'/content/drive/MyDrive/Colab Notebooks/data/blstm1.pt'))\n","        devset_max_accuracy = epoch_dev_accuracy\n","    scheduler.step(devset_max_accuracy)"]},{"cell_type":"code","execution_count":59,"id":"J0qyKHBKewBx","metadata":{"executionInfo":{"elapsed":312,"status":"ok","timestamp":1636759119389,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"J0qyKHBKewBx"},"outputs":[],"source":["del model, optimizer, loss_fn"]},{"cell_type":"code","execution_count":61,"id":"jlsCXVEgQhXA","metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1636759122052,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"jlsCXVEgQhXA"},"outputs":[],"source":["def make_output_file(x, y, pre_data,loaded_model,op_filename, test_file = False):\n","    loaded_model.eval()\n","    line_num = 0\n","    me = 0\n","    \n","    with torch.no_grad():\n","        with open(op_filename, \"w\") as fp:\n","            for i in range(len(x)):\n","              curr_indx = 1\n","              x_len = np.array([len(x[i])])\n","              ip = torch.LongTensor(x[i]).to(device)\n","              ip = torch.unsqueeze(ip, 0)\n","              op = loaded_model(ip,x_len)\n","              op = op.view(-1, op.shape[-1])\n","              _, pred = torch.max(op, 1)\n","\n","              if not test_file:\n","                targ_ner = y[i]\n","                for j in range(len(targ_ner)):\n","                    \n","                    pred_tag = int(pred[j])\n","                    targ_tag = int(targ_ner[j])\n","                    \n","                    z = pre_data[line_num][1]\n","                    \n","                    for key,value in tagidx_dict.items():\n","                      if value == targ_tag:\n","                        gold = key\n","                      if value == pred_tag:\n","                        my_word = key\n","                    \n","                    my_sen_pred = str(curr_indx)+' '+z+' '+gold+' '+my_word+'\\n'\n","                    fp.write(my_sen_pred)\n","                    curr_indx += 1\n","                    line_num += 1\n","                fp.write('\\n')\n","              else:\n","                for j in range(len(pred)):\n","                  pred_tag = int(pred[j])\n","                  z = pre_data[line_num][1]\n","                  for key,value in tagidx_dict.items():\n","                      if value == pred_tag:\n","                        my_word = key\n","                  my_sen_pred = str(curr_indx)+' '+z+' '+my_word+'\\n'\n","                  fp.write(my_sen_pred)\n","                  curr_indx += 1\n","                  line_num += 1\n","                fp.write('\\n')\n"]},{"cell_type":"code","execution_count":62,"id":"Vq-nLQGChfnY","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":164},"executionInfo":{"elapsed":10,"status":"error","timestamp":1636759122891,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"Vq-nLQGChfnY","outputId":"0376060b-c544-4f99-8ff1-f838e493979e"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-62-9eee18ee6649>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"]}],"source":["del load_model"]},{"cell_type":"code","execution_count":63,"id":"1e00b2c0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7138,"status":"ok","timestamp":1636759131079,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"1e00b2c0","outputId":"e4afec0e-0ce3-4c7b-aab7-3c3f9e04c5e9"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.33 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"]},{"name":"stdout","output_type":"stream","text":["False\n"]}],"source":["load_model = task1_simple_BLSTM(ip_dim, em_dim, hidden_dim, fc_dim, op_dim).to(device)\n","load_model.load_state_dict(torch.load(os.path.join(sys.path[0],'/content/drive/MyDrive/Colab Notebooks/data/blstm1.pt')))\n","make_output_file(dev_blstm_x, dev_blstm_y, pre_dev, load_model, os.path.join(sys.path[0],'/content/drive/MyDrive/Colab Notebooks/data/dev1.out'))\n"]},{"cell_type":"code","execution_count":65,"id":"73c89f5e","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1636759263040,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"73c89f5e"},"outputs":[],"source":["def make_test_x_y_blstm(pre_data):\n","    blstm_word_idx = []\n","    #blstm_tag_idx = []\n","    list_of_sen = []\n","    list_of_sen.append(pre_data[0])\n","    for i in range(1,len(pre_data)):\n","        if pre_data[i][0] != '1':\n","            list_of_sen.append(pre_data[i])\n","        else:\n","            words = np.array([])\n","            #tags = np.array([])\n","            my_word =''\n","            for curr_indx in range(len(list_of_sen)):\n","                my_word = list_of_sen[curr_indx][1]\n","                if my_word not in wordidx_dict:\n","         \n","                    if chk_num_tag(list_of_sen[curr_indx][1]):\n","                        my_word  = number_tag\n","\n","                    else:\n","                        my_word  = unknown_tag\n","       \n","                words= np.append(words,wordidx_dict[my_word])\n","                #tags= np.append(tags,tagidx_dict[list_of_sen[curr_indx][2]])            \n","            \n","            blstm_word_idx.append(words)\n","            #blstm_tag_idx.append(tags)\n","\n","            list_of_sen = []\n","            list_of_sen.append(pre_data[i])\n","    \n","    \n","    blstm_word_idx.append(np.array([257.]))\n","    #blstm_tag_idx.append(np.array([1]))\n","\n","    return np.array(blstm_word_idx)"]},{"cell_type":"code","execution_count":66,"id":"13a7e23d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1636759264661,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"13a7e23d","outputId":"75aaa7e4-610d-44cf-b1b1-8888112d6568"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"]}],"source":["test_blstm_x = make_test_x_y_blstm(pre_test)"]},{"cell_type":"code","execution_count":68,"id":"97b1b409","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7019,"status":"ok","timestamp":1636759315561,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"97b1b409","outputId":"e38e55fd-9af9-4cda-80b6-08971863e07e"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.33 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"]},{"name":"stdout","output_type":"stream","text":["True\n"]}],"source":["load_model = task1_simple_BLSTM(ip_dim, em_dim, hidden_dim, fc_dim, op_dim).to(device)\n","load_model.load_state_dict(torch.load(os.path.join(sys.path[0],'/content/drive/MyDrive/Colab Notebooks/data/blstm1.pt')))\n","make_output_file(test_blstm_x, [], pre_test, load_model, os.path.join(sys.path[0],'/content/drive/MyDrive/Colab Notebooks/data/test1.out'),True)\n"]},{"cell_type":"code","execution_count":31,"id":"t7h-cpHTRFQR","metadata":{"executionInfo":{"elapsed":57380,"status":"ok","timestamp":1636759664792,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"t7h-cpHTRFQR"},"outputs":[],"source":["all_words = pre_train_words + pre_dev_words + pre_test_words\n","glove_w2v_file = 'glove.txt.word2vec'\n","glove2word2vec(\"glove.6B.100d.gz\", glove_w2v_file)\n","glove_vec = KeyedVectors.load_word2vec_format(glove_w2v_file)"]},{"cell_type":"code","execution_count":32,"id":"tGllnr6dqjrY","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":369,"status":"ok","timestamp":1636759899775,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"tGllnr6dqjrY","outputId":"9a5ee8d3-8633-4eb7-f4a6-9ee8fdc5aa32"},"outputs":[{"name":"stdout","output_type":"stream","text":["22137\n"]}],"source":["print(len(all_words))"]},{"cell_type":"code","execution_count":33,"id":"svgGgmbHuE0y","metadata":{"executionInfo":{"elapsed":0,"status":"ok","timestamp":1636759901014,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"svgGgmbHuE0y"},"outputs":[],"source":["all_wordidx_dict = {}\n","curr_indx = 0\n","\n","for t2_curr_word in all_words:\n","    for my_word in t2_curr_word:\n","        if my_word not in all_wordidx_dict:\n","            all_wordidx_dict[my_word] = curr_indx\n","            curr_indx += 1\n","    all_wordidx_dict[number_tag] = curr_indx"]},{"cell_type":"code","execution_count":36,"id":"fcd65442","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1636759901392,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"fcd65442","outputId":"19064595-36c2-4b7f-bf9d-8d1307e9bbc6"},"outputs":[],"source":["embed_weight_mat = np.zeros((len(all_wordidx_dict), 100), dtype = float)\n","glove_embed_dict = {}\n"]},{"cell_type":"code","execution_count":37,"id":"g00Z76K-vt8s","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1636759901746,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"g00Z76K-vt8s"},"outputs":[],"source":["def glove_embed_weight(embed_weight_mat, model):\n","    global all_wordidx_dict, glove_embed_dict\n","    for my_word, curr_indx in all_wordidx_dict.items():\n","        my_word = my_word.lower()\n","        \n","        if my_word in glove_embed_dict:\n","            embed_weight_mat[curr_indx] = glove_embed_dict[my_word]\n","        else:\n","          if my_word in model.vocab:\n","            embed_weight_mat[curr_indx] = model[my_word]\n","          else:\n","            rand_embed = np.random.normal(scale = 0.6, size = (100,))\n","            embed_weight_mat[curr_indx] = rand_embed\n","            glove_embed_dict[my_word] = rand_embed\n","\n","            \n","    \n","    return embed_weight_mat"]},{"cell_type":"code","execution_count":38,"id":"GT2uYZYZvr1s","metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1636759901746,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"GT2uYZYZvr1s"},"outputs":[],"source":["embed_weight_mat = glove_embed_weight(embed_weight_mat, glove_vec)\n"]},{"cell_type":"code","execution_count":41,"id":"b9854d94","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["100\n"]}],"source":["print(len(embed_weight_mat[0]))"]},{"cell_type":"code","execution_count":42,"id":"438f2743","metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1636759902447,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"438f2743"},"outputs":[],"source":["def glove_make_x_y_blstm(pre_data,test = False):\n","    blstm_word_idx = []\n","    blstm_tag_idx = []\n","    list_of_sen = []\n","    list_of_sen.append(pre_data[0])\n","    for i in range(1,len(pre_data)):\n","        if pre_data[i][0] != '1':\n","            list_of_sen.append(pre_data[i])\n","        else:\n","            words = np.array([])\n","            tags = np.array([])\n","            my_word =''\n","            for curr_indx in range(len(list_of_sen)):\n","                my_word = list_of_sen[curr_indx][1]\n","                if chk_num_tag(my_word):\n","\n","                  my_word  = number_tag              \n","       \n","                words= np.append(words,all_wordidx_dict[my_word])\n","                if not test:\n","                    tags= np.append(tags,tagidx_dict[list_of_sen[curr_indx][2]])            \n","            \n","            blstm_word_idx.append(words)\n","            if not test:\n","                blstm_tag_idx.append(tags)\n","\n","            list_of_sen = []\n","            list_of_sen.append(pre_data[i])\n","    \n","    \n","    blstm_word_idx.append(np.array([257.]))\n","    if not test:\n","        blstm_tag_idx.append(np.array([1]))\n","\n","    return np.array(blstm_word_idx), np.array(blstm_tag_idx)"]},{"cell_type":"code","execution_count":43,"id":"3VjL_4q6yIOA","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6760,"status":"ok","timestamp":1636759909204,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"3VjL_4q6yIOA","outputId":"b3038ff7-c30a-499c-a327-101210a8b317"},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/17/jys7jgwn3x37cltk9w8j0l080000gq/T/ipykernel_59682/3584130673.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  return np.array(blstm_word_idx), np.array(blstm_tag_idx)\n"]}],"source":["glove_train_blstm_x, glove_train_blstm_y = glove_make_x_y_blstm(pre_train)\n","glove_dev_blstm_x, glove_dev_blstm_y = glove_make_x_y_blstm(pre_dev)\n","glove_test_blstm_x,_ = glove_make_x_y_blstm(pre_test,True)\n"]},{"cell_type":"code","execution_count":44,"id":"e6b7b4a0","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0. 1. 2. 3. 4. 5. 6. 7. 8.]\n"]}],"source":["print(glove_train_blstm_x[0])"]},{"cell_type":"code","execution_count":45,"id":"A0tg-OaBTEL8","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1636759909205,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"A0tg-OaBTEL8"},"outputs":[],"source":["glove_train_dataset = list(zip(glove_train_blstm_x,glove_train_blstm_y))\n","glove_dev_dataset = list(zip(glove_dev_blstm_x,glove_dev_blstm_y))\n","\n","glove_train_loader = DataLoader(glove_train_dataset, batch_size = curr_batch_len, drop_last = True, shuffle = True,collate_fn=PadSequence())\n","glove_dev_loader = DataLoader(glove_dev_dataset, batch_size = curr_batch_len, drop_last = True, shuffle = True,collate_fn=PadSequence())\n"]},{"cell_type":"code","execution_count":47,"id":"gYwl1z8d33jO","metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1636759909205,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"gYwl1z8d33jO"},"outputs":[],"source":["ip_dim = len(all_wordidx_dict)\n","em_dim = 100\n","hidden_dim = 256\n","fc_dim = 128\n","op_dim = len(tagidx_dict)\n","tag_weightage = class_weight.compute_class_weight('balanced', np.unique(all_ner_tags), all_ner_tags)"]},{"cell_type":"code","execution_count":76,"id":"aa2aa396","metadata":{},"outputs":[],"source":["del model, optimizer"]},{"cell_type":"code","execution_count":77,"id":"zhYwb_nc4GXq","metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1636759909206,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"zhYwb_nc4GXq"},"outputs":[],"source":["def find_embed_layer(ip_dim, em_dim, embed_weight_mat):\n","    embed_weight_mat = torch.FloatTensor(embed_weight_mat).to(device)\n","    embed_layer = torch.nn.Embedding(num_embeddings = ip_dim, embedding_dim = em_dim)\n","    embed_layer.load_state_dict({'weight': embed_weight_mat})\n","    return embed_layer"]},{"cell_type":"code","execution_count":78,"id":"W2N9FszR3_EK","metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1636759909206,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"W2N9FszR3_EK"},"outputs":[],"source":["class task2_glove_BLSTM(torch.nn.Module):\n","    def __init__(self, ip_dim, em_dim, hidden_dim, fc_dim, op_dim, embed_weight_mat):\n","        super(task2_glove_BLSTM, self).__init__()\n","        self.embed_layer = find_embed_layer(ip_dim, em_dim, embed_weight_mat)\n","        self.blstm_layer = torch.nn.LSTM(input_size = em_dim, hidden_size = hidden_dim, num_layers = 1, bidirectional = True, batch_first = True, dropout = 0.33)\n","        self.linear_layer = torch.nn.Linear(hidden_dim * 2, fc_dim)\n","        self.elu_layer = torch.nn.ELU()\n","        self.classifier_layer = torch.nn.Linear(fc_dim, op_dim)\n","    \n","    def forward(self, x,x_len):\n","        print('x:',x.shape)\n","        emb = self.embed_layer(x)\n","        print('emb:',emb.shape)\n","        blstm_packed = pack_padded_sequence(emb, x_len, batch_first = True, enforce_sorted = True)\n","        print('hd:',len(blstm_packed))\n","        blstm_layer_out, _ = self.blstm_layer(blstm_packed)\n","        blstm_layer_out, _ = pad_packed_sequence(blstm_layer_out, batch_first = True)\n","        classifier_layer_out = self.elu_layer(self.linear_layer(blstm_layer_out))\n","        target_output = self.classifier_layer(classifier_layer_out)\n","        return target_output\n","    "]},{"cell_type":"code","execution_count":79,"id":"bLfT1yYC4lt3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1636761085923,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"bLfT1yYC4lt3","outputId":"9f29e021-9f61-43c1-ecf0-01418c4da1ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["task2_glove_BLSTM(\n","  (embed_layer): Embedding(30291, 100)\n","  (blstm_layer): LSTM(100, 256, batch_first=True, dropout=0.33, bidirectional=True)\n","  (linear_layer): Linear(in_features=512, out_features=128, bias=True)\n","  (elu_layer): ELU(alpha=1.0)\n","  (classifier_layer): Linear(in_features=128, out_features=9, bias=True)\n",")\n"]}],"source":["model = task2_glove_BLSTM(ip_dim, em_dim, hidden_dim, fc_dim, op_dim, embed_weight_mat).to(device)\n","print(model)"]},{"cell_type":"code","execution_count":80,"id":"rDCze7-F4qua","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1636761085924,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"rDCze7-F4qua"},"outputs":[],"source":["tag_weightage = torch.FloatTensor(tag_weightage)\n","loss_fn = torch.nn.CrossEntropyLoss(weight = tag_weightage, ignore_index = -1).to(device)\n","optimizer = torch.optim.SGD(model.parameters(), lr = 0.017, momentum = 0.9)\n","scheduler = StepLR(optimizer, step_size = 25) \n"]},{"cell_type":"code","execution_count":85,"id":"qfa6XHnp4s_q","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":831431,"status":"ok","timestamp":1636761917642,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"qfa6XHnp4s_q","outputId":"c39e2916-5470-42a7-e57e-5e378f020e5c"},"outputs":[{"name":"stdout","output_type":"stream","text":["ip: torch.Size([40]) tensor([40, 35, 33, 30, 22, 12,  5,  4])\n","x: torch.Size([8, 40])\n","emb: torch.Size([8, 40, 100])\n","hd: 4\n","op: torch.Size([8, 40, 9])\n","t: torch.Size([320, 9])\n","finalt: tensor([ 0.0370, -0.0612,  0.0275,  0.0570,  0.0579,  0.0130, -0.0389, -0.0656,\n","         0.0131], grad_fn=<SelectBackward>)\n","tar: tensor([ 2,  1,  3,  4,  1,  1,  1,  1,  1,  3,  4,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  5,  1,  1,  1,  1,  1,  1,  3,  1,  1,  1,  1,  1,  5,  1,  0,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  5,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1, -1, -1, -1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  5,  1,  1,  1,  2,  1,  1,  5,  8,  1,  1,  1,  1,  1,  2,  1,\n","         1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  5,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1,\n","         1,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  3,  4,  4,  1,  1,  1,\n","         1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","        -1, -1,  3,  4,  1,  5,  1,  1,  3,  4,  1,  5,  1,  1, -1, -1, -1, -1,\n","        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","        -1, -1, -1, -1, -1, -1,  1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1,\n","        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  5,  1,  5,  1, -1, -1, -1, -1,\n","        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n"]},{"ename":"NameError","evalue":"name 'find_epoch_accuracy' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/var/folders/17/jys7jgwn3x37cltk9w8j0l080000gq/T/ipykernel_59682/2654635382.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mepoch_train_accuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_epoch_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarg_ner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mtrainset_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'find_epoch_accuracy' is not defined"]}],"source":["epochs = 1\n","devset_min_loss = np.inf\n","devset_max_accuracy = 0\n","curr_train_loader = glove_train_loader\n","curr_dev_loader = glove_dev_loader\n","\n","\n","for epoch in range(epochs):\n","    model.train()\n","    epoch_train_accuracy = 0.0\n","    epoch_dev_accuracy = 0.0\n","    trainset_loss = 0.0\n","    devset_loss = 0.0\n","    i = 0\n","    for ip_sen, targ_ner,x_len in curr_train_loader:\n","        print('ip:',ip_sen[0].shape,x_len)\n","        if i==1:\n","            break\n","        i+=1\n","        ip_sen, targ_ner,x_len = ip_sen.to(device), targ_ner.to(device),x_len\n","        optimizer.zero_grad()\n","        output = model(ip_sen,x_len)\n","        print('op:',output.shape)\n","        print('t:',output.view(-1,output.shape[-1]).shape)\n","        output = output.view(-1, output.shape[-1])\n","        print('finalt:',output[0])\n","        targ_ner = targ_ner.view(-1)\n","        print('tar:',targ_ner)\n","        loss = loss_fn(output, targ_ner)\n","        loss.backward()\n","        optimizer.step()\n","        epoch_train_accuracy += float(find_epoch_accuracy(output,targ_ner).item()) \n","        trainset_loss += loss.item()\n","    \n","    model.eval()\n","\n","    for ip_sen, targ_ner,x_len in curr_dev_loader:\n","        if i==1:\n","            break\n","        ip_sen, targ_ner = ip_sen.to(device), targ_ner.to(device)\n","        ip_sen, targ_ner = ip_sen, targ_ner\n","        output = model(ip_sen,x_len)\n","        output = output.view(-1, output.shape[-1])\n","        targ_ner = targ_ner.view(-1)\n","        loss = loss_fn(output, targ_ner)\n","        epoch_dev_accuracy += float(find_epoch_accuracy(output,targ_ner).item()) \n","        devset_loss += loss.item()\n","    \n","    epoch_train_accuracy = (epoch_train_accuracy * curr_batch_len)/len(curr_train_loader.dataset)\n","    epoch_dev_accuracy = (epoch_dev_accuracy * curr_batch_len)/len(curr_dev_loader.dataset)\n","    trainset_loss = trainset_loss/len(curr_train_loader.dataset)\n","    devset_loss = devset_loss/len(curr_dev_loader.dataset)\n","    \n","    \n","    print('Epoch:',epoch+1,'\\nTraining Loss:', trainset_loss,' Devset Loss:',devset_loss)\n","    print('Training Accuracy:',epoch_train_accuracy,' Devset Accuracy:',epoch_dev_accuracy)\n","    print('\\n')\n","    if epoch_dev_accuracy >= devset_max_accuracy:\n","        print('Devset Accuracy increased hence saving model as checkpoint')\n","        print('\\n')\n","        print(\"Previous Best:\",devset_max_accuracy,\" Current Best:\",epoch_dev_accuracy)\n","        print('\\n')\n","        torch.save(model.state_dict(), os.path.join(sys.path[0],'/content/drive/MyDrive/Colab Notebooks/data/blstm2.pt'))\n","        devset_max_accuracy = epoch_dev_accuracy\n","    scheduler.step(devset_max_accuracy)"]},{"cell_type":"code","execution_count":126,"id":"__7JIH2eql64","metadata":{"executionInfo":{"elapsed":368,"status":"ok","timestamp":1636762811390,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"__7JIH2eql64"},"outputs":[],"source":["del load_model"]},{"cell_type":"code","execution_count":127,"id":"b9ca24b9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6816,"status":"ok","timestamp":1636762819556,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"b9ca24b9","outputId":"8bfc731f-ef46-46f1-ef90-227b0a6dd7e8"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.33 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"]},{"name":"stdout","output_type":"stream","text":["False\n"]}],"source":["load_model = task2_glove_BLSTM(ip_dim, em_dim, hidden_dim, fc_dim, op_dim,embed_weight_mat).to(device)\n","load_model.load_state_dict(torch.load(os.path.join(sys.path[0],'/content/drive/MyDrive/Colab Notebooks/data/blstm2.pt') ))\n","make_output_file(glove_dev_blstm_x, glove_dev_blstm_y, pre_dev, load_model, os.path.join(sys.path[0],'/content/drive/MyDrive/Colab Notebooks/data/dev2.out'))\n"]},{"cell_type":"code","execution_count":128,"id":"gb1ci7LapGTO","metadata":{"executionInfo":{"elapsed":369,"status":"ok","timestamp":1636762961549,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"gb1ci7LapGTO"},"outputs":[],"source":["del load_model"]},{"cell_type":"code","execution_count":129,"id":"R2tdBcgg-Kga","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7043,"status":"ok","timestamp":1636763019972,"user":{"displayName":"shubham singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07569025068133696078"},"user_tz":480},"id":"R2tdBcgg-Kga","outputId":"c42512ef-baad-470b-ef80-59914c4b7e6f"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.33 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"]},{"name":"stdout","output_type":"stream","text":["True\n"]}],"source":["load_model = task2_glove_BLSTM(ip_dim, em_dim, hidden_dim, fc_dim, op_dim,embed_weight_mat).to(device)\n","load_model.load_state_dict(torch.load(os.path.join(sys.path[0],'/content/drive/MyDrive/Colab Notebooks/data/blstm2.pt')))\n","make_output_file(glove_test_blstm_x, [], pre_test, load_model, os.path.join(sys.path[0],'/content/drive/MyDrive/Colab Notebooks/data/test2.out'),True)\n"]},{"cell_type":"code","execution_count":null,"id":"MGsrUZZhqeNM","metadata":{"id":"MGsrUZZhqeNM"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Shubham_Singh_HW4.ipynb","provenance":[]},"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"},"kernelspec":{"display_name":"Python 3.9.7 64-bit","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":5}
